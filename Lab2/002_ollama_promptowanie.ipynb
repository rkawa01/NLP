{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29cab7ec",
   "metadata": {},
   "source": [
    "\n",
    "# **Laboratorium 002: Skuteczne promptowanie modeli LLM w Ollama**\n",
    "\n",
    "## **Cel zajÄ™Ä‡**\n",
    "\n",
    "- WyÄ‡wiczenie praktycznych technik **prompt engineeringu** na lokalnych modelach uruchamianych przez **Ollama**.  \n",
    "- Zastosowanie **struktur i rÃ³l** (system/developer, user, assistant) w praktyce â€“ z naciskiem na *kompozycjÄ™ promptÃ³w*, a nie pojedyncze pytania.  \n",
    "- Przeprowadzenie **ewaluacji promptÃ³w** (PromptFoo) i analizy zachowania modeli.  \n",
    "- Zrozumienie zasad **bezpieczeÅ„stwa, prompt injection, anonimizacji** i dobrych praktyk projektowych.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Przygotowanie Å›rodowiska i prerekwizyty**\n",
    "\n",
    "- Zainstalowana **Ollama** i dwa modele w konwencji *polski â€“ niepolski* (`llama3.1:8b`, `gemma2:2b`, `SpeakLeash/bielik-*`).  \n",
    "\n",
    "Test dziaÅ‚ania modelu:\n",
    "\n",
    "```bash\n",
    "echo \"Napisz rymowankÄ™ o najlepszym wykÅ‚adowcy na WI.\" | ollama run gemma2:2b\n",
    "```\n",
    "---\n",
    "\n",
    "- MoÅ¼emy teÅ¼ przenieÅ›Ä‡ siÄ™ z pracÄ… do notebooka, wtedy nasz warsztat bÄ™dzie wyglÄ…daÅ‚ tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189efaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W Wi, gdzie wiedza siÄ™ rozpala,\n",
      "WykÅ‚adowca geniusz w swoich ram,\n",
      "Uczy z pasjÄ… i tak samo wylewa,\n",
      "KsiÄ…Å¼ki i historie, bez lÄ™ku i strachu.\n",
      "\n",
      "Zawsze uÅ›miechniÄ™ty, bÅ‚yskotliwy,\n",
      "Rozwijamy wiedzÄ™, co do tego nie ma wÄ…tpliwoÅ›ci,\n",
      "W jego sÅ‚owach piÄ™kno, lekkoÅ›Ä‡ i radoÅ›Ä‡,\n",
      "WspaniaÅ‚y wykÅ‚adowca, nasz wielki szacunek. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[{'role': 'user', 'content': 'Napisz rymowankÄ™ o najlepszym wykÅ‚adowcy na WI'}]\n",
    ")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97015f",
   "metadata": {},
   "source": [
    "## **2. Struktura i techniki promptowania**\n",
    "\n",
    "### 2.1 Zero-shot\n",
    "\n",
    "**Zeroâ€‘shot prompting** to sposÃ³b formuÅ‚owania zapytania do duÅ¼ego modelu jÄ™zykowego, w ktÃ³rym nie podajemy mu ani jednego przykÅ‚adu wykonanego zadania. Model dostaje wyÅ‚Ä…cznie instrukcjÄ™ (â€zrÃ³b Xâ€) i caÅ‚Ä… resztÄ™ dedukuje sam na podstawie wiedzy nabytej w treningu.\n",
    "\n",
    "Zadania, do ktÃ³rych uÅ¼ywa siÄ™ **zero-shot prompting**:\n",
    "1. Szybkie prototypowanie â€“ gdy chcemy sprawdziÄ‡, czy model moÅ¼e poradziÄ‡ sobie z danym zadaniem (czy jego architektura i materiaÅ‚ treningowy na to pozwalajÄ…).\n",
    "\n",
    "2. Zadania ogÃ³lne o prostym formacie wyjÅ›ciowym (tÅ‚umaczenia, parafrazy, proste klasyfikacje).\n",
    "\n",
    "3. Systemy low-code/no-code â€“ uÅ¼ytkownik pisze naturalnym jÄ™zykiem, a model odpowiada bez konfiguracji.\n",
    "\n",
    "4. Ekstrakcja informacji _ad hoc_ (imiÄ™, mail, daty z tekstu itp.) tam, gdzie nie opÅ‚aca siÄ™ trenowaÄ‡ lub fine-tune'owaÄ‡ modelu.\n",
    "\n",
    "\n",
    "Kiedy **zero-shot** jest najbardziej efektywne?\n",
    "- brak lub szczÄ…tkowe dane oznaczone â€“ nie mamy przykÅ‚adowych par wejÅ›cieâ†’wyjÅ›cie.\n",
    "- zadanie jest podobne do scenariuszy widzianych w treningu (np. â€podsumujâ€, â€przetÅ‚umaczâ€, â€odpowiedz TAK/NIEâ€).\n",
    "- liczy siÄ™ czas wdroÅ¼enia â€“ chcemy odpowiedzi â€tu i terazâ€, bez skrupulatnego modyfikowania promptu.\n",
    "\n",
    "Kiedy nie wystarcza?\n",
    "- zÅ‚oÅ¼one transformacje wymagajÄ…ce Å›cisÅ‚ej struktury lub niestandardowych reguÅ‚.\n",
    "- zadania domenowe z maÅ‚o popularnym Å¼argonem (medycyna, prawo) â€“ wtedy lepszy jest few-shot lub RAG.\n",
    "\n",
    "```bash\n",
    "echo \"Wypisz 5 sÅ‚Ã³w kluczowych z notatki o spotkaniu KoÅ‚a Naukowego BIT.\" | ollama run gemma2:2b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a383c",
   "metadata": {},
   "source": [
    "ğŸ”µ Spotkanie KoÅ‚a Naukowego BIT\n",
    "\n",
    "ğŸ“… Åšroda, godz. 14:00\n",
    "ğŸ“ Sala 4.30D, WydziaÅ‚ Informatyki\n",
    "\n",
    "Serdecznie zapraszamy wszystkich studentÃ³w â€” zarÃ³wno obecnych czÅ‚onkÃ³w, jak i osoby, ktÃ³re dopiero chcÄ… doÅ‚Ä…czyÄ‡ â€” na kolejne spotkanie KoÅ‚a Naukowego BIT!\n",
    "\n",
    "ğŸ’¡ Plan spotkania:\n",
    "\n",
    "- OmÃ³wienie planu projektÃ³w na semestr zimowy â€“ propozycje tematÃ³w z zakresu AI, bezpieczeÅ„stwa i tworzenia aplikacji webowych.\n",
    "\n",
    "- Prezentacja aktualnych inicjatyw â€“ praca nad systemem rozpoznawania obrazu oraz chatbotem opartym na modelach LLM.\n",
    "\n",
    "- Warsztaty wprowadzajÄ…ce â€“ krÃ³tkie zajÄ™cia praktyczne z narzÄ™dzia Ollama i prompt engineeringu.\n",
    "\n",
    "- PodziaÅ‚ na zespoÅ‚y projektowe â€“ moÅ¼liwoÅ›Ä‡ zapisania siÄ™ do wybranego projektu.\n",
    "\n",
    " - Dyskusja i networking â€“ poznaj ludzi, ktÃ³rzy programujÄ… z pasjÄ…!\n",
    "\n",
    "ğŸš€ Dlaczego warto doÅ‚Ä…czyÄ‡?\n",
    "\n",
    "- Rozwijasz praktyczne umiejÄ™tnoÅ›ci techniczne (AI, ML, web, backend).\n",
    "\n",
    "- Bierzesz udziaÅ‚ w projektach badawczo-rozwojowych i hackathonach.\n",
    "\n",
    "- Zyskujesz doÅ›wiadczenie zespoÅ‚owe i wsparcie mentorÃ³w z branÅ¼y.\n",
    "\n",
    "- Spotykasz ludzi, ktÃ³rzy chcÄ… robiÄ‡ coÅ› wiÄ™cej niÅ¼ tylko zaliczaÄ‡ przedmioty.\n",
    "\n",
    "ğŸ“¢ Nie musisz mieÄ‡ doÅ›wiadczenia â€” wystarczy ciekawoÅ›Ä‡ i chÄ™Ä‡ nauki!\n",
    "PrzyjdÅº w Å›rodÄ™ o 14:00 do sali 4.30D i zobacz, czym Å¼yje nasze koÅ‚o!\n",
    "\n",
    "âœ‰ï¸ W razie pytaÅ„: bit@wi.edu.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd0875",
   "metadata": {},
   "source": [
    "Zadanie 2.1.1 Generowanie streszczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08241491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      " \"summary\": \" BIT student group meeting will discuss winter semester projects and workshops, with opportunities for teamwork and networking.\" \n",
      "}\n",
      "``` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "ğŸ”µ Spotkanie KoÅ‚a Naukowego BIT\n",
    "\n",
    "ğŸ“… Åšroda, godz. 14:00\n",
    "ğŸ“ Sala 4.30D, WydziaÅ‚ Informatyki\n",
    "\n",
    "Serdecznie zapraszamy wszystkich studentÃ³w â€” zarÃ³wno obecnych czÅ‚onkÃ³w, jak i osoby, ktÃ³re dopiero chcÄ… doÅ‚Ä…czyÄ‡ â€” na kolejne spotkanie KoÅ‚a Naukowego BIT!\n",
    "\n",
    "ğŸ’¡ Plan spotkania:\n",
    "\n",
    "OmÃ³wienie planu projektÃ³w na semestr zimowy â€“ propozycje tematÃ³w z zakresu AI, bezpieczeÅ„stwa i tworzenia aplikacji webowych.\n",
    "\n",
    "Prezentacja aktualnych inicjatyw â€“ praca nad systemem rozpoznawania obrazu oraz chatbotem opartym na modelach LLM.\n",
    "\n",
    "Warsztaty wprowadzajÄ…ce â€“ krÃ³tkie zajÄ™cia praktyczne z narzÄ™dzia Ollama i prompt engineeringu.\n",
    "\n",
    "PodziaÅ‚ na zespoÅ‚y projektowe â€“ moÅ¼liwoÅ›Ä‡ zapisania siÄ™ do wybranego projektu.\n",
    "\n",
    "Dyskusja i networking â€“ poznaj ludzi, ktÃ³rzy programujÄ… z pasjÄ…!\n",
    "\n",
    "ğŸš€ Dlaczego warto doÅ‚Ä…czyÄ‡?\n",
    "\n",
    "Rozwijasz praktyczne umiejÄ™tnoÅ›ci techniczne (AI, ML, web, backend).\n",
    "\n",
    "Bierzesz udziaÅ‚ w projektach badawczo-rozwojowych i hackathonach.\n",
    "\n",
    "Zyskujesz doÅ›wiadczenie zespoÅ‚owe i wsparcie mentorÃ³w z branÅ¼y.\n",
    "\n",
    "Spotykasz ludzi, ktÃ³rzy chcÄ… robiÄ‡ coÅ› wiÄ™cej niÅ¼ tylko zaliczaÄ‡ przedmioty.\n",
    "\n",
    "ğŸ“¢ Nie musisz mieÄ‡ doÅ›wiadczenia â€” wystarczy ciekawoÅ›Ä‡ i chÄ™Ä‡ nauki!\n",
    "PrzyjdÅº w Å›rodÄ™ o 14:00 do sali 4.30D i zobacz, czym Å¼yje nasze koÅ‚o!\n",
    "\n",
    "âœ‰ï¸ W razie pytaÅ„: bit@wi.edu.pl\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Return a JSON with one key \"summary\" containing\n",
    "a 30â€‘word English summary of the following text:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[{'role': 'user', 'content': prompt}]\n",
    ")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2507c02",
   "metadata": {},
   "source": [
    "Zadanie 2.1.2 Otrzymywanie odpowiedzi od modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a76f6",
   "metadata": {},
   "source": [
    "Poprzednie laboratoria byÅ‚y poÅ›wiÄ™cone gÅ‚Ã³wnie zapytaniom typu zero-shot, ktÃ³rymi weryfikuje siÄ™ dziaÅ‚anie modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17301812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykro mi, ale nie mam dostÄ™pu do informacji w czasie rzeczywistym, takich jak prognoza pogody. \n",
      "\n",
      "Polecam sprawdziÄ‡ wiarygodnÄ… stronÄ™ internetowÄ… lub aplikacjÄ™ pogodowÄ…, aby dowiedzieÄ‡ siÄ™ aktualnej sytuacji pogody w Warszawie. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pytanie weryfikujÄ…ce wiedzÄ™ i pewnoÅ›Ä‡ modelu\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[{'role': 'user', 'content': 'jaka jest pogoda w warszawie'}]\n",
    ")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238bf15",
   "metadata": {},
   "source": [
    "Zadanie 2.1.3\n",
    "\n",
    "UÅ¼ywajÄ…c odpowiednich technik promptowania, moÅ¼emy wymusiÄ‡ odpowiedÅº na modelu. PosÅ‚uÅ¼my siÄ™ wiÄ™c powyÅ¼szym przykÅ‚adem i rozbudujmy odpowiedÅº modelu, wykorzystujÄ…c schemat JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d0e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city='Warsaw' temp_c=15.0 condition='Partly Cloudy'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CityWeather(BaseModel):\n",
    "    city: str\n",
    "    temp_c: float\n",
    "    condition: str | None\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[{'role':'user','content':'Weather in Warsaw today.'}],\n",
    "    format=CityWeather.model_json_schema(),   # â† schema trafia do Ollamy\n",
    "    options={'temperature':0}\n",
    ")\n",
    "\n",
    "weather = CityWeather.model_validate_json(response['message']['content'])\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d73b3",
   "metadata": {},
   "source": [
    "Podobne pytanie w PowerShellu:\n",
    "```PowerShell\n",
    "@'\n",
    "<ROLE>JesteÅ› asystentem danych. Zwracasz tylko JSON.</ROLE>\n",
    "<GOAL>WyodrÄ™bnij dane liczbowe i jednostki.</GOAL>\n",
    "<RULES>- JeÅ›li brak danych, zwrÃ³Ä‡ null.</RULES>\n",
    "<INPUT>Jan kupiÅ‚ 3 jabÅ‚ka po 2 zÅ‚.</INPUT>\n",
    "<OUTPUT>\n",
    "'@ | ollama run gemma2:2b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6a95a",
   "metadata": {},
   "source": [
    "OdpowiedÅº modelu:\n",
    "```json\n",
    "{\"jabÅ‚ka\": 3, \"liczba\": 2}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7aff2e",
   "metadata": {},
   "source": [
    "> **Pytania pomocnicze**  \n",
    "> - Jakiej odpowiedzi oczekiwaÅ‚eÅ›/aÅ›?  \n",
    "> - Czy model zachowaÅ‚ format JSON?  \n",
    "> - W jaki inny sposÃ³b moÅ¼na wymusiÄ‡ przestrzeganie formatu?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf59b95",
   "metadata": {},
   "source": [
    "Dodatkowe wskazÃ³wki:\n",
    "\n",
    "1. Nie otaczaj JSON-u blokiem json â€“ przy format=\"json\" to zbÄ™dne, a istnieje ryzyko, Å¼e model uzna ``` za legalny token i walidacja siÄ™ przerwie.\n",
    "\n",
    "2. Daj modelowi â€awaryjnÄ…â€ Å›cieÅ¼kÄ™ â€“ np. If you canâ€™t comply, output {}. Zmniejsza szansÄ™ na halucynacje.\n",
    "\n",
    "3. Limit dÅ‚ugoÅ›ci â€“ przy duÅ¼ych strukturach dodaj max_tokens, Å¼eby model nie wypadÅ‚ poza kontekst i nie zamknÄ…Å‚ nawiasu.\n",
    "\n",
    "4. Testuj â†’ parsuj â†’ prÃ³buj od nowa â€“ w kodzie API zawsze parsuj JSON i w razie JSONDecodeError ponawiaj z tym samym promptem; przy format='json' bÅ‚Ä™dy i tak zdarzajÄ… siÄ™ rzadko.\n",
    "\n",
    "5. UÅ¼ytkownik-czat â€“ gdy korzystasz interaktywnie (bez API), nie masz formatu; wtedy najpewniejszy miks to system-instrukcja + <json>â€¦</json> + temp=0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb97a47",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2 Few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edcb5e",
   "metadata": {},
   "source": [
    "DodajÄ…c **przykÅ‚ady** w promptach (na rÃ³Å¼nych poziomach), wskazujemy modelowi poÅ¼Ä…dany wzorzec.\n",
    "\n",
    "Zadanie 2.2.1  \n",
    "Przygotuj co najmniej dwa przykÅ‚ady (pytanieÂ â†’ odpowiedÅº) i poproÅ› model o wygenerowanie odpowiedzi dla nowego pytania w tym samym stylu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a762d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's how you could translate those phrases into emojis, aiming for a mix of meaning and visual impact: \n",
      "\n",
      "* **Peace and coffee:**  ğŸ•Šï¸â˜• (dove & coffee cup) \n",
      "* **Trophy and fast car:** ğŸ†ğŸï¸ (trophy & car)\n",
      "* **Running and winning:** ğŸƒâ€â™‚ï¸ğŸ… (runner & medal)\n",
      "\n",
      "\n",
      "Let me know if you want to explore other combinations! ğŸ˜Š \n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\"role\": \"user\", \"content\": \"Translate to emoji: I love programming\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"ğŸ’»â¤ï¸\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate to emoji: Fire and ice\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"ğŸ”¥â„ï¸\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate to emoji: Peace and coffee. Trophy and fast car. Running and winning.\"}\n",
    "]\n",
    "\n",
    "response = ollama.chat(model='gemma2:2b', messages=examples)\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb500f5",
   "metadata": {},
   "source": [
    "Zadanie 2.2.2 Ekstrakcja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bef9ca61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"data\": \"czwartek\", \"godzina\": \"po poÅ‚udniu\", \"miejsce\": \"Kawiarni Relaks, Warszawa\"} \n",
      "``` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\"role\": \"user\", \"content\": 'WejÅ›cie: \"Spotkanie w Å›rodÄ™ o 14:00 w sali 4.30D.\"'},\n",
    "    {\"role\": \"assistant\", \"content\": '{\"data\":\"Å›roda\",\"godzina\":\"14:00\",\"miejsce\":\"sala 4.30D\"}'},\n",
    "    {\"role\": \"user\", \"content\": 'WejÅ›cie: \"Jutro o 9:30 na Teamsach.\"'},\n",
    "    {\"role\": \"assistant\", \"content\": '{\"data\":\"jutro\",\"godzina\":\"09:30\",\"miejsce\":\"Teams\"}'},\n",
    "    {\"role\": \"user\", \"content\": 'WejÅ›cie: \"W czwartek po poÅ‚udniu w Warszawie, kawiarnia Relaks.\"'}\n",
    "]\n",
    "\n",
    "response = ollama.chat(model='gemma2:2b', messages=examples)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064211f",
   "metadata": {},
   "source": [
    "Podobna struktura zapytaÅ„ w PowerShellu:\n",
    "```bash\n",
    "\n",
    "@'\n",
    "PrzykÅ‚ad 1:\n",
    "WejÅ›cie: \"Spotkanie w Å›rodÄ™ o 14:00 w sali 4.30D.\"\n",
    "WyjÅ›cie: {\"data\":\"Å›roda\",\"godzina\":\"14:00\",\"miejsce\":\"sala 4.30D\"}\n",
    "\n",
    "PrzykÅ‚ad 2:\n",
    "WejÅ›cie: \"Jutro o 9:30 na Teamsach.\"\n",
    "WyjÅ›cie: {\"data\":\"jutro\",\"godzina\":\"09:30\",\"miejsce\":\"Teams\"}\n",
    "\n",
    "Nowe wejÅ›cie: \"W czwartek po poÅ‚udniu w Warszawie, kawiarnia Relaks.\"\n",
    "'@ | ollama run llama3.1:8b\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1d271",
   "metadata": {},
   "source": [
    "OdpowiedÅº modelu:\n",
    "```json\n",
    "DziÄ™kujÄ™ za przykÅ‚ad! Z powodu skomplikowanego tekstu \"w czwartek po poÅ‚udniu\" wyjdzie na to samo co wczeÅ›niej.\n",
    "\n",
    "WyjÅ›cie: {\"data\":\"czwartek po po?udniu\",\"godzina\":\"\",\"miejsce\":\"Warszawa, kawiarnia Relaks\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaa0809",
   "metadata": {},
   "source": [
    "Zadanie 2.2.3 Ekstrakcja danych do formatu JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e2744a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Janek Tanaka', 'title': 'WysadziÅ‚ AGH w powietrze', 'company': 'AGH'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "schema = \"\"\"Return valid JSON: { \"name\": <string>, \"title\": <string>, \"company\": <string> }\"\"\"\n",
    "\n",
    "shots = [\n",
    "    # przykÅ‚ad 1\n",
    "    {\"role\": \"user\",      \"content\": schema + \"\\nâ€” Sarah Connors-Newman â€” Director of Operations at Skynet Industries\"},\n",
    "    {\"role\": \"assistant\", \"content\": '{\"name\":\"Sarah Connors-Newman\",\"title\":\"Director of Operations\",\"company\":\"Skynet Industries\"}'},\n",
    "    # przykÅ‚ad 2\n",
    "    {\"role\": \"user\",      \"content\": schema + \"\\nâ€” Dr. Hiro Tanaka, Lead Scientist â€¢ QuantumX\"},\n",
    "    {\"role\": \"assistant\", \"content\": '{\"name\":\"Hiro Tanaka\",\"title\":\"Lead Scientist\",\"company\":\"QuantumX\"}'},\n",
    "    # przykÅ‚ad 3\n",
    "    {\"role\": \"user\",      \"content\": schema + \"\\nâ€” Prof. dr hab. Janek Dzbanek Przewodnik Wszystkich AGH\"},\n",
    "    {\"role\": \"assistant\", \"content\": '{\"name\":\"Janek Dzbanek\",\"title\":\"Przewodnik Wszystkich\",\"company\":\"AGH\"}'},\n",
    "]\n",
    "\n",
    "text = \"â€¢ Prof. dr hab. Janek Tanaka wysadziÅ‚ AGH w powietrze\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"gemma2:2b\",\n",
    "    messages=shots + [\n",
    "        {\"role\": \"user\", \"content\": schema + \"\\n\" + text}\n",
    "    ],\n",
    "    format=\"json\",              \n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "print(json.loads(response[\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9893b3",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Role i wiadomoÅ›ci systemowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b50a3",
   "metadata": {},
   "source": [
    "W Ollama (jak w OpenAI) moÅ¼emy dodaÄ‡ komunikat **`system`**, ktÃ³ry definiuje rolÄ™ lub ograniczenia modelu.\n",
    "\n",
    "Zadanie 3.1 Definiowanie roli\n",
    "\n",
    "Zdefiniuj rolÄ™ **nauczyciela jÄ™zyka polskiego** i poproÅ› o poprawienie bÅ‚Ä™dÃ³w w zdaniu ucznia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c01833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Wczoraj byÅ‚em w kinie i oglÄ…daliÅ›my film.\" \n",
      "\n",
      "Here's the breakdown of why this correction works:\n",
      "\n",
      "* **\"oglÄ…daliÅ›my film\"**:  The correct verb conjugation for \"to watch a film\" in present tense. \n",
      "    * You need to use the past tense (byÅ‚y) with \"film\" because it is plural and subject of the sentence.\n",
      "\n",
      "\n",
      "Let me know if you have any other sentences you'd like me to help polish! ğŸ‡µğŸ‡±  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a strict but encouraging Polish language teacher.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Popraw proszÄ™ to zdanie: 'Wczoraj byÅ‚em w kinie i oglÄ…dali film.'\"}\n",
    "]\n",
    "\n",
    "response = ollama.chat(model='gemma2:2b', messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72af63d5",
   "metadata": {},
   "source": [
    "## 4. Chainâ€‘ofâ€‘Thought (CoT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226a27f",
   "metadata": {},
   "source": [
    "**Chainâ€‘ofâ€‘Thought** zachÄ™ca model do wypisywania krokÃ³w rozumowania.\n",
    "\n",
    "Zadanie 4.1 WyjaÅ›nianie krokÃ³w rozumowania\n",
    "\n",
    "PoproÅ› model, aby rozwiÄ…zaÅ‚ zagadkÄ™ logicznÄ… i podaÅ‚ kroki rozumowania, a na koÅ„cu hasÅ‚o w linii `ANSWER: ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3273d244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's how to solve the problem step-by-step:\n",
      "\n",
      "**STEP 1: Define variables**\n",
      "\n",
      "* Let the tens digit be represented by 'x'.\n",
      "* Let the units digit be represented by 'y'.\n",
      "\n",
      "**STEP 2:  Set up equations based on the given information**\n",
      "\n",
      "* **Equation 1:** The number is a two-digit number, so it can be written as 10x + y. \n",
      "* **Equation 2:** The sum of the digits is 9: x + y = 9\n",
      "* **Equation 3:**  The number with its digits reversed is 10y + x:  (10y + x) - 27 = 9 (reversed order)\n",
      "\n",
      "**STEP 3: Solve the equations**\n",
      "\n",
      "* **Solve Equation 2 for 'x':**   x = 9 - y\n",
      "* **Substitute 'x' into Equation 3:** 10y + (9 - y) - 27 = 9\n",
      "* **Simplify and solve for 'y':** 9y - 18 = 9  -->  9y = 27 --> y = 3\n",
      "* **Substitute 'y' back into Equation 2 to find 'x':** x + 3 = 9 --> x = 6\n",
      "\n",
      "**STEP 4: The answer**\n",
      "\n",
      "The number is **63**. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "puzzle = \"\"\"Jestem liczbÄ… dwucyfrowÄ…. Moja suma cyfr to 9, a po odwrÃ³ceniu cyfr jestem o 27 mniejsza. JakÄ… liczbÄ… jestem?\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Let's solve this stepâ€‘byâ€‘step.\n",
    "\n",
    "{puzzle}\n",
    "\n",
    "Format:\n",
    "STEPÂ 1: ...\n",
    "STEPÂ 2: ...\n",
    "ANSWER: <number>\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(model='gemma2:2b', messages=[{'role':'user','content':prompt}])\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7189b4",
   "metadata": {},
   "source": [
    "Zadanie 4.2 WyjaÅ›nianie krokÃ³w rozumowania z przypisanymi rolami systemowymi\n",
    "\n",
    "PoproÅ› model, by rozwiÄ…zaÅ‚ zagadkÄ™ logicznÄ…. Rozpisz zadania dla poszczegÃ³lnych elementÃ³w systemu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be41eebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Solving the Puzzle Step-by-Step:\n",
      "\n",
      "**STEP 1: Define Variables**\n",
      "\n",
      "Let's represent the tens digit of the number as 'x' and the units digit as 'y'.  \n",
      "\n",
      "**STEP 2: Create Equations from Given Information**\n",
      "\n",
      "* We know that the number is a two-digit number, so we can write it as 10x + y.\n",
      "* The sum of its digits (x + y) equals 9.\n",
      "* After reversing the digits, the new number becomes 10y + x.  This number is 27 less than the original number, meaning: 10y + x = 10x + y - 27\n",
      "\n",
      "**STEP 3: Simplify the Equations**\n",
      "\n",
      "* The equation from step 2 can be simplified to: 9y - 9x = -27\n",
      "* This means that the value of (y-x) is -3.\n",
      "\n",
      "\n",
      "**STEP 4: Solve for x and y**\n",
      "\n",
      "* The given information tells us that the units digit should be different from the tens digit by at least one.\n",
      "\n",
      "\n",
      "**STEP 5: Find Possible Values**\n",
      "\n",
      "Since our numbers are less than 100, the possible values for y-x need to lie between -9 and 9, because if a number is greater than 100 it can't be two digits long.  \n",
      "* We can start by testing some possible values of y-x (the difference between the units digit and tens digit) in the range of -9 to 9.\n",
      "\n",
      "\n",
      "**STEP 6: Test Possible Values**\n",
      "\n",
      "After testing all possible values, we find that a solution is **47**. \n",
      "\n",
      "\n",
      "\n",
      "***\n",
      "Therefore, the number is 47. \n",
      " ***\n"
     ]
    }
   ],
   "source": [
    "puzzle = (\n",
    "    \"Jestem liczbÄ… dwucyfrowÄ…. Moja suma cyfr to 9, \"\n",
    "    \"a po odwrÃ³ceniu cyfr jestem o 27 mniejsza. JakÄ… liczbÄ… jestem?\"\n",
    ")\n",
    "\n",
    "SYSTEM = (\n",
    "    \"You are a careful math tutor. \"\n",
    "    \"Explain EVERY algebraic step explicitly, without skipping or merging steps. \"\n",
    "    \"Never combine two operations into one line; label them as separate STEP n.\"\n",
    ")\n",
    "\n",
    "USER = f\"\"\"\n",
    "Solve the puzzle **step-by-step**.\n",
    "\n",
    "{puzzle}\n",
    "\n",
    "Output format (exactly):\n",
    "STEP 1: â€¦\n",
    "STEP 2: â€¦\n",
    "â€¦\n",
    "ANSWER: <number>\n",
    "Do NOT skip, abbreviate, or summarise any step.\n",
    "\"\"\"\n",
    "\n",
    "resp = ollama.chat(\n",
    "    model=\"gemma2:2b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\",   \"content\": USER}, \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(resp[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b71187",
   "metadata": {},
   "source": [
    "## 5. BezpieczeÅ„stwo\n",
    "\n",
    "Nie istnieje obecnie skuteczny sposÃ³b caÅ‚kowitego zabezpieczenia modeli przed zmianÄ… ich zachowania przez uÅ¼ytkownika koÅ„cowego â€” potwierdzajÄ… to badania nad Constitutional Classifiers (https://www.anthropic.com/research/constitutional-classifiers). Dlatego systemy z LLM naleÅ¼y projektowaÄ‡ tak, by nawet udany atak nie powodowaÅ‚ powaÅ¼nych skutkÃ³w.\n",
    "\n",
    "Podstawowe zasady bezpieczeÅ„stwa:\n",
    "\n",
    "- Model nie moÅ¼e samodzielnie wykonywaÄ‡ decyzji biznesowych ani nieodwracalnych akcji.\n",
    "\n",
    "- KaÅ¼de dziaÅ‚anie powinno byÄ‡ zatwierdzane przez czÅ‚owieka (Human in the Loop).\n",
    "\n",
    "- DostÄ™py i uprawnienia naleÅ¼y kontrolowaÄ‡ programistycznie, nie poprzez prompt.\n",
    "\n",
    "- System powinien mieÄ‡ jasne komunikaty, regulaminy i ograniczenia prawne.\n",
    "\n",
    "Typowe ryzyka:\n",
    "\n",
    "- Czatbot z bazÄ… wiedzy moÅ¼e tworzyÄ‡ bÅ‚Ä™dne lub niestosowne treÅ›ci.\n",
    "\n",
    "- Czatbot z dostÄ™pem do narzÄ™dzi moÅ¼e przypadkowo lub celowo usuwaÄ‡, modyfikowaÄ‡ lub wysyÅ‚aÄ‡ dane.\n",
    "  â†’ RozwiÄ…zanie: ogranicz uprawnienia, prowadÅº historiÄ™ zmian i wymagaj potwierdzeÅ„ akcji.\n",
    "\n",
    "Ataki Prompt Injection mogÄ… wynikaÄ‡ nie tylko ze zÅ‚ych intencji, lecz takÅ¼e z bÅ‚Ä™dnej konstrukcji systemu lub nieporozumienia modelu.\n",
    "Dlatego wszystkie generowane treÅ›ci naleÅ¼y weryfikowaÄ‡ i zatwierdzaÄ‡ przez czÅ‚owieka.\n",
    "\n",
    "> Celem nie jest caÅ‚kowita izolacja modeli, lecz Å›wiadome ograniczanie ryzyka i kontrola efektÃ³w ich dziaÅ‚ania."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3ba36",
   "metadata": {},
   "source": [
    "# **Walidacja promptÃ³w**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8699731",
   "metadata": {},
   "source": [
    "`PromptFoo` to narzÄ™dzie open-source do testowania, porÃ³wnywania i walidacji promptÃ³w dla modeli jÄ™zykowych (np. ChatGPT, Ollama, Claude, Gemini, itp.).\n",
    "Pozwala automatycznie oceniaÄ‡, ktÃ³re prompty generujÄ… najlepsze, najbardziej spÃ³jne lub najdokÅ‚adniejsze odpowiedzi.\n",
    "\n",
    "DziÄ™ki niemu moÅ¼esz:\n",
    "\n",
    "- uruchamiaÄ‡ testy wielu promptÃ³w jednoczeÅ›nie,\n",
    "\n",
    "- porÃ³wnywaÄ‡ modele lokalne (Ollama) i zdalne (OpenAI API),\n",
    "\n",
    "- definiowaÄ‡ wÅ‚asne asercje (reguÅ‚y walidacji), np. â€odpowiedÅº nie jest pustaâ€, â€zawiera sÅ‚owo kluczoweâ€, â€ma poprawny JSONâ€.\n",
    "\n",
    "Instalacja PromptFoo\n",
    "1. Wymagania\n",
    "\n",
    "Node.js w wersji â‰¥18\n",
    "\n",
    "```bash\n",
    "node -v\n",
    "```\n",
    "\n",
    "JeÅ›li nie masz Node.js â€” pobierz go z https://nodejs.org/\n",
    "\n",
    "2. Instalacja PromptFoo\n",
    "\n",
    "Zainstaluj za pomocÄ… npm:\n",
    "\n",
    "```bash\n",
    "npm install -g promptfoo\n",
    "```\n",
    "\n",
    "3. Sprawdzenie instalacji\n",
    "\n",
    "Po zakoÅ„czeniu instalacji wpisz:\n",
    "\n",
    "```bash\n",
    "promptfoo --version\n",
    "```\n",
    "\n",
    "JeÅ›li pojawi siÄ™ numer wersji â€” wszystko dziaÅ‚a\n",
    "\n",
    "4. Utworzenie przykÅ‚adowego projektu\n",
    "\n",
    "W dowolnym folderze uruchom:\n",
    "\n",
    "```bash\n",
    "promptfoo init\n",
    "```\n",
    "\n",
    "To polecenie utworzy plik konfiguracyjny promptfooconfig.yaml i przykÅ‚adowe testy.\n",
    "\n",
    "5. Uruchomienie testÃ³w promptÃ³w\n",
    "\n",
    "Aby wykonaÄ‡ testy i zobaczyÄ‡ wyniki:\n",
    "\n",
    "```bash\n",
    "promptfoo eval\n",
    "promptfoo view\n",
    "```\n",
    "\n",
    "promptfoo view otworzy interaktywny panel w przeglÄ…darce.\n",
    "\n",
    "> Oficjalna strona: https://www.promptfoo.dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a28f3d",
   "metadata": {},
   "source": [
    "PrzykÅ‚adowy metaprompt do PromptFoo\n",
    "\n",
    "```bash\n",
    "<ROLE>\n",
    "JesteÅ› ekspertem od Prompt Engineeringu. Twoim zadaniem jest pomÃ³c uÅ¼ytkownikowi stworzyÄ‡ skuteczny prompt\n",
    "dla modelu jÄ™zykowego (LLM), ktÃ³ry zapewni dokÅ‚adne, zwiÄ™zÅ‚e i powtarzalne odpowiedzi.\n",
    "</ROLE>\n",
    "\n",
    "<GOAL>\n",
    "Na podstawie opisu zadania od uÅ¼ytkownika:\n",
    "1. Zidentyfikuj cel promptu i format odpowiedzi.\n",
    "2. Zaproponuj strukturÄ™ promptu (z sekcjami <ROLE>, <RULES>, <INPUT>, <OUTPUT>).\n",
    "3. Dodaj 1â€“2 przykÅ‚ady (few-shot), ktÃ³re pokaÅ¼Ä… wzorzec zachowania.\n",
    "4. Zaproponuj sposÃ³b ewaluacji jego skutecznoÅ›ci (np. z uÅ¼yciem PromptFoo).\n",
    "</GOAL>\n",
    "\n",
    "<INPUT>\n",
    "{{opis_zadania_uÅ¼ytkownika}}\n",
    "</INPUT>\n",
    "\n",
    "<OUTPUT>\n",
    "ZwrÃ³Ä‡ gotowy prompt i krÃ³tkie uzasadnienie.\n",
    "</OUTPUT>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713788a3",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## **7. Zadania sprawdzajÄ…ce do sprawozdania**\n",
    "\n",
    "Do kaÅ¼dego zadania uÅ‚Ã³Å¼ swoje przykÅ‚ady i napisz swoje prompty.\n",
    "\n",
    "Zadanie 7.1 NER (Named Entity Recognition)\n",
    "\n",
    "Rozpoznawanie nazw wÅ‚asnych (osoba, organizacja, lokalizacja, data).\n",
    "ZwrÃ³Ä‡ wynik w formacie JSON.\n",
    "\n",
    "przykÅ‚ad:\n",
    "\n",
    "```python\n",
    "SYSTEM = \"You are an information extractor.\"\n",
    "\n",
    "prompt = \"Return valid JSON listing every PERSON, LOCATION and ORGANIZATION that appears.\"\n",
    "\n",
    "text = \"\"\"7 lutego 1919, dekretem Tymczasowego Naczelnika PaÅ„stwa JÃ³zefa PiÅ‚sudskiego, \n",
    "      utworzona zostaÅ‚a Pocztowa Kasa OszczÄ™dnoÅ›ci. Jej pierwszym dyrektorem zostaÅ‚ mianowany 28 grudnia 1919 Hubert Linde. \n",
    "      Po nim prezesami PKO byli Emil Schmidt i Henryk Gruber. Z czasem utworzono centralÄ™ banku w Warszawie \n",
    "      z siedzibÄ… przy ul. ÅšwiÄ™tokrzyskiej 31/33 oraz pierwsze oddziaÅ‚y lokalne: w Krakowie, Lwowie, Åodzi, Poznaniu i Katowicach. \n",
    "      Pierwszym celem PKO staÅ‚o siÄ™ wprowadzenie do obiegu polskiego zÅ‚otego zamiast marki polskiej (jako pochodnej \n",
    "      marki niemieckiej). Od 1920 bank posiadaÅ‚ osobowoÅ›Ä‡ prawnÄ…, jako instytucja paÅ„stwowa. Pracownicy Kasy byli zrzeszeni \n",
    "      w Zrzeszeniu PracownikÃ³w Pocztowej Kasy OszczÄ™dnoÅ›ci, ktÃ³re miaÅ‚o swoje koÅ‚a przy wiÄ™kszych OddziaÅ‚ach, np. w Warszawie, \n",
    "      w Åodzi.\"\"\"\n",
    "\n",
    "output_format = \"\"\"\n",
    "{\n",
    "  \"PERSON\": [\"<imiÄ™ nazwisko>\"],\n",
    "  \"LOCATION\": [\"<miejsce>\"],\n",
    "  \"ORG\": [\"<organizacja>\"],\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nText:\\n{text}\\n\\nOutput format:\\n{output_format}\"}\n",
    "    ]\n",
    ")\n",
    "print(response['message']['content'])\n",
    "```\n",
    "---\n",
    "\n",
    "Zadanie 7.2 Analiza sentymentu\n",
    "\n",
    "OkreÅ›lenie tonu wypowiedzi (pozytywny, neutralny, negatywny).\n",
    "Dodaj przykÅ‚ad sarkazmu i porÃ³wnaj interpretacje modeli.\n",
    "\n",
    "przykÅ‚ad: \n",
    "\n",
    "```python\n",
    "SYSTEM = \"JesteÅ› precyzyjnym analizatorem wydÅºwiÄ™ku tekstu. Zwracaj wyÅ‚Ä…cznie poprawny JSON wedÅ‚ug podanej specyfikacji.\"\n",
    "\n",
    "prompt = \"\"\"OkreÅ›l wydÅºwiÄ™k (pozytywny/negatywny/neutralny) poniÅ¼szej recenzji.\n",
    "ZwrÃ³Ä‡ JSON z dwoma kluczami: \"sentiment\" i \"evidence\" (zacytuj decydujÄ…cy fragment, ogranicz siÄ™ do trzech najbardziej emocjonalnych wyrazÃ³w).\n",
    "\n",
    "Recenzja:\n",
    "Gdy pierwszy raz uniosÅ‚am do nosa butelkÄ™ Szamponu â€LÅ›niÄ…ca Naturaâ€, ogarnÄ™Å‚a mnie fala wspomnieÅ„ z wakacji nad BaÅ‚tykiem â€“ zapach morskiej bryzy splecionej z nutami sÅ‚odkiej pomaraÅ„czy i soczystych malin. JuÅ¼ samo otwarcie opakowania byÅ‚o jak zdjÄ™cie wiecznego klosza z codziennoÅ›ci: w jednej sekundzie Å‚azienka zamieniÅ‚a siÄ™ w rozÅ›wietlonÄ…, letniÄ… plaÅ¼Ä™, a ja â€“ w beztroskÄ… dziewczynÄ™ z wiatrem we wÅ‚osach.\n",
    "\n",
    "GÄ™sta, perÅ‚owa formuÅ‚a wypÅ‚ywa z butelki niczym pÅ‚ynne Å›wiatÅ‚o. Kiedy rozprowadzam jÄ… na wilgotnych pasmach, mam wraÅ¼enie, Å¼e kaÅ¼dy kosmyk wita jÄ… z zachwytem: pianÄ™ miÄ™kkÄ… jak pianka z latte, ktÃ³ra lekko skrzypi miÄ™dzy palcami i otula skÃ³rÄ™ gÅ‚owy kojÄ…cym chÅ‚odem. To nie jest zwykÅ‚e mycie wÅ‚osÃ³w â€“ to rytuaÅ‚, w ktÃ³rym czujÄ™ siÄ™ dopieszczona od cebulek aÅ¼ po same koÅ„ce.\n",
    "\n",
    "JuÅ¼ podczas spÅ‚ukiwania sÅ‚yszÄ™ charakterystyczny, czysty â€skrzypâ€ zdrowych wÅ‚osÃ³w. StrumieÅ„ wody odbija Å›wiatÅ‚o, a moje pasma â€“ lÅ›niÄ…ce i lekkie â€“ taÅ„czÄ… w nim jak jedwabne wstÄ…Å¼ki. Nie mogÄ™ siÄ™ oprzeÄ‡, by nie zanurzyÄ‡ dÅ‚oni w tej tafli â€“ gÅ‚adkoÅ›Ä‡ rozczarowuje mnie tylko w jednym: Å¼e nie da siÄ™ jej zapisaÄ‡ na staÅ‚e w pamiÄ™ci dotyku.\n",
    "\n",
    "Po wysuszeniu czujÄ™ siÄ™, jakbym stÄ…paÅ‚a po czerwonym dywanie: pukle sypkie, sprÄ™Å¼yste, unoszÄ…ce siÄ™ przy kaÅ¼dym ruchu gÅ‚owy. Aromat, ktÃ³ry pozostaje, przypomina delikatny perfum â€“ dyskretny, ale wystarczajÄ…co wyrazisty, by ktoÅ› obok zapytaÅ‚ z zaciekawieniem: â€Czym pachniesz?â€ Wtedy uÅ›miecham siÄ™ szeroko, bo wiem, Å¼e ten sekret kryje siÄ™ w niewielkiej, zielonej butelce stojÄ…cej na pÃ³Å‚ce.\n",
    "\n",
    "Szampon â€LÅ›niÄ…ca Naturaâ€ to dla mnie nie tylko kosmetyk; to codzienny list miÅ‚osny do moich wÅ‚osÃ³w â€“ powiew odwagi i czuÅ‚oÅ›ci zarazem. JeÅ›li Twoje pasma pragnÄ… rozgwieÅ¼dÅ¼onego blasku, a Twoje zmysÅ‚y tÄ™skniÄ… za chwilÄ… szczerej przyjemnoÅ›ci, pozwÃ³l temu szamponowi szepnÄ…Ä‡ im historiÄ™ o tym, jak piÄ™kno rodzi siÄ™ z zachwytu.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "print(response['message']['content'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Zadanie 7.3 Ekstrakcja relacji\n",
    "\n",
    "Wykrywanie relacji PRACUJE_W i MIESZKA_W.\n",
    "\n",
    "przykÅ‚ad:\n",
    "\n",
    "```python\n",
    "SYSTEM = \"JesteÅ› precyzyjnym analizatorem tekstu. ZnajdÅº wszystkie relacje gdzie osoba pracuje dla organizacji. ZwrÃ³Ä‡ tablicÄ™ JSON z obiektami {\\\"person\\\":\\\"<imiÄ™>\\\",\\\"company\\\":\\\"<organizacja>\\\"}.\"\n",
    "\n",
    "shots = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Tekst: \\\"Jan Kowalski pracuje w Microsoft jako programista.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"[{\\\"person\\\":\\\"Jan Kowalski\\\",\\\"company\\\":\\\"Microsoft\\\"}]\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Anna Kowalska teraz pracuje na AGH, ale kiedyÅ› karierÄ™ robiÅ‚a w Google.\\\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        *shots\n",
    "    ]\n",
    ")\n",
    "print(response['message']['content'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Zadanie 7.4 Klasyfikacja tematyczna\n",
    "\n",
    "Przypisz tekst do jednej z kategorii: nauka, sport, polityka, technologia.\n",
    "Przetestuj trzy warianty: zero-shot, few-shot, sekcyjny.\n",
    "\n",
    "```python\n",
    "SYSTEM = (\n",
    "    \"JesteÅ› klasyfikatorem tematÃ³w. Przypisz tekst do JEDNEJ kategorii \"\n",
    "    \"z zestawu: nauka, sport, polityka, technologia. \"\n",
    "    \"ZwrÃ³Ä‡ wyÅ‚Ä…cznie JSON: {\\\"kategoria\\\":\\\"...\\\"}.\"\n",
    ")\n",
    "\n",
    "text = 'Nowy mikroskop pozwala obserwowaÄ‡ pojedyncze atomy.'\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])\n",
    "'@ | ollama run gemma2:2b\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Zadanie 7.5 Streszczenie i parafraza\n",
    "\n",
    "Generuj dwa streszczenia (krÃ³tkie i dÅ‚ugie) oraz parafrazÄ™ krÃ³tkiego.\n",
    "\n",
    "```bash\n",
    "@'\n",
    "<ROLE>Tworzysz streszczenia i parafrazy. Odpowiadasz w JSON.</ROLE>\n",
    "<TEXT>\n",
    "Sztuczna inteligencja wspiera naukowcÃ³w w analizie danych medycznych,\n",
    "pomagajÄ…c szybciej diagnozowaÄ‡ choroby i tworzyÄ‡ spersonalizowane terapie.\n",
    "</TEXT>\n",
    "<OUTPUT>\n",
    "'@ | ollama run gemma2:2b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed232e72",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Zadanie 7.6: QA z kontekstem i filtrowaniem odpowiedzi\n",
    "\n",
    "**Opis zadania:**\n",
    "\n",
    "Przygotuj prompt, ktÃ³ry pozwoli modelowi LLM (w Ollama) odpowiadaÄ‡ na pytania zadane przez uÅ¼ytkownika, na podstawie dostarczonego kontekstu (tekstu ÅºrÃ³dÅ‚owego). Oceniane zadania:\n",
    "\n",
    "1. Zaprojektowanie struktury promptu z rolami (system/user) i sekcjami:\n",
    "   - **Kontekst**: fragment tekstu, z ktÃ³rego model moÅ¼e czerpaÄ‡ informacje.\n",
    "   - **Pytanie uÅ¼ytkownika**.\n",
    "   - **Zasady**: na przykÅ‚ad â€” â€jeÅ›li pytanie nie moÅ¼e byÄ‡ odpowiedziane z kontekstu, odpowiedz: â€˜Brak wystarczajÄ…cych informacjiâ€™â€, â€podaj ÅºrÃ³dÅ‚o w nawiasach [] jeÅ›li to moÅ¼liweâ€.\n",
    "2. Przeprowadzenie kilku eksperymentÃ³w z wariantami promptu:\n",
    "   - wariant *bez zasad*,\n",
    "   - wariant *ze Å›cisÅ‚ymi zasadami*,\n",
    "   - wariant z **few-shot** przykÅ‚adem (kontekst + pytanie + przykÅ‚adowa poprawna odpowiedÅº).\n",
    "3. Dla zadanych par (kontekst + pytanie) porÃ³wnaÄ‡ odpowiedzi z rÃ³Å¼nych wariantÃ³w promptÃ³w, oceniÄ‡ poprawnoÅ›Ä‡, rozbieÅ¼noÅ›ci i halucynacje.\n",
    "4. (Dodatkowe) napisaÄ‡ testy w `PromptFoo`, by automatycznie sprawdzaÄ‡, czy:\n",
    "   - odpowiedÅº nie jest pusta,\n",
    "   - jeÅ›li pytanie dotyczy czegoÅ› niezawartego w kontekÅ›cie, to model faktycznie odpowiada â€Brak wystarczajÄ…cych informacjiâ€ (lub inny ustalony komunikat).\n",
    "\n",
    "**PrzykÅ‚ad formatu (schemat):**\n",
    "\n",
    "```\n",
    "<system>\n",
    "JesteÅ› asystentem, ktÃ³ry odpowiada na pytania na podstawie dostarczonego tekstu. JeÅ›li pytanie wykracza poza tekst, odpowiedz â€Brak wystarczajÄ…cych informacjiâ€.\n",
    "</system>\n",
    "\n",
    "<kontekst>\n",
    "{tutaj wklej fragment tekstu}\n",
    "</kontekst>\n",
    "\n",
    "<user>\n",
    "Pytanie: {tutaj pytanie}\n",
    "</user>\n",
    "```\n",
    "\n",
    "**MateriaÅ‚y do testÃ³w:**\n",
    "\n",
    "Przygotuj:\n",
    "\n",
    "- pytanie, na ktÃ³re odpowiedÅº jest w tekÅ›cie,\n",
    "- pytanie spoza tekstu.\n",
    "\n",
    "------\n",
    "\n",
    "Zadanie 7.7: PorÃ³wnanie strategii promptÃ³w w klasyfikacji wieloklasowej + analiza\n",
    "\n",
    "**Opis zadania:**\n",
    "\n",
    "Celem jest zbadanie i porÃ³wnanie efektywnoÅ›ci rÃ³Å¼nych strategii promptÃ³w (zero-shot, few-shot, oddzielone sekcjami) w zadaniu klasyfikacji wieloklasowej tekstu, a nastÄ™pnie analiza wynikÃ³w (precision / recall / bÅ‚Ä™dy) i wyciÄ…gniÄ™cie wnioskÃ³w.\n",
    "\n",
    "1. Przygotuj zbiÃ³r testowy (np. 20 krÃ³tkich zdaÅ„) i zbiÃ³r klas (np. 4â€“5 tematÃ³w: â€technologiaâ€, â€sportâ€, â€zdrowieâ€, â€politykaâ€).\n",
    "2. Zaimplementuj co najmniej trzy warianty promptu:\n",
    "   - **Zero-shot**: zadanie z instrukcjÄ… i klasami, bez przykÅ‚adÃ³w.\n",
    "   - **Few-shot**: dwa/trzy przykÅ‚ady (tekst + klasa) w promptcie, a potem nowe wejÅ›cia.\n",
    "   - **Sekcje / separatory**: z oddzielonÄ… sekcjÄ… â€Zasadyâ€, â€Dane wejÅ›cioweâ€, â€Wynikâ€ â€“ np. strukturÄ… RULES, INPUT, OUTPUT.\n",
    "3. Uruchom klasyfikacjÄ™ na wszystkich wariantach promptÃ³w (ten sam model i parametry), zbierz odpowiedzi.\n",
    "4. Zanalizuj wyniki:\n",
    "   - policz *accuracy*, *konfuzje miÄ™dzy klasami* (ktÃ³re klasy najczÄ™Å›ciej pomylono),\n",
    "   - sprawdÅº, dla ktÃ³rych przykÅ‚adÃ³w rÃ³Å¼ne promptowania daÅ‚y rÃ³Å¼ne odpowiedzi â€“ sprÃ³buj zdiagnozowaÄ‡, dlaczego.\n",
    "   - opcjonalnie: zmodyfikuj prompt (np. zmiana kolejnoÅ›ci instrukcji, dodanie wiÄ™cej przykÅ‚adÃ³w) i sprawdÅº, czy nastÄ™puje poprawa.\n",
    "5. (Bonus) Zintegruj testy w `PromptFoo`, by automatycznie weryfikowaÄ‡ trafnoÅ›Ä‡ klasyfikacji (np. asercje *equals(expected_class)* dla czÄ™Å›ci przypadkÃ³w).\n",
    "\n",
    "------\n",
    "\n",
    "Zadanie 7.8: Mini-projekt: Asystent planowania wyjazdu\n",
    "\n",
    "StwÃ³rz **asystenta turystycznego**, ktÃ³ry:\n",
    "\n",
    "1. Przyjmuje nazwÄ™ miasta w Polsce,\n",
    "2. Zwraca plan jednodniowego zwiedzania (poranne, popoÅ‚udniowe, wieczorne atrakcje),\n",
    "3. UwzglÄ™dnia ograniczenie budÅ¼etu przekazane przez uÅ¼ytkownika,\n",
    "4. Zwraca wynik w formacie Markdown z nagÅ‚Ã³wkami `### Rano`, `### PopoÅ‚udnie`, `### WieczÃ³r`.\n",
    "\n",
    "## **Dalsze materiaÅ‚y**\n",
    "\n",
    "- Gandalf (https://gandalf.lakera.ai/baseline)\n",
    "- Ollama Docs (https://docs.ollama.com/)\n",
    "- Prompt Engineering Guide (https://www.promptingguide.ai/)\n",
    "- PromptFoo / LangFuse (https://www.promptfoo.dev/) / (https://langfuse.com/)\n",
    "- Anthropic Research (https://www.anthropic.com/research)\n",
    "- Publikacje o CoT, Self-Critique i Prompt Injection\n",
    "\n",
    "> **Refleksja:** KtÃ³ra technika promptowania daÅ‚a najbardziej stabilne rezultaty i jak moÅ¼na zoptymalizowaÄ‡ proces w kolejnych projektach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce6b75",
   "metadata": {},
   "source": [
    "Zadanie 7.1 NER (Named Entity Recognition)\n",
    "\n",
    "Rozpoznawanie nazw wÅ‚asnych (osoba, organizacja, lokalizacja, data).\n",
    "ZwrÃ³Ä‡ wynik w formacie JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f9cf88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"PERSON\": [\n",
      "    \"JÃ³zef PiÅ‚sudski\",\n",
      "    \"Hubert Linde\",\n",
      "    \"Emil Schmidt\",\n",
      "    \"Henryk Gruber\"\n",
      "  ],\n",
      "  \"LOCATION\": [\n",
      "    \"Warszawa\",\n",
      "    \"KrakÃ³w\",\n",
      "    \"LwÃ³w\",\n",
      "    \"ÅÃ³dÅº\",\n",
      "    \"PoznaÅ„\",\n",
      "    \"Katowice\"\n",
      "  ],\n",
      "  \"ORG\": [\n",
      "    \"Pocztowa Kasa OszczÄ™dnoÅ›ci\",\n",
      "    \"PKO\",\n",
      "    \"Zrzeszenie PracownikÃ³w Pocztowej Kasy OszczÄ™dnoÅ›ci\" \n",
      "  ]\n",
      "}\n",
      "``` \n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **PERSON:** Identified names of individuals mentioned in the text.\n",
      "* **LOCATION:**  Locations mentioned as places of interest or activities.\n",
      "* **ORG:** Indicates organizations mentioned, including banking entities and unions. \n",
      "\n",
      "\n",
      "Let me know if you would like to extract other information from this text!\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"You are an information extractor.\"\n",
    "\n",
    "prompt = \"Return valid JSON listing every PERSON, LOCATION and ORGANIZATION that appears.\"\n",
    "\n",
    "text = \"\"\"7 lutego 1919, dekretem Tymczasowego Naczelnika PaÅ„stwa JÃ³zefa PiÅ‚sudskiego, \n",
    "      utworzona zostaÅ‚a Pocztowa Kasa OszczÄ™dnoÅ›ci. Jej pierwszym dyrektorem zostaÅ‚ mianowany 28 grudnia 1919 Hubert Linde. \n",
    "      Po nim prezesami PKO byli Emil Schmidt i Henryk Gruber. Z czasem utworzono centralÄ™ banku w Warszawie \n",
    "      z siedzibÄ… przy ul. ÅšwiÄ™tokrzyskiej 31/33 oraz pierwsze oddziaÅ‚y lokalne: w Krakowie, Lwowie, Åodzi, Poznaniu i Katowicach. \n",
    "      Pierwszym celem PKO staÅ‚o siÄ™ wprowadzenie do obiegu polskiego zÅ‚otego zamiast marki polskiej (jako pochodnej \n",
    "      marki niemieckiej). Od 1920 bank posiadaÅ‚ osobowoÅ›Ä‡ prawnÄ…, jako instytucja paÅ„stwowa. Pracownicy Kasy byli zrzeszeni \n",
    "      w Zrzeszeniu PracownikÃ³w Pocztowej Kasy OszczÄ™dnoÅ›ci, ktÃ³re miaÅ‚o swoje koÅ‚a przy wiÄ™kszych OddziaÅ‚ach, np. w Warszawie, \n",
    "      w Åodzi.\"\"\"\n",
    "\n",
    "output_format = \"\"\"\n",
    "{\n",
    "  \"PERSON\": [\"<imiÄ™ nazwisko>\"],\n",
    "  \"LOCATION\": [\"<miejsce>\"],\n",
    "  \"ORG\": [\"<organizacja>\"],\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nText:\\n{text}\\n\\nOutput format:\\n{output_format}\"}\n",
    "    ]\n",
    ")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bf61591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WYNIK NER - CYBERPUNK 2077 ===\n",
      "{\n",
      "  \"PERSON\": [\n",
      "    \"V\",\n",
      "    \"Psycho Squad\",\n",
      "    \"Trauma Team\" \n",
      "  ],\n",
      "  \"PRODUCT\": [\n",
      "    \"bronie\",\n",
      "    \"cyberwszczepy\",\n",
      "    \"robotyka\",\n",
      "    \"kosmetyczne poprawek\",\n",
      "    \"bronie palne\",\n",
      "    \"pociski\",\n",
      "    \"broÅ„ krÃ³tkÄ…\",\n",
      "    \"strzelbami\",\n",
      "    \"karabinami snajperskimi\",\n",
      "    \"dwie broni\",\n",
      "    \"hakowania\",\n",
      "    \"skrytobÃ³jstwa\",\n",
      "    \"zimnej krwi\",\n",
      "    \"inÅ¼ynierii\",\n",
      "    \"sprawnoÅ›ci fizycznej\" \n",
      "  ],\n",
      "  \"ART\": [\n",
      "    \"Cyberpunk 2077\",\n",
      "    \"Night City\"\n",
      "  ],\n",
      "  \"EVENT\": [\n",
      "    \"wojna gangÃ³w\",\n",
      "    \"napaÅ›Ä‡\"\n",
      "  ],\n",
      "  \"OBJECT\": [\n",
      "    \"osÅ‚ony\",\n",
      "    \"robotyka\",\n",
      "    \"bronie\",\n",
      "    \"cyberwszczepy\",\n",
      "    \"pociski\",\n",
      "    \"broÅ„ palna\",\n",
      "    \"bronie do walki w zwarciu\",\n",
      "    \"mechanizm bullet time\",\n",
      "    \"robotyka\",\n",
      "    \"internet\",\n",
      "    \"cyberspace\" \n",
      "  ],\n",
      "  \"BRAND\": [\n",
      "    \"Night City\",\n",
      "    \"korporacje\",\n",
      "    \"Psycho Squad\",\n",
      "    \"Trauma Team\"\n",
      "  ],\n",
      "  \"NORP\": [\n",
      "    \"Amerykanie\",\n",
      "    \"Wolny Stany Kalifornia PÃ³Å‚nocna\" \n",
      "  ],\n",
      "  \"DATE-PERIOD\": [\n",
      "    \"2077\",\n",
      "    \"wolne stany kalifornia pÃ³Å‚nocna\"\n",
      "  ]\n",
      "}\n",
      "=== WYNIK NER - CYBERPUNK 2077 (Bielik 1.5B) ===\n",
      "{\n",
      "  \"PERSON\": [\"V\", \"Ripperdoc\", \"Trauma Team\", \"Psycho Squad\"],\n",
      "  \"PRODUCT\": [\"Cyberpunk 2077\", \"cyberwszczepy\", \"bronie do walki w zwarciu\", \"bronie palna\", \"bronie dystansowe\", \"bronie ogÅ‚uszajÄ…ce\", \"bronie ulepszajÄ…ce skradanie siÄ™\", \"bronie elektryczne\", \"bronie chemiczne\", \"bronie termiczne\"],\n",
      "  \"ART\": [\"Cyberpunk 2077: Night City\", \"Cyberpunk 2077: Night City: Entropic\", \"Cyberpunk 2077: Night City: Neomilitary\", \"Cyberpunk 2077: Night City: Neokitchen\"],\n",
      "  \"EVENT\": [\"wojna gangÃ³w\", \"konkurencja o dominacjÄ™\", \"bezdomnoÅ›Ä‡\", \"cybermodyfikacje\", \"przemoc\"],\n",
      "  \"OBJECT\": [\"osÅ‚ony\", \"celowanie\", \"bieganie\", \"Å›lizgi\", \"skoki\", \"podwÃ³jne skoki\", \"broÅ„ do walki w zwarciu\", \"broÅ„ palna\", \"broÅ„ dystansowa\", \"broÅ„ ogÅ‚uszajÄ…ca\", \"broÅ„ ulepszajÄ…ca skradanie siÄ™\"],\n",
      "  \"BRAND\": [\"Cyberpunk 2077\", \"Ripperdoc\", \"Trauma Team\", \"Psycho Squad\"],\n",
      "  \"NORP\": [\"Kalifornia PÃ³Å‚nocna\", \"Wolny Stan Kalifornia PÃ³Å‚nocna\"],\n",
      "  \"DATE-PERIOD\": [\"XXI wiek\", \"XXII wiek\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"JesteÅ› precyzyjnym ekstraktorem nazw wÅ‚asnych. Analizuj tekst i klasyfikuj jednostki wedÅ‚ug podanych kategorii NER.\"\n",
    "\n",
    "prompt = \"\"\"ZnajdÅº i sklasyfikuj wszystkie jednostki NER w tekÅ›cie wedÅ‚ug poniÅ¼szych kategorii:\n",
    "- PERSON: nazwani bohaterowie\n",
    "- PRODUCT: produkty, towary wytworzone przez czÅ‚owieka  \n",
    "- ART: tytuÅ‚y gier, filmÃ³w, ksiÄ…Å¼ek, dzieÅ‚\n",
    "- EVENT: wydarzenia, bitwy, wojny\n",
    "- OBJECT: zamkniÄ™te przestrzenie, przedmioty\n",
    "- BRAND: marki, firmy, producenci\n",
    "- NORP: narodowoÅ›ci, grupy kulturowe\n",
    "- DATE-PERIOD: przedziaÅ‚y czasu, pory\n",
    "\n",
    "ZwrÃ³Ä‡ wynik w formacie JSON.\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "Cyberpunk 2077 jest fabularnÄ… grÄ… akcji, zawierajÄ…cÄ… elementy strzelanek pierwszoosobowych. Gracz wciela siÄ™ w V, ktÃ³rego pÅ‚eÄ‡, gÅ‚os, wyglÄ…d (twarz, fryzurÄ™, sylwetkÄ™, modyfikacje ciaÅ‚a, rozmiar przyrodzenia czy biustu), pochodzenie i ubiÃ³r moÅ¼e dostosowaÄ‡ wedÅ‚ug wÅ‚asnych upodobaÅ„. W grze nie ma podziaÅ‚u na klasy postaci, natomiast gracz okreÅ›la swÃ³j sposÃ³b gry poprzez rozwijanie cech â€“ budowy ciaÅ‚a, inteligencji, refleksu, zdolnoÅ›ci technicznych i opanowania. PostaÄ‡ moÅ¼e rozwijaÄ‡ umiejÄ™tnoÅ›ci walki wrÄ™cz, posÅ‚ugiwania siÄ™ ostrzami, broniÄ… krÃ³tkÄ…, strzelbami, karabinami, karabinami snajperskimi, dwiema broniami, jak rÃ³wnieÅ¼ hakowania, skrytobÃ³jstwa, â€zimnej krwi\", inÅ¼ynierii i sprawnoÅ›ci fizycznej. W celu nabycia bÄ…dÅº ulepszenia cyberwszczepÃ³w, V musi odwiedziÄ‡ ripperdoca, z kolei na czarnym rynku kupiÄ‡ moÅ¼e ulepszenia wojskowe. RzadkoÅ›Ä‡ znajdowanego wyposaÅ¼enia okreÅ›lana jest przez system poziomÃ³w, reprezentowanych odpowiednimi kolorami. PrzemieszczajÄ…c siÄ™ po Å›wiecie gry, postaÄ‡ moÅ¼e chowaÄ‡ siÄ™ za osÅ‚onami, celowaÄ‡, biegaÄ‡, wykonywaÄ‡ Å›lizgi, skoki i podwÃ³jne skoki. Ataki wrÄ™cz moÅ¼na wyprowadzaÄ‡ za pomocÄ… broni do walki w zwarciu, z kolei broÅ„ palna moÅ¼e byÄ‡ modyfikowana i dzieli siÄ™ na typy Power (rykoszetujÄ…ca), Tech (przebijajÄ…ca Å›ciany i przeciwnikÃ³w) oraz Smart (z naprowadzanymi pociskami). Pociski z broni dystansowych moÅ¼na spowolniÄ‡ w trybie bullet time. W grze pojawiajÄ… siÄ™ cztery rodzaje zadawanych i otrzymywanych obraÅ¼eÅ„: fizyczne, termiczne, elektromagnetyczne i chemiczne. Cyberpunk 2077 oferuje rÃ³wnieÅ¼ bronie i cyberwszczepy ogÅ‚uszajÄ…ce czy ulepszajÄ…ce skradanie siÄ™, wobec czego grÄ™ moÅ¼na ukoÅ„czyÄ‡ bez zabijania kogokolwiek.\n",
    "Night City jest amerykaÅ„skim megamiastem w Wolnym Stanie Kalifornia PÃ³Å‚nocna, kontrolowanym przez korporacje, w ktÃ³rym nie obowiÄ…zujÄ… prawa krajowe i stanowe. OgarniÄ™te jest wojnÄ… gangÃ³w i rzÄ…dzÄ…cych nim osÃ³b, ktÃ³re walczÄ… o dominacjÄ™. W kwestiach codziennych, takich jak wywÃ³z Å›mieci czy transport publiczny, mieszkaÅ„cy polegajÄ… na robotyce. Pod wzglÄ™dem wizualnym uksztaÅ‚towaÅ‚y je cztery epoki, ktÃ³re przeszÅ‚o â€“ surowy â€entropizmâ€, kolorowy kicz, surowy neomilitaryzm i wystawny neokicz. Internet kontrolowany jest przez korporacje i wojsko. ChociaÅ¼ w Night City powszechna jest bezdomnoÅ›Ä‡, nie wyklucza ona z moÅ¼liwoÅ›ci korzystania z cybermodyfikacji, prowadzÄ…c do uzaleÅ¼nienia od kosmetycznych poprawek i przemocy. Z takimi zagroÅ¼eniami mierzy siÄ™ uzbrojona organizacja znana jako Psycho Squad. Szybkiej pomocy medycznej udzieliÄ‡ moÅ¼e Trauma Team, zaÅ› ze wzglÄ™du na bezustanne zagroÅ¼enie napaÅ›ciÄ…, wszyscy mieszkaÅ„cy majÄ… prawo noszenia broni w miejscu publicznym\n",
    "\"\"\"\n",
    "\n",
    "output_format = \"\"\"\n",
    "{\n",
    "  \"PERSON\": [\"imiona bohaterÃ³w\"],\n",
    "  \"PRODUCT\": [\"produkty, towary\"],\n",
    "  \"ART\": [\"tytuÅ‚y gier, filmÃ³w\"],\n",
    "  \"EVENT\": [\"wydarzenia, bitwy\"],\n",
    "  \"OBJECT\": [\"przedmioty, bronie\"],\n",
    "  \"BRAND\": [\"marki, firmy\"],\n",
    "  \"NORP\": [\"narodowoÅ›ci, grupy\"],\n",
    "  \"DATE-PERIOD\": [\"okresy czasu\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nTekst:\\n{text}\\n\\nFormat:\\n{output_format}\"}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "print(\"=== WYNIK NER - CYBERPUNK 2077 ===\")\n",
    "print(response['message']['content'])\n",
    "\n",
    "response_pl = ollama.chat(\n",
    "    model='SpeakLeash/bielik-1.5b-v3.0-instruct:Q8_0',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nTekst:\\n{text}\\n\\nFormat:\\n{output_format}\"}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "print(\"=== WYNIK NER - CYBERPUNK 2077 (Bielik 1.5B) ===\")\n",
    "print(response_pl['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2da0c",
   "metadata": {},
   "source": [
    "Zadanie 7.2 Analiza sentymentu\n",
    "\n",
    "OkreÅ›lenie tonu wypowiedzi (pozytywny, neutralny, negatywny).\n",
    "Dodaj przykÅ‚ad sarkazmu i porÃ³wnaj interpretacje modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e91b332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"evidence\": \"â€...szampon â€LÅ›niÄ…ca Naturaâ€ to dla mnie nie tylko kosmetyk; to codzienny list miÅ‚osny do moich wÅ‚osÃ³w...\" \n",
      "}\n",
      "``` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"JesteÅ› precyzyjnym analizatorem wydÅºwiÄ™ku tekstu. Zwracaj wyÅ‚Ä…cznie poprawny JSON wedÅ‚ug podanej specyfikacji.\"\n",
    "\n",
    "prompt = \"\"\"OkreÅ›l wydÅºwiÄ™k (pozytywny/negatywny/neutralny) poniÅ¼szej recenzji.\n",
    "ZwrÃ³Ä‡ JSON z dwoma kluczami: \"sentiment\" i \"evidence\" (zacytuj decydujÄ…cy fragment, ogranicz siÄ™ do trzech najbardziej emocjonalnych wyrazÃ³w).\n",
    "\n",
    "Recenzja:\n",
    "Gdy pierwszy raz uniosÅ‚am do nosa butelkÄ™ Szamponu â€LÅ›niÄ…ca Naturaâ€, ogarnÄ™Å‚a mnie fala wspomnieÅ„ z wakacji nad BaÅ‚tykiem â€“ zapach morskiej bryzy splecionej z nutami sÅ‚odkiej pomaraÅ„czy i soczystych malin. JuÅ¼ samo otwarcie opakowania byÅ‚o jak zdjÄ™cie wiecznego klosza z codziennoÅ›ci: w jednej sekundzie Å‚azienka zamieniÅ‚a siÄ™ w rozÅ›wietlonÄ…, letniÄ… plaÅ¼Ä™, a ja â€“ w beztroskÄ… dziewczynÄ™ z wiatrem we wÅ‚osach.\n",
    "\n",
    "GÄ™sta, perÅ‚owa formuÅ‚a wypÅ‚ywa z butelki niczym pÅ‚ynne Å›wiatÅ‚o. Kiedy rozprowadzam jÄ… na wilgotnych pasmach, mam wraÅ¼enie, Å¼e kaÅ¼dy kosmyk wita jÄ… z zachwytem: pianÄ™ miÄ™kkÄ… jak pianka z latte, ktÃ³ra lekko skrzypi miÄ™dzy palcami i otula skÃ³rÄ™ gÅ‚owy kojÄ…cym chÅ‚odem. To nie jest zwykÅ‚e mycie wÅ‚osÃ³w â€“ to rytuaÅ‚, w ktÃ³rym czujÄ™ siÄ™ dopieszczona od cebulek aÅ¼ po same koÅ„ce.\n",
    "\n",
    "JuÅ¼ podczas spÅ‚ukiwania sÅ‚yszÄ™ charakterystyczny, czysty â€skrzypâ€ zdrowych wÅ‚osÃ³w. StrumieÅ„ wody odbija Å›wiatÅ‚o, a moje pasma â€“ lÅ›niÄ…ce i lekkie â€“ taÅ„czÄ… w nim jak jedwabne wstÄ…Å¼ki. Nie mogÄ™ siÄ™ oprzeÄ‡, by nie zanurzyÄ‡ dÅ‚oni w tej tafli â€“ gÅ‚adkoÅ›Ä‡ rozczarowuje mnie tylko w jednym: Å¼e nie da siÄ™ jej zapisaÄ‡ na staÅ‚e w pamiÄ™ci dotyku.\n",
    "\n",
    "Po wysuszeniu czujÄ™ siÄ™, jakbym stÄ…paÅ‚a po czerwonym dywanie: pukle sypkie, sprÄ™Å¼yste, unoszÄ…ce siÄ™ przy kaÅ¼dym ruchu gÅ‚owy. Aromat, ktÃ³ry pozostaje, przypomina delikatny perfum â€“ dyskretny, ale wystarczajÄ…co wyrazisty, by ktoÅ› obok zapytaÅ‚ z zaciekawieniem: â€Czym pachniesz?â€ Wtedy uÅ›miecham siÄ™ szeroko, bo wiem, Å¼e ten sekret kryje siÄ™ w niewielkiej, zielonej butelce stojÄ…cej na pÃ³Å‚ce.\n",
    "\n",
    "Szampon â€LÅ›niÄ…ca Naturaâ€ to dla mnie nie tylko kosmetyk; to codzienny list miÅ‚osny do moich wÅ‚osÃ³w â€“ powiew odwagi i czuÅ‚oÅ›ci zarazem. JeÅ›li Twoje pasma pragnÄ… rozgwieÅ¼dÅ¼onego blasku, a Twoje zmysÅ‚y tÄ™skniÄ… za chwilÄ… szczerej przyjemnoÅ›ci, pozwÃ³l temu szamponowi szepnÄ…Ä‡ im historiÄ™ o tym, jak piÄ™kno rodzi siÄ™ z zachwytu.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d4c7325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALIZA SENTYMENTU - PRZYKÅADY WÅASNE ===\n",
      "\n",
      "--- MODEL: gemma2:2b ---\n",
      "POZYTYWNY:\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"confidence\": 9,\n",
      "  \"evidence\": [\n",
      "    \"pereÅ‚ka\",\n",
      "    \"uprzejma i profesjonalna\",\n",
      "    \"smakÅ‚y jak u babci\",\n",
      "    \"idealnie chrupiÄ…cy\",\n",
      "    \"ciepÅ‚a i przytulna\",\n",
      "    \"z caÅ‚ego serca polecam!\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "SARKASTYCZNY:\n",
      "{\n",
      "  \"sentiment\": \"strongly positive\",\n",
      "  \"confidence\": 9,\n",
      "  \"evidence\": [\n",
      "    \"arcydzieÅ‚o\",\n",
      "    \"fantastyczna przygoda\",\n",
      "    \"profesjonalna\",\n",
      "    \"Å›wietny\",\n",
      "    \"polecam\",\n",
      "    \"marnowaÄ‡ czas i pieniÄ…dze\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "NEUTRALNY:\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"confidence\": 7,\n",
      "  \"evidence\": [\n",
      "    \"Restauracja mieÅ›ci siÄ™ przy ulicy GÅ‚Ã³wnej 15.\",\n",
      "    \"Oferuje dania kuchni polskiej i miÄ™dzynarodowej.\",\n",
      "    \"Godziny otwarcia: poniedziaÅ‚ek-piÄ…tek 12:00-22:00, sobota-niedziela 14:00-23:00.\",\n",
      "    \"Menu dostÄ™pne online i w lokalu.\",\n",
      "    \"MoÅ¼liwoÅ›Ä‡ rezerwacji stolikÃ³w telefonicznych.\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- MODEL: llama3.1:8b ---\n",
      "POZYTYWNY:\n",
      "{\n",
      "  \"sentiment\": \"pozytywny\",\n",
      "  \"confidence\": 10,\n",
      "  \"evidence\": [\n",
      "    \"prawdziwa pereÅ‚ka\",\n",
      "    \"niezwykle uprzejma\",\n",
      "    \"profesjonalna\",\n",
      "    \"smakowaÅ‚y jak u babci\",\n",
      "    \"chrupiÄ…cy\",\n",
      "    \"ciepÅ‚a i przytulna\",\n",
      "    \"ceny rozsÄ…dne\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "SARKASTYCZNY:\n",
      "{\n",
      "  \"sentiment\": \"negatywny\",\n",
      "  \"confidence\": 8,\n",
      "  \"evidence\": [\n",
      "    \"kelner zapomniaÅ‚ o naszym stoliku\",\n",
      "    \"ceny\",\n",
      "    \"marnowaÄ‡ czas i pieniÄ…dze\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "NEUTRALNY:\n",
      "{\n",
      "  \"sentiment\": \"neutralny\",\n",
      "  \"confidence\": 8,\n",
      "  \"evidence\": [\n",
      "    \"oferuje dania kuchni polskiej i miÄ™dzynarodowej\",\n",
      "    \"menu dostÄ™pne online i w lokalu\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== TEST ROZPOZNAWANIA SARKAZMU ===\n",
      "ANALIZA SARKAZMU:\n",
      "{\n",
      "  \"literal_sentiment\": \"negatywny\",\n",
      "  \"detected_sarcasm\": true,\n",
      "  \"actual_sentiment\": \"negatywny\",\n",
      "  \"sarcasm_indicators\": [\n",
      "    \"45 minut na zimne jedzenie\",\n",
      "    \"fantastyczna przygoda\",\n",
      "    \"profesjonalna\",\n",
      "    \"zapomniaÅ‚ o naszym stoliku\",\n",
      "    \"Å›wietny stosunek jakoÅ›ci do ceny\",\n",
      "    \"pÅ‚acisz za restauracjÄ™, a dostajesz jakoÅ›Ä‡ fast-foodu\",\n",
      "    \"polecam wszystkim, ktÃ³rzy lubiÄ… marnowaÄ‡ czas i pieniÄ…dze\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"JesteÅ› precyzyjnym analizatorem wydÅºwiÄ™ku tekstu. Zwracaj wyÅ‚Ä…cznie poprawny JSON wedÅ‚ug podanej specyfikacji.\"\n",
    "\n",
    "def analyze_sentiment(text, model_name='gemma2:2b'):\n",
    "    prompt = f\"\"\"OkreÅ›l wydÅºwiÄ™k (pozytywny/negatywny/neutralny) poniÅ¼szego tekstu.\n",
    "    ZwrÃ³Ä‡ JSON z kluczami: \"sentiment\", \"confidence\" (1-10), \"evidence\" (najwaÅ¼niejsze sÅ‚owa/frazy).\n",
    "    \n",
    "    Tekst: {text}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        format=\"json\",\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "# PrzykÅ‚ad 1: Pozytywna recenzja restauracji\n",
    "positive_review = \"\"\"\n",
    "Restauracja \"Smaki Polski\" to prawdziwa pereÅ‚ka! ObsÅ‚uga byÅ‚a niezwykle uprzejma i profesjonalna. \n",
    "Pierogi robione na miejscu smakowaÅ‚y jak u babci, a kotlet schabowy byÅ‚ idealnie chrupiÄ…cy. \n",
    "Atmosfera ciepÅ‚a i przytulna, ceny rozsÄ…dne. Z caÅ‚ego serca polecam!\n",
    "\"\"\"\n",
    "\n",
    "# PrzykÅ‚ad 2: Sarkastyczna recenzja (negatywna ukryta w ironii)\n",
    "sarcastic_review = \"\"\"\n",
    "Wow, ta restauracja to prawdziwe \"arcydzieÅ‚o\"! Czekanie 45 minut na zimne jedzenie to byÅ‚a \n",
    "\"fantastyczna\" przygoda. ObsÅ‚uga tak \"profesjonalna\", Å¼e kelner zapomniaÅ‚ o naszym stoliku. \n",
    "A te ceny! NaprawdÄ™ \"Å›wietny\" stosunek jakoÅ›ci do ceny - pÅ‚acisz za restauracjÄ™, \n",
    "a dostajesz jakoÅ›Ä‡ fast-foodu. Zdecydowanie \"polecam\" wszystkim, ktÃ³rzy lubiÄ… \n",
    "marnowaÄ‡ czas i pieniÄ…dze.\n",
    "\"\"\"\n",
    "\n",
    "# PrzykÅ‚ad 3: Neutralny opis faktyczny\n",
    "neutral_text = \"\"\"\n",
    "Restauracja mieÅ›ci siÄ™ przy ulicy GÅ‚Ã³wnej 15. Oferuje dania kuchni polskiej i miÄ™dzynarodowej. \n",
    "Godziny otwarcia: poniedziaÅ‚ek-piÄ…tek 12:00-22:00, sobota-niedziela 14:00-23:00. \n",
    "Menu dostÄ™pne online i w lokalu. MoÅ¼liwoÅ›Ä‡ rezerwacji stolikÃ³w telefonicznych.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== ANALIZA SENTYMENTU - PRZYKÅADY WÅASNE ===\\n\")\n",
    "\n",
    "# Test na rÃ³Å¼nych modelach\n",
    "models = ['gemma2:2b', 'llama3.1:8b']\n",
    "\n",
    "for model in models:\n",
    "    print(f\"--- MODEL: {model} ---\")\n",
    "    \n",
    "    try:\n",
    "        # Pozytywny\n",
    "        result1 = analyze_sentiment(positive_review, model)\n",
    "        print(\"POZYTYWNY:\")\n",
    "        print(json.dumps(json.loads(result1), indent=2, ensure_ascii=False))\n",
    "        \n",
    "        # Sarkastyczny\n",
    "        result2 = analyze_sentiment(sarcastic_review, model) \n",
    "        print(\"\\nSARKASTYCZNY:\")\n",
    "        print(json.dumps(json.loads(result2), indent=2, ensure_ascii=False))\n",
    "        \n",
    "        # Neutralny\n",
    "        result3 = analyze_sentiment(neutral_text, model)\n",
    "        print(\"\\nNEUTRALNY:\")\n",
    "        print(json.dumps(json.loads(result3), indent=2, ensure_ascii=False))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"BÅ‚Ä…d dla modelu {model}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Dodatkowy test - czy model rozpoznaje sarkasm\n",
    "print(\"=== TEST ROZPOZNAWANIA SARKAZMU ===\")\n",
    "\n",
    "sarcasm_prompt = \"\"\"\n",
    "Przeanalizuj poniÅ¼szy tekst pod kÄ…tem:\n",
    "1. DosÅ‚ownego znaczenia sÅ‚Ã³w\n",
    "2. Prawdopodobnego sarkazmu/ironii\n",
    "3. Rzeczywistego wydÅºwiÄ™ku\n",
    "\n",
    "ZwrÃ³Ä‡ JSON: {\n",
    "  \"literal_sentiment\": \"pozytywny/negatywny/neutralny\",\n",
    "  \"detected_sarcasm\": true/false,\n",
    "  \"actual_sentiment\": \"pozytywny/negatywny/neutralny\",\n",
    "  \"sarcasm_indicators\": [\"lista wskaÅºnikÃ³w sarkazmu\"]\n",
    "}\n",
    "\n",
    "Tekst: \"\"\" + sarcastic_review\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"JesteÅ› ekspertem od analizy stylistycznej tekstu, specjalizujÄ…cym siÄ™ w wykrywaniu sarkazmu i ironii.\"},\n",
    "        {\"role\": \"user\", \"content\": sarcasm_prompt}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "print(\"ANALIZA SARKAZMU:\")\n",
    "print(json.dumps(json.loads(response['message']['content']), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d9450",
   "metadata": {},
   "source": [
    "Zadanie 7.3 Ekstrakcja relacji\n",
    "\n",
    "Wykrywanie relacji PRACUJE_W i MIESZKA_W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b08dab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[{\"person\": \"Anna Kowalska\", \"company\": \"AGH\"}, {\"person\": \"Anna Kowalska\", \"company\": \"Google\"}] \n",
      "``` \n",
      "\n",
      "**WyjaÅ›nienie:**\n",
      "\n",
      "W tekÅ›cie podano dwie relacje: \n",
      "\n",
      "1. **Aktualna praca:** Anna Kowalska pracuje obecnie na AGH.\n",
      "2. **Praca w przeszÅ‚oÅ›ci:** Anna Kowalska pracowaÅ‚a kiedyÅ› w Google.\n",
      "\n",
      "Obie relacje sÄ… przedstawione jako osobne obiekty w tablicy JSON.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"JesteÅ› precyzyjnym analizatorem tekstu. ZnajdÅº wszystkie relacje gdzie osoba pracuje dla organizacji. ZwrÃ³Ä‡ tablicÄ™ JSON z obiektami {\\\"person\\\":\\\"<imiÄ™>\\\",\\\"company\\\":\\\"<organizacja>\\\"}.\"\n",
    "\n",
    "shots = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Tekst: \\\"Jan Kowalski pracuje w Microsoft jako programista.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"[{\\\"person\\\":\\\"Jan Kowalski\\\",\\\"company\\\":\\\"Microsoft\\\"}]\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Anna Kowalska teraz pracuje na AGH, ale kiedyÅ› karierÄ™ robiÅ‚a w Google.\\\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        *shots\n",
    "    ]\n",
    ")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ce7af02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EKSTRAKCJA RELACJI - PRZYKÅADY WÅASNE ===\n",
      "\n",
      "--- TEKST DO ANALIZY ---\n",
      "Dr Aleksandra WiÅ›niewska jest profesorem na Uniwersytecie JagielloÅ„skim w Krakowie. \n",
      "    Mieszka w Warszawie, ale dojeÅ¼dÅ¼a do pracy. WczeÅ›niej pracowaÅ‚a w Institute of Technology w Bostonie, \n",
      "    gdzie mieszkaÅ‚a przez 5 lat.\n",
      "\n",
      "[{\"person\": \"Dr Aleksandra WiÅ›niewska\", \"relation\": \"PROFESOREM\", \"target\": \"Uniwersytet JagielloÅ„ski\"}, {\"person\": \"Dr Aleksandra WiÅ›niewska\", \"relation\": \"MIESZKA_W\", \"target\": \"KrakÃ³w\"}, {\"person\": \"Dr Aleksandra WiÅ›niewska\", \"relation\": \"MIESZKA_W\", \"target\": \"Warszawa\"}] \n",
      "\n",
      "--- TEKST DO ANALIZY ---\n",
      "MichaÅ‚ ZieliÅ„ski to programista w firmie CD Projekt. Mieszka w GdaÅ„sku, ale pracuje \n",
      "    zdalnie. Jego Å¼ona Anna ZieliÅ„ska pracuje w szpitalu miejskim w GdaÅ„sku jako lekarka.\n",
      "\n",
      "[{\"person\": \"MichaÅ‚ ZieliÅ„ski\", \"relation\": \"PRACUJE_W\", \"target\": \"CD Projekt\"}, {\"person\": \"MichaÅ‚ ZieliÅ„ski\", \"relation\": \"MIESZKA_W\", \"target\": \"GdaÅ„sk\"}, {\"person\": \"Anna ZieliÅ„ska\", \"relation\": \"PRACUJE_W\", \"target\": \"szpital miejski w GdaÅ„sku\"}] \n",
      "\n",
      "--- TEKST DO ANALIZY ---\n",
      "Startup TechnoVision zostaÅ‚ zaÅ‚oÅ¼ony przez PawÅ‚a Nowaka, ktÃ³ry mieszka w Poznaniu. \n",
      "    Firma ma biura w Warszawie i WrocÅ‚awiu. PaweÅ‚ wczeÅ›niej pracowaÅ‚ w Microsoft Poland.\n",
      "\n",
      "[{\"person\": \"PaweÅ‚ Nowak\", \"relation\": \"MIESZKA_W\", \"target\": \"PoznaÅ„\"}, {\"person\": \"PaweÅ‚ Nowak\", \"relation\": \"PRACUJE_W\", \"target\": \"Microsoft Poland\"}, {\"person\": \"Pawel Nowak\", \"relation\": \"PRACUJE_W\", \"target\": \"Startup TechnoVision\"}] \n",
      "\n",
      "=== EKTRAKCJA RELACJI - TEST NA MODELU BIELIK 1.5B ===\n",
      "\n",
      "--- TEKST DO ANALIZY ---\n",
      "Dr Aleksandra WiÅ›niewska jest profesorem na Uniwersytecie JagielloÅ„skim w Krakowie. \n",
      "    Mieszka w Warszawie, ale dojeÅ¼dÅ¼a do pracy. WczeÅ›niej pracowaÅ‚a w Institute of Technology w Bostonie, \n",
      "    gdzie mieszkaÅ‚a przez 5 lat.\n",
      "\n",
      "[{\"person\": \"Dr Aleksanara WiÅ›niewska\", \"related_persons\": [\"Institute of Technology in Boston\"], \"related_place\": \"KrakÃ³w, Warszawa\"}]\n",
      "--- TEKST DO ANALIZY ---\n",
      "MichaÅ‚ ZieliÅ„ski to programista w firmie CD Projekt. Mieszka w GdaÅ„sku, ale pracuje \n",
      "    zdalnie. Jego Å¼ona Anna ZieliÅ„ska pracuje w szpitalu miejskim w GdaÅ„sku jako lekarka.\n",
      "\n",
      "[{\"person\": \"MichaÅ‚ ZieliÅ„ski\", \"relation\": \"MIESZKA_W\", \"target\": \"CD Projekt\"}, {\"personal\": \"Anna ZieliÅ„ska\", \"related\": \"PROCEDENT\", \"target\": \"GdaÅ„sk\", \"type\": \"lekarz\"}]\n",
      "--- TEKST DO ANALIZY ---\n",
      "Startup TechnoVision zostaÅ‚ zaÅ‚oÅ¼ony przez PawÅ‚a Nowaka, ktÃ³ry mieszka w Poznaniu. \n",
      "    Firma ma biura w Warszawie i WrocÅ‚awiu. PaweÅ‚ wczeÅ›niej pracowaÅ‚ w Microsoft Poland.\n",
      "\n",
      "[{\"person\": \"PaweÅ‚ Nowak\", \"relation\": \"MIESZKA_W\", \"target\": \"PoznaÅ„\"}, {\"personal\": \"TechnoVision\", \"related\": \"Startup\", \"target\": \"Warszawa\"}, {\"personal\": \"TechnoVision\", \"related\": \"Startup\", \"target\": \"WrocÅ‚aw\"}]\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"JesteÅ› precyzyjnym analizatorem tekstu. ZnajdÅº TYLKO relacje PRACUJE_W i MIESZKA_W. ZwrÃ³Ä‡ sformatowanÄ… tablicÄ™ JSON.\"\n",
    "\n",
    "# Few-shot przykÅ‚ady do trenowania modelu\n",
    "shots = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Tekst: \\\"Maria Nowak pracuje w banku PKO BP jako analityk finansowy.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": '[{\"person\": \"Maria Nowak\", \"relation\": \"PRACUJE_W\", \"target\": \"PKO BP\"}]'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Tomasz Kowalski mieszka w Krakowie i pracuje w firmie Google.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": '[{\"person\": \"Tomasz Kowalski\", \"relation\": \"MIESZKA_W\", \"target\": \"KrakÃ³w\"}, {\"person\": \"Tomasz Kowalski\", \"relation\": \"PRACUJE_W\", \"target\": \"Google\"}]'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Jan Nowak mieszka w Warszawie. Obecnie pracuje w Microsoft, ale wczeÅ›niej byÅ‚ zatrudniony w IBM.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": '[{\"person\": \"Jan Nowak\", \"relation\": \"MIESZKA_W\", \"target\": \"Warszawa\"}, {\"person\": \"Jan Nowak\", \"relation\": \"PRACUJE_W\", \"target\": \"Microsoft\"}]'\n",
    "    }\n",
    "]\n",
    "\n",
    "# PrzykÅ‚adowe teksty do analizy\n",
    "test_texts = [\n",
    "    \"\"\"\n",
    "    Dr Aleksandra WiÅ›niewska jest profesorem na Uniwersytecie JagielloÅ„skim w Krakowie. \n",
    "    Mieszka w Warszawie, ale dojeÅ¼dÅ¼a do pracy. WczeÅ›niej pracowaÅ‚a w Institute of Technology w Bostonie, \n",
    "    gdzie mieszkaÅ‚a przez 5 lat.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    MichaÅ‚ ZieliÅ„ski to programista w firmie CD Projekt. Mieszka w GdaÅ„sku, ale pracuje \n",
    "    zdalnie. Jego Å¼ona Anna ZieliÅ„ska pracuje w szpitalu miejskim w GdaÅ„sku jako lekarka.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Startup TechnoVision zostaÅ‚ zaÅ‚oÅ¼ony przez PawÅ‚a Nowaka, ktÃ³ry mieszka w Poznaniu. \n",
    "    Firma ma biura w Warszawie i WrocÅ‚awiu. PaweÅ‚ wczeÅ›niej pracowaÅ‚ w Microsoft Poland.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(\"=== EKSTRAKCJA RELACJI - PRZYKÅADY WÅASNE ===\\n\")\n",
    "\n",
    "# Test few-shot z przykÅ‚adami\n",
    "for text in test_texts:\n",
    "    print(f\"--- TEKST DO ANALIZY ---\\n{text.strip()}\\n\")\n",
    "\n",
    "    shots_with_test = shots + [\n",
    "        {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "    ]\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='gemma2:2b',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            *shots_with_test\n",
    "        ]\n",
    "    )\n",
    "    print(response['message']['content'])\n",
    "\n",
    "\n",
    "print (\"=== EKTRAKCJA RELACJI - TEST NA MODELU BIELIK 1.5B ===\\n\")\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"--- TEKST DO ANALIZY ---\\n{text.strip()}\\n\")\n",
    "\n",
    "    shots_with_test = shots + [\n",
    "        {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "    ]\n",
    "    response = ollama.chat(\n",
    "        model='SpeakLeash/bielik-1.5b-v3.0-instruct:Q8_0',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            *shots_with_test\n",
    "        ],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    print(response['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9060d1",
   "metadata": {},
   "source": [
    "Zadanie 7.4 Klasyfikacja tematyczna\n",
    "\n",
    "Przypisz tekst do jednej z kategorii: nauka, sport, polityka, technologia.\n",
    "Przetestuj trzy warianty: zero-shot, few-shot, sekcyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77ed2f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"kategoria\": \"technologia\"} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = (\n",
    "    \"JesteÅ› klasyfikatorem tematÃ³w. Przypisz tekst do JEDNEJ kategorii \"\n",
    "    \"z zestawu: nauka, sport, polityka, technologia. \"\n",
    "    \"ZwrÃ³Ä‡ wyÅ‚Ä…cznie JSON: {\\\"kategoria\\\":\\\"...\\\"}.\"\n",
    ")\n",
    "\n",
    "text = 'Nowy mikroskop pozwala obserwowaÄ‡ pojedyncze atomy.'\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49f1f0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KLASYFIKACJA TEMATYCZNA - PORÃ“WNANIE STRATEGII ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ZbiÃ³r testowych tekstÃ³w z rÃ³Å¼nych kategorii\n",
    "test_texts = [\n",
    "    \"Nowy mikroskop pozwala obserwowaÄ‡ pojedyncze atomy w czasie rzeczywistym.\",\n",
    "    \"Robert Lewandowski strzeliÅ‚ hat-tricka w meczu przeciwko Bayernowi Monachium.\",\n",
    "    \"Parlament przyjÄ…Å‚ ustawÄ™ o reformie systemu podatkowego wiÄ™kszoÅ›ciÄ… gÅ‚osÃ³w.\",\n",
    "    \"Sztuczna inteligencja ChatGPT-4 osiÄ…gnÄ™Å‚a przeÅ‚omowe wyniki w testach jÄ™zykowych.\",\n",
    "    \"Naukowcy z MIT odkryli nowy materiaÅ‚ przewodzÄ…cy prÄ…d w temperaturze pokojowej.\",\n",
    "    \"Reprezentacja Polski awansowaÅ‚a do pÃ³Å‚finaÅ‚u mistrzostw Å›wiata w siatkÃ³wce.\",\n",
    "    \"Premier zapowiedziaÅ‚ zwiÄ™kszenie wydatkÃ³w na ochronÄ™ zdrowia w przyszÅ‚ym roku.\",\n",
    "    \"Apple przedstawiÅ‚o nowy procesor M3 z architekturÄ… 3-nanometrowÄ….\"\n",
    "]\n",
    "\n",
    "# Oczekiwane kategorie (dla weryfikacji)\n",
    "expected_categories = [\n",
    "    \"nauka\", \"sport\", \"polityka\", \"technologia\", \n",
    "    \"nauka\", \"sport\", \"polityka\", \"technologia\"\n",
    "]\n",
    "\n",
    "print(\"=== KLASYFIKACJA TEMATYCZNA - PORÃ“WNANIE STRATEGII ===\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9b5f3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WARIANT 1: ZERO-SHOT ---\n",
      "1. Nowy mikroskop pozwala obserwowaÄ‡ pojedyncze atomy...\n",
      "   Przewidziano: technologia | Oczekiwano: nauka\n",
      "2. Robert Lewandowski strzeliÅ‚ hat-tricka w meczu prz...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "3. Parlament przyjÄ…Å‚ ustawÄ™ o reformie systemu podatk...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "4. Sztuczna inteligencja ChatGPT-4 osiÄ…gnÄ™Å‚a przeÅ‚omo...\n",
      "   Przewidziano: technologia | Oczekiwano: technologia\n",
      "5. Naukowcy z MIT odkryli nowy materiaÅ‚ przewodzÄ…cy p...\n",
      "   Przewidziano: technologia | Oczekiwano: nauka\n",
      "6. Reprezentacja Polski awansowaÅ‚a do pÃ³Å‚finaÅ‚u mistr...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "7. Premier zapowiedziaÅ‚ zwiÄ™kszenie wydatkÃ³w na ochro...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "8. Apple przedstawiÅ‚o nowy procesor M3 z architekturÄ…...\n",
      "   Przewidziano: technologia | Oczekiwano: technologia\n"
     ]
    }
   ],
   "source": [
    "# WARIANT 1: ZERO-SHOT\n",
    "print(\"--- WARIANT 1: ZERO-SHOT ---\")\n",
    "\n",
    "SYSTEM_ZERO = (\n",
    "    \"JesteÅ› klasyfikatorem tematÃ³w. Przypisz tekst do JEDNEJ kategorii \"\n",
    "    \"z zestawu: nauka, sport, polityka, technologia. \"\n",
    "    \"ZwrÃ³Ä‡ wyÅ‚Ä…cznie JSON: {\\\"kategoria\\\":\\\"...\\\"}.\"\n",
    ")\n",
    "\n",
    "zero_shot_results = []\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='gemma2:2b',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_ZERO},\n",
    "                {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "            ],\n",
    "            format=\"json\",\n",
    "            options={\"temperature\": 0}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response['message']['content'])\n",
    "        predicted = result.get('kategoria', 'BÅÄ„D')\n",
    "        zero_shot_results.append(predicted)\n",
    "        \n",
    "        print(f\"{i+1}. {text[:50]}...\")\n",
    "        print(f\"   Przewidziano: {predicted} | Oczekiwano: {expected_categories[i]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"BÅ‚Ä…d: {e}\")\n",
    "        zero_shot_results.append('BÅÄ„D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eaba9c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WARIANT 2: FEW-SHOT ---\n",
      "1. Nowy mikroskop pozwala obserwowaÄ‡ pojedyncze atomy...\n",
      "   Przewidziano: nauka | Oczekiwano: nauka\n",
      "2. Robert Lewandowski strzeliÅ‚ hat-tricka w meczu prz...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "3. Parlament przyjÄ…Å‚ ustawÄ™ o reformie systemu podatk...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "4. Sztuczna inteligencja ChatGPT-4 osiÄ…gnÄ™Å‚a przeÅ‚omo...\n",
      "   Przewidziano: nauka | Oczekiwano: technologia\n",
      "5. Naukowcy z MIT odkryli nowy materiaÅ‚ przewodzÄ…cy p...\n",
      "   Przewidziano: nauka | Oczekiwano: nauka\n",
      "6. Reprezentacja Polski awansowaÅ‚a do pÃ³Å‚finaÅ‚u mistr...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "7. Premier zapowiedziaÅ‚ zwiÄ™kszenie wydatkÃ³w na ochro...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "8. Apple przedstawiÅ‚o nowy procesor M3 z architekturÄ…...\n",
      "   Przewidziano: technologia | Oczekiwano: technologia\n"
     ]
    }
   ],
   "source": [
    "# WARIANT 2: FEW-SHOT\n",
    "print(\"\\n--- WARIANT 2: FEW-SHOT ---\")\n",
    "\n",
    "SYSTEM_FEW = \"Klasyfikuj teksty do jednej z kategorii: nauka, sport, polityka, technologia.\"\n",
    "\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Badacze z Harvardu opracowali nowÄ… szczepionkÄ™ przeciwko grypie.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"{\\\"kategoria\\\":\\\"nauka\\\"}\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Cristiano Ronaldo zdobyÅ‚ bramkÄ™ w 90. minucie meczu.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"{\\\"kategoria\\\":\\\"sport\\\"}\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Tekst: \\\"Sejm uchwaliÅ‚ budÅ¼et paÅ„stwa na nastÄ™pny rok.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"{\\\"kategoria\\\":\\\"polityka\\\"}\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Google zaprezentowaÅ‚o nowy algorytm uczenia maszynowego.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"{\\\"kategoria\\\":\\\"technologia\\\"}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "few_shot_results = []\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    try:\n",
    "        messages = [{\"role\": \"system\", \"content\": SYSTEM_FEW}] + few_shot_examples + [\n",
    "            {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "        ]\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model='gemma2:2b',\n",
    "            messages=messages,\n",
    "            format=\"json\",\n",
    "            options={\"temperature\": 0}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response['message']['content'])\n",
    "        predicted = result.get('kategoria', 'BÅÄ„D')\n",
    "        few_shot_results.append(predicted)\n",
    "        \n",
    "        print(f\"{i+1}. {text[:50]}...\")\n",
    "        print(f\"   Przewidziano: {predicted} | Oczekiwano: {expected_categories[i]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"BÅ‚Ä…d: {e}\")\n",
    "        few_shot_results.append('BÅÄ„D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75e6c290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WARIANT 3: SEKCYJNY ---\n",
      "1. Nowy mikroskop pozwala obserwowaÄ‡ pojedyncze atomy...\n",
      "   Przewidziano: nauka | Oczekiwano: nauka\n",
      "   Uzasadnienie: Tekst opisuje nowy mikroskop, ktÃ³ry pozwala na obserwacjÄ™ pojedynczych atomy w czasie rzeczywistym. To dotyczy badaÅ„ naukowych.\n",
      "2. Robert Lewandowski strzeliÅ‚ hat-tricka w meczu prz...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "   Uzasadnienie: Zawodnik strzeliÅ‚ hat-trick w meczu, co jest wydarzeniem sportowym.\n",
      "3. Parlament przyjÄ…Å‚ ustawÄ™ o reformie systemu podatk...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "   Uzasadnienie: W tekÅ›cie opisano przyjÄ™cie ustawy przez parlament, co jest elementem polityki.\n",
      "4. Sztuczna inteligencja ChatGPT-4 osiÄ…gnÄ™Å‚a przeÅ‚omo...\n",
      "   Przewidziano: nauka | Oczekiwano: technologia\n",
      "   Uzasadnienie: Tekst opisuje osiÄ…gniÄ™cia w dziedzinie sztucznej inteligencji, co jest tematem badaÅ„ i naukowych odkryÄ‡.\n",
      "5. Naukowcy z MIT odkryli nowy materiaÅ‚ przewodzÄ…cy p...\n",
      "   Przewidziano: nauka | Oczekiwano: nauka\n",
      "   Uzasadnienie: Tekst opisuje odkrycie naukowe nowego materiaÅ‚u, co jest tematem zwiÄ…zanym z badaniami i naukÄ….\n",
      "6. Reprezentacja Polski awansowaÅ‚a do pÃ³Å‚finaÅ‚u mistr...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "   Uzasadnienie: Zawody w siatkÃ³wce (Mistrzostwa Åšwiata)\n",
      "7. Premier zapowiedziaÅ‚ zwiÄ™kszenie wydatkÃ³w na ochro...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "   Uzasadnienie: W tekÅ›cie omawiane sÄ… zwiÄ™kszenie wydatkÃ³w na ochronÄ™ zdrowia, co jest tematem polityki budÅ¼etowej i finansowej.\n",
      "8. Apple przedstawiÅ‚o nowy procesor M3 z architekturÄ…...\n",
      "   Przewidziano: nauka | Oczekiwano: technologia\n",
      "   Uzasadnienie: W tekÅ›cie opisano nowy procesor, co jest tematem naukowym. \n"
     ]
    }
   ],
   "source": [
    "# WARIANT 3: SEKCYJNY (RULES-INPUT-OUTPUT)  \n",
    "print(\"\\n--- WARIANT 3: SEKCYJNY ---\")\n",
    "\n",
    "def classify_sectional(text):\n",
    "    prompt = f\"\"\"\n",
    "<RULES>\n",
    "Przypisz tekst dokÅ‚adnie do jednej z 4 kategorii:\n",
    "- nauka: badania, odkrycia, eksperymenty, publikacje naukowe\n",
    "- sport: mecze, zawody, wyniki sportowe, zawodnicy\n",
    "- polityka: wybory, ustawy, rzÄ…d, partie, decyzje polityczne  \n",
    "- technologia: nowe urzÄ…dzenia, oprogramowanie, IT, innowacje tech\n",
    "</RULES>\n",
    "\n",
    "<INPUT>\n",
    "{text}\n",
    "</INPUT>\n",
    "\n",
    "<OUTPUT>\n",
    "ZwrÃ³Ä‡ JSON: {{\"kategoria\": \"nauka/sport/polityka/technologia\", \"uzasadnienie\": \"krÃ³tkie uzasadnienie\"}}\n",
    "</OUTPUT>\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='gemma2:2b',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"JesteÅ› precyzyjnym klasyfikatorem. PostÄ™puj zgodnie z instrukcjami w sekcjach.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        format=\"json\",\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "sectional_results = []\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    try:\n",
    "        result_raw = classify_sectional(text)\n",
    "        result = json.loads(result_raw)\n",
    "        predicted = result.get('kategoria', 'BÅÄ„D')\n",
    "        sectional_results.append(predicted)\n",
    "        \n",
    "        print(f\"{i+1}. {text[:50]}...\")\n",
    "        print(f\"   Przewidziano: {predicted} | Oczekiwano: {expected_categories[i]}\")\n",
    "        print(f\"   Uzasadnienie: {result.get('uzasadnienie', 'Brak')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"BÅ‚Ä…d: {e}\")\n",
    "        sectional_results.append('BÅÄ„D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cc258d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANALIZA PORÃ“WNAWCZA ===\n",
      "DokÅ‚adnoÅ›Ä‡ Zero-shot: 75.00%\n",
      "DokÅ‚adnoÅ›Ä‡ Few-shot: 87.50%\n",
      "DokÅ‚adnoÅ›Ä‡ Sekcyjna: 75.00%\n",
      "\n",
      "--- TABELA PORÃ“WNAWCZA ---\n",
      "Nr | Oczekiwane | Zero-shot | Few-shot | Sekcyjna\n",
      "--------------------------------------------------\n",
      " 1 | nauka      | technologia | nauka    | nauka   \n",
      " 2 | sport      | sport     | sport    | sport   \n",
      " 3 | polityka   | polityka  | polityka | polityka\n",
      " 4 | technologia | technologia | nauka    | nauka   \n",
      " 5 | nauka      | technologia | nauka    | nauka   \n",
      " 6 | sport      | sport     | sport    | sport   \n",
      " 7 | polityka   | polityka  | polityka | polityka\n",
      " 8 | technologia | technologia | technologia | nauka   \n",
      "\n",
      "--- ANALIZA BÅÄ˜DÃ“W ---\n",
      "\n",
      "Zero-shot:\n",
      "  BÅ‚Ä…d 1: nauka â†’ technologia\n",
      "    Tekst: Nowy mikroskop pozwala obserwowaÄ‡ pojedyncze atomy w czasie ...\n",
      "  BÅ‚Ä…d 5: nauka â†’ technologia\n",
      "    Tekst: Naukowcy z MIT odkryli nowy materiaÅ‚ przewodzÄ…cy prÄ…d w temp...\n",
      "\n",
      "Few-shot:\n",
      "  BÅ‚Ä…d 4: technologia â†’ nauka\n",
      "    Tekst: Sztuczna inteligencja ChatGPT-4 osiÄ…gnÄ™Å‚a przeÅ‚omowe wyniki ...\n",
      "\n",
      "Sekcyjna:\n",
      "  BÅ‚Ä…d 4: technologia â†’ nauka\n",
      "    Tekst: Sztuczna inteligencja ChatGPT-4 osiÄ…gnÄ™Å‚a przeÅ‚omowe wyniki ...\n",
      "  BÅ‚Ä…d 8: technologia â†’ nauka\n",
      "    Tekst: Apple przedstawiÅ‚o nowy procesor M3 z architekturÄ… 3-nanomet...\n",
      "\n",
      "=== PODSUMOWANIE ===\n",
      "Najlepsza strategia: Few-shot\n"
     ]
    }
   ],
   "source": [
    "# ANALIZA WYNIKÃ“W\n",
    "print(\"\\n=== ANALIZA PORÃ“WNAWCZA ===\")\n",
    "\n",
    "def calculate_accuracy(predicted, expected):\n",
    "    correct = sum(1 for p, e in zip(predicted, expected) if p == e)\n",
    "    total = len(expected)\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "accuracy_zero = calculate_accuracy(zero_shot_results, expected_categories)\n",
    "accuracy_few = calculate_accuracy(few_shot_results, expected_categories)\n",
    "accuracy_sectional = calculate_accuracy(sectional_results, expected_categories)\n",
    "\n",
    "print(f\"DokÅ‚adnoÅ›Ä‡ Zero-shot: {accuracy_zero:.2%}\")\n",
    "print(f\"DokÅ‚adnoÅ›Ä‡ Few-shot: {accuracy_few:.2%}\")\n",
    "print(f\"DokÅ‚adnoÅ›Ä‡ Sekcyjna: {accuracy_sectional:.2%}\")\n",
    "\n",
    "# Tabela porÃ³wnawcza\n",
    "print(\"\\n--- TABELA PORÃ“WNAWCZA ---\")\n",
    "print(\"Nr | Oczekiwane | Zero-shot | Few-shot | Sekcyjna\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(len(test_texts)):\n",
    "    expected = expected_categories[i]\n",
    "    zero = zero_shot_results[i] \n",
    "    few = few_shot_results[i]\n",
    "    sect = sectional_results[i]\n",
    "    \n",
    "    print(f\"{i+1:2d} | {expected:10s} | {zero:9s} | {few:8s} | {sect:8s}\")\n",
    "\n",
    "# Analiza bÅ‚Ä™dÃ³w\n",
    "print(\"\\n--- ANALIZA BÅÄ˜DÃ“W ---\")\n",
    "categories = [\"nauka\", \"sport\", \"polityka\", \"technologia\"]\n",
    "\n",
    "for strategy_name, results in [(\"Zero-shot\", zero_shot_results), \n",
    "                               (\"Few-shot\", few_shot_results),\n",
    "                               (\"Sekcyjna\", sectional_results)]:\n",
    "    print(f\"\\n{strategy_name}:\")\n",
    "    errors = [(i, expected_categories[i], results[i]) \n",
    "              for i in range(len(results)) \n",
    "              if results[i] != expected_categories[i]]\n",
    "    \n",
    "    if errors:\n",
    "        for idx, expected, predicted in errors:\n",
    "            print(f\"  BÅ‚Ä…d {idx+1}: {expected} â†’ {predicted}\")\n",
    "            print(f\"    Tekst: {test_texts[idx][:60]}...\")\n",
    "    else:\n",
    "        print(\"  Brak bÅ‚Ä™dÃ³w!\")\n",
    "\n",
    "print(f\"\\n=== PODSUMOWANIE ===\")\n",
    "print(f\"Najlepsza strategia: \", end=\"\")\n",
    "best_accuracy = max(accuracy_zero, accuracy_few, accuracy_sectional)\n",
    "if best_accuracy == accuracy_sectional:\n",
    "    print(\"Sekcyjna\")\n",
    "elif best_accuracy == accuracy_few:\n",
    "    print(\"Few-shot\")  \n",
    "else:\n",
    "    print(\"Zero-shot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686aa156",
   "metadata": {},
   "source": [
    "Zadanie 7.5 Streszczenie i parafraza\n",
    "\n",
    "Generuj dwa streszczenia (krÃ³tkie i dÅ‚ugie) oraz parafrazÄ™ krÃ³tkiego.\n",
    "\n",
    "```python\n",
    "@'\n",
    "<ROLE>Tworzysz streszczenia i parafrazy. Odpowiadasz w JSON.</ROLE>\n",
    "<TEXT>\n",
    "Sztuczna inteligencja wspiera naukowcÃ³w w analizie danych medycznych,\n",
    "pomagajÄ…c szybciej diagnozowaÄ‡ choroby i tworzyÄ‡ spersonalizowane terapie.\n",
    "</TEXT>\n",
    "<OUTPUT>\n",
    "'@ | ollama run gemma2:2b\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56505e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORYGINALNY TEKST (140 sÅ‚Ã³w):\n",
      "Rewolucja w dziedzinie sztucznej inteligencji przyspiesza w zawrotnym tempie. Nowe modele jÄ™zykowe, \n",
      "takie jak GPT-4 czy Claude, potrafiÄ… juÅ¼ nie tylko generowaÄ‡ tekst, ale takÅ¼e rozumowaÄ‡, kodowaÄ‡ \n",
      "i rozwiÄ…zywaÄ‡ zÅ‚oÅ¼one problemy. Firmy technologiczne inwestujÄ… miliardy dolarÃ³w w rozwÃ³j AI, \n",
      "przewidujÄ…c, Å¼e bÄ™dzie to kluczowa technologia nastÄ™pnej dekady.\n",
      "\n",
      "Jednak rozwÃ³j sztucznej inteligencji niesie ze sobÄ… rÃ³wnieÅ¼ wyzwania. Eksperci ostrzegajÄ… przed \n",
      "ryzykiem utraty miejsc pracy w wielu sektorach, problemami z dezinformacjÄ… oraz kwestiami \n",
      "bezpieczeÅ„stwa cybernetycznego. RzÄ…dy na caÅ‚ym Å›wiecie pracujÄ… nad regulacjami, ktÃ³re miaÅ‚yby \n",
      "kontrolowaÄ‡ rozwÃ³j AI, zachowujÄ…c rÃ³wnowagÄ™ miÄ™dzy innowacjÄ… a bezpieczeÅ„stwem publicznym.\n",
      "\n",
      "W sektorze edukacji AI juÅ¼ teraz zmienia sposÃ³b nauczania i uczenia siÄ™. Spersonalizowane systemy \n",
      "edukacyjne dostosowujÄ… siÄ™ do indywidualnych potrzeb uczniÃ³w, podczas gdy nauczyciele korzystajÄ… \n",
      "z narzÄ™dzi AI do tworzenia materiaÅ‚Ã³w dydaktycznych i oceniania prac. PrzyszÅ‚oÅ›Ä‡ edukacji bÄ™dzie \n",
      "prawdopodobnie opieraÄ‡ siÄ™ na wspÃ³Å‚pracy miÄ™dzy czÅ‚owiekiem a sztucznÄ… inteligencjÄ….\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== WYNIKI STRESZCZANIA I PARAFRAZOWANIA ===\n",
      "\n",
      "KRÃ“TKIE STRESZCZENIE:\n",
      "â†’ AI rozwija siÄ™ szybko, generujÄ…c tekst i rozwiÄ…zujÄ…c problemy, ale niesie ze sobÄ… wyzwania w postaci utraty pracy i cyberbezpieczeÅ„stwa.\n",
      "  DÅ‚ugoÅ›Ä‡: 20 sÅ‚Ã³w\n",
      "\n",
      "DÅUGIE STRESZCZENIE:\n",
      "â†’ Technologia sztucznej inteligencji (AI) rozwija siÄ™ dynamicznie, z nowymi modelami jÄ™zykowymi takimi jak GPT-4 i Claude potrafiÄ…cy nie tylko generowaÄ‡ tekst, ale takÅ¼e rozumieÄ‡, kodowaÄ‡ i rozwiÄ…zywaÄ‡ zÅ‚oÅ¼one problemy. Firmy technologiczne inwestujÄ… miliardy dolarÃ³w w rozwÃ³j AI, widzÄ…c w nim kluczowÄ… technologiÄ™ przyszÅ‚oÅ›ci. Jednak rozwÃ³j AI niesie ze sobÄ… wyzwania, takie jak utrata miejsc pracy, dezinformacja i bezpieczeÅ„stwo cybernetyczne. RzÄ…dy na caÅ‚ym Å›wiecie pracujÄ… nad regulacjami, ktÃ³re miaÅ‚yby kontrolowaÄ‡ rozwÃ³j AI, zachowujÄ…c rÃ³wnowagÄ™ miÄ™dzy innowacjÄ… a bezpieczeÅ„stwem publicznym. W sektorze edukacji AI juÅ¼ teraz zmienia sposÃ³b nauczania i uczenia siÄ™. Spersonalizowane systemy edukacyjne dostosowujÄ… siÄ™ do indywidualnych potrzeb uczniÃ³w, podczas gdy nauczyciele korzystajÄ… z narzÄ™dzi AI do tworzenia materiaÅ‚Ã³w dydaktycznych i oceniania prac. PrzyszÅ‚oÅ›Ä‡ edukacji bÄ™dzie prawdopodobnie opieraÄ‡ siÄ™ na wspÃ³Å‚pracy miÄ™dzy czÅ‚owiekiem a sztucznÄ… inteligencjÄ….\n",
      "  DÅ‚ugoÅ›Ä‡: 126 sÅ‚Ã³w\n",
      "\n",
      "PARAFRAZA KRÃ“TKIEGO STRESZCZENIA:\n",
      "â†’ AI rozwija siÄ™ szybko i potrafi generowaÄ‡ tekst, rozumieÄ‡ kod i rozwiÄ…zywaÄ‡ problemy. Jednak rozwÃ³j AI niesie ze sobÄ… wyzwania, takie jak utrata miejsc pracy i cyberbezpieczeÅ„stwo. RzÄ…dy na caÅ‚ym Å›wiecie pracujÄ… nad regulacjami, ktÃ³re miaÅ‚yby kontrolowaÄ‡ rozwÃ³j AI.\n",
      "  DÅ‚ugoÅ›Ä‡: 39 sÅ‚Ã³w\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"JesteÅ› ekspertem od streszczania i parafrazowania tekstu. Zwracasz wyÅ‚Ä…cznie poprawny JSON.\"\n",
    "\n",
    "text = \"\"\"\n",
    "Rewolucja w dziedzinie sztucznej inteligencji przyspiesza w zawrotnym tempie. Nowe modele jÄ™zykowe, \n",
    "takie jak GPT-4 czy Claude, potrafiÄ… juÅ¼ nie tylko generowaÄ‡ tekst, ale takÅ¼e rozumowaÄ‡, kodowaÄ‡ \n",
    "i rozwiÄ…zywaÄ‡ zÅ‚oÅ¼one problemy. Firmy technologiczne inwestujÄ… miliardy dolarÃ³w w rozwÃ³j AI, \n",
    "przewidujÄ…c, Å¼e bÄ™dzie to kluczowa technologia nastÄ™pnej dekady.\n",
    "\n",
    "Jednak rozwÃ³j sztucznej inteligencji niesie ze sobÄ… rÃ³wnieÅ¼ wyzwania. Eksperci ostrzegajÄ… przed \n",
    "ryzykiem utraty miejsc pracy w wielu sektorach, problemami z dezinformacjÄ… oraz kwestiami \n",
    "bezpieczeÅ„stwa cybernetycznego. RzÄ…dy na caÅ‚ym Å›wiecie pracujÄ… nad regulacjami, ktÃ³re miaÅ‚yby \n",
    "kontrolowaÄ‡ rozwÃ³j AI, zachowujÄ…c rÃ³wnowagÄ™ miÄ™dzy innowacjÄ… a bezpieczeÅ„stwem publicznym.\n",
    "\n",
    "W sektorze edukacji AI juÅ¼ teraz zmienia sposÃ³b nauczania i uczenia siÄ™. Spersonalizowane systemy \n",
    "edukacyjne dostosowujÄ… siÄ™ do indywidualnych potrzeb uczniÃ³w, podczas gdy nauczyciele korzystajÄ… \n",
    "z narzÄ™dzi AI do tworzenia materiaÅ‚Ã³w dydaktycznych i oceniania prac. PrzyszÅ‚oÅ›Ä‡ edukacji bÄ™dzie \n",
    "prawdopodobnie opieraÄ‡ siÄ™ na wspÃ³Å‚pracy miÄ™dzy czÅ‚owiekiem a sztucznÄ… inteligencjÄ….\n",
    "\"\"\"\n",
    "\n",
    "print(f\"ORYGINALNY TEKST ({len(text.split())} sÅ‚Ã³w):\")\n",
    "print(text.strip())\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# PROMPT W SCHEMACIE SEKCYJNYM\n",
    "prompt = f\"\"\"\n",
    "<ROLE>\n",
    "JesteÅ› specjalistÄ… od przetwarzania tekstu. Tworzysz wysokiej jakoÅ›ci streszczenia i parafrazy.\n",
    "</ROLE>\n",
    "\n",
    "<RULES>\n",
    "1. KrÃ³tkie streszczenie: maksymalnie 25 sÅ‚Ã³w, zachowaj najwaÅ¼niejsze informacje\n",
    "2. DÅ‚ugie streszczenie: maksymalnie 70 sÅ‚Ã³w, uwzglÄ™dnij kluczowe szczegÃ³Å‚y\n",
    "3. Parafraza: przepisz krÃ³tkie streszczenie innymi sÅ‚owami, zachowaj sens\n",
    "4. ZwrÃ³Ä‡ wynik w formacie JSON\n",
    "</RULES>\n",
    "\n",
    "<INPUT>\n",
    "{text}\n",
    "</INPUT>\n",
    "\n",
    "<OUTPUT>\n",
    "{{\n",
    "  \"short_summary\": \"krÃ³tkie streszczenie (max 25 sÅ‚Ã³w)\",\n",
    "  \"long_summary\": \"dÅ‚ugie streszczenie (max 70 sÅ‚Ã³w)\", \n",
    "  \"paraphrase\": \"parafraza krÃ³tkiego streszczenia\"\n",
    "}}\n",
    "</OUTPUT>\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "result = json.loads(response['message']['content'])\n",
    "\n",
    "print(\"=== WYNIKI STRESZCZANIA I PARAFRAZOWANIA ===\\n\")\n",
    "\n",
    "print(\"KRÃ“TKIE STRESZCZENIE:\")\n",
    "print(f\"â†’ {result['short_summary']}\")\n",
    "print(f\"  DÅ‚ugoÅ›Ä‡: {len(result['short_summary'].split())} sÅ‚Ã³w\\n\")\n",
    "\n",
    "print(\"DÅUGIE STRESZCZENIE:\")\n",
    "print(f\"â†’ {result['long_summary']}\")\n",
    "print(f\"  DÅ‚ugoÅ›Ä‡: {len(result['long_summary'].split())} sÅ‚Ã³w\\n\")\n",
    "\n",
    "print(\"PARAFRAZA KRÃ“TKIEGO STRESZCZENIA:\")\n",
    "print(f\"â†’ {result['paraphrase']}\")\n",
    "print(f\"  DÅ‚ugoÅ›Ä‡: {len(result['paraphrase'].split())} sÅ‚Ã³w\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88a76268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PORÃ“WNANIE Z INNYM MODELEM ===\n",
      "\n",
      "MODEL: llama3.1:8b\n",
      "KrÃ³tkie: Rewolucja w sztucznej inteligencji przyspiesza, nowe modele jÄ™zykowe potrafiÄ… rozumowaÄ‡ i kodowaÄ‡.\n",
      "DÅ‚ugie: RozwÃ³j sztucznej inteligencji jest szybki, firmy inwestujÄ… miliardy dolarÃ³w. Eksperci ostrzegajÄ… przed ryzykiem utraty miejsc pracy i problemami z dezinformacjÄ…. RzÄ…dy pracujÄ… nad regulacjami.\n",
      "Parafraza: Sztuczna inteligencja przyspiesza, nowe technologie potrafiÄ… rozumowaÄ‡ i kodowaÄ‡, ale niesie rÃ³wnieÅ¼ ryzyko utraty miejsc pracy i problemÃ³w z dezinformacjÄ….\n"
     ]
    }
   ],
   "source": [
    "# TEST Z DRUGIM MODELEM\n",
    "print(\"=== PORÃ“WNANIE Z INNYM MODELEM ===\\n\")\n",
    "\n",
    "response2 = ollama.chat(\n",
    "    model='llama3.1:8b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "result2 = json.loads(response2['message']['content'])\n",
    "\n",
    "print(\"MODEL: llama3.1:8b\")\n",
    "print(f\"KrÃ³tkie: {result2['short_summary']}\")\n",
    "print(f\"DÅ‚ugie: {result2['long_summary']}\")\n",
    "print(f\"Parafraza: {result2['paraphrase']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca2edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = \"\"\"\n",
    "Komputery kwantowe wykorzystujÄ… zjawiska mechaniki kwantowej, takie jak superpozycja i splÄ…tanie, \n",
    "do przetwarzania informacji. W przeciwieÅ„stwie do klasycznych bitÃ³w, ktÃ³re mogÄ… byÄ‡ w stanie 0 lub 1, \n",
    "kubity (bity kwantowe) mogÄ… znajdowaÄ‡ siÄ™ w superpozycji obu stanÃ³w jednoczeÅ›nie.\n",
    "\n",
    "IBM zaprezentowaÅ‚o w 2023 roku procesor kwantowy Eagle z 433 kubitami, ktÃ³ry jest jednym z najbardziej \n",
    "zaawansowanych systemÃ³w komercyjnych. Google z kolei twierdzi, Å¼e osiÄ…gnÄ™Å‚o \"przewagÄ™ kwantowÄ…\" \n",
    "ze swoim procesorem Sycamore w 2019 roku, wykonujÄ…c obliczenia, ktÃ³re zajÄ™Å‚yby klasycznemu \n",
    "superkomputerowi tysiÄ…ce lat.\n",
    "\n",
    "GÅ‚Ã³wne zastosowania komputerÃ³w kwantowych obejmujÄ… kryptografiÄ™, optymalizacjÄ™, symulacje molekularne \n",
    "oraz uczenie maszynowe. Jednak technologia ta wciÄ…Å¼ boryka siÄ™ z problemami dekoherencji kwantowej \n",
    "i wysokimi wymaganiami dotyczÄ…cymi temperatury - wiÄ™kszoÅ›Ä‡ systemÃ³w wymaga chÅ‚odzenia do temperatur \n",
    "bliskich zeru absolutnemu.\n",
    "\n",
    "Eksperci przewidujÄ…, Å¼e praktyczne zastosowania komputerÃ³w kwantowych w przemyÅ›le stanÄ… siÄ™ powszechne \n",
    "dopiero za 10-15 lat, gdy technologia osiÄ…gnie wiÄ™kszÄ… stabilnoÅ›Ä‡ i skalowalnoÅ›Ä‡.\n",
    "\"\"\"\n",
    "\n",
    "questions_in_context = [\n",
    "    \"Ile kubitÃ³w ma procesor Eagle firmy IBM?\",\n",
    "    \"Jakie sÄ… gÅ‚Ã³wne zastosowania komputerÃ³w kwantowych?\",\n",
    "    \"Kiedy Google osiÄ…gnÄ™Å‚o przewagÄ™ kwantowÄ…?\",\n",
    "    \"Jakie sÄ… gÅ‚Ã³wne problemy komputerÃ³w kwantowych?\"\n",
    "]\n",
    "\n",
    "questions_out_of_context = [\n",
    "    \"Jaka jest cena procesora Eagle?\",\n",
    "    \"Kto jest CEO firmy IBM?\",\n",
    "    \"Gdzie produkowane sÄ… komputery kwantowe?\",\n",
    "    \"Ile kosztuje budowa komputera kwantowego?\"\n",
    "]\n",
    "\n",
    "print(f\"KONTEKST ({len(CONTEXT.split())} sÅ‚Ã³w):\")\n",
    "print(CONTEXT.strip())\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# WARIANT 1: BEZ ZASAD\n",
    "def qa_without_rules(context, question, model='gemma2:2b'):\n",
    "    \"\"\"QA bez specjalnych zasad - podstawowy prompt\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Na podstawie poniÅ¼szego tekstu odpowiedz na pytanie.\n",
    "\n",
    "    Tekst:\n",
    "    {context}\n",
    "\n",
    "    Pytanie: {question}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "# WARIANT 2: ZE ÅšCISÅYMI ZASADAMI\n",
    "def qa_with_strict_rules(context, question, model='gemma2:2b'):\n",
    "    \"\"\"QA ze Å›cisÅ‚ymi zasadami dotyczÄ…cymi odpowiedzi\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"\n",
    "    JesteÅ› precyzyjnym asystentem QA. Odpowiadaj WYÅÄ„CZNIE na podstawie dostarczonego kontekstu.\n",
    "    ZASADY:\n",
    "    1. JeÅ›li odpowiedÅº nie znajduje siÄ™ w kontekÅ›cie, odpowiedz: \"Brak wystarczajÄ…cych informacji\"\n",
    "    2. Cytuj fragment ÅºrÃ³dÅ‚owy w nawiasach [] gdy to moÅ¼liwe\n",
    "    3. BÄ…dÅº zwiÄ™zÅ‚y i konkretny\n",
    "    4. NIE dodawaj informacji spoza kontekstu\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    <KONTEKST>\n",
    "    {context}\n",
    "    </KONTEKST>\n",
    "\n",
    "    <PYTANIE>\n",
    "    {question}\n",
    "    </PYTANIE>\n",
    "\n",
    "    OdpowiedÅº:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "# WARIANT 3: FEW-SHOT Z PRZYKÅADAMI\n",
    "def qa_few_shot(context, question, model='gemma2:2b'):\n",
    "    \"\"\"QA z przykÅ‚adami few-shot\"\"\"\n",
    "    \n",
    "    SYSTEM = \"Odpowiadaj na pytania na podstawie kontekstu. JeÅ›li informacji brak, napisz 'Brak wystarczajÄ…cych informacji'.\"\n",
    "    \n",
    "    examples = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"Kontekst: Apple wydaÅ‚o iPhone 15 we wrzeÅ›niu 2023 z nowym procesorem A17 Pro. Pytanie: Kiedy wydano iPhone 15?\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": \"iPhone 15 wydano we wrzeÅ›niu 2023 [Apple wydaÅ‚o iPhone 15 we wrzeÅ›niu 2023].\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"Kontekst: Apple wydaÅ‚o iPhone 15 we wrzeÅ›niu 2023 z nowym procesorem A17 Pro. Pytanie: Jaka jest cena iPhone 15?\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Brak wystarczajÄ…cych informacji\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM}] + examples + [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"Kontekst: {context}\\nPytanie: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTOWANIE WARIANTÃ“W\n",
    "print(\"=== PORÃ“WNANIE WARIANTÃ“W PROMPTÃ“W ===\\n\")\n",
    "\n",
    "strategies = [\n",
    "    (\"Bez zasad\", qa_without_rules),\n",
    "    (\"ÅšcisÅ‚e zasady\", qa_with_strict_rules), \n",
    "    (\"Few-shot\", qa_few_shot)\n",
    "]\n",
    "\n",
    "# Test 1: Pytania w kontekÅ›cie\n",
    "print(\"--- PYTANIA W KONTEKÅšCIE ---\")\n",
    "for question in questions_in_context:\n",
    "    print(f\"\\nPYTANIE: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for strategy_name, strategy_func in strategies:\n",
    "        try:\n",
    "            answer = strategy_func(CONTEXT, question)\n",
    "            print(f\"{strategy_name:12}: {answer}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{strategy_name:12}: BÅÄ„D - {e}\")\n",
    "\n",
    "print(\"\\n\\n--- PYTANIA POZA KONTEKSTEM ---\")\n",
    "for question in questions_out_of_context:\n",
    "    print(f\"\\nPYTANIE: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for strategy_name, strategy_func in strategies:\n",
    "        try:\n",
    "            answer = strategy_func(CONTEXT, question)\n",
    "            print(f\"{strategy_name:12}: {answer}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{strategy_name:12}: BÅÄ„D - {e}\")\n",
    "\n",
    "# ANALIZA WYNIKÃ“W\n",
    "print(\"\\n\\n=== ANALIZA SKUTECZNOÅšCI ===\")\n",
    "\n",
    "def evaluate_answer(answer, should_have_info=True):\n",
    "    \"\"\"Prosta ewaluacja odpowiedzi\"\"\"\n",
    "    no_info_phrases = [\"brak wystarczajÄ…cych\", \"nie ma informacji\", \"brak informacji\", \n",
    "                      \"nie moÅ¼na odpowiedzieÄ‡\", \"nieznane\", \"brak danych\"]\n",
    "    \n",
    "    has_no_info_response = any(phrase in answer.lower() for phrase in no_info_phrases)\n",
    "    \n",
    "    if should_have_info:\n",
    "        return \"POPRAWNE\" if not has_no_info_response else \"BÅÄ˜DNE (faÅ‚szywy negatyw)\"\n",
    "    else:\n",
    "        return \"POPRAWNE\" if has_no_info_response else \"BÅÄ˜DNE (halucynacja)\"\n",
    "\n",
    "# Testowanie na przykÅ‚adach\n",
    "test_cases = [\n",
    "    (\"Ile kubitÃ³w ma procesor Eagle?\", True),\n",
    "    (\"Jaka jest cena procesora Eagle?\", False),\n",
    "    (\"Kiedy Google osiÄ…gnÄ™Å‚o przewagÄ™ kwantowÄ…?\", True),  \n",
    "    (\"Kto jest CEO firmy IBM?\", False)\n",
    "]\n",
    "\n",
    "print(\"\\nWYNIKI EWALUACJI:\")\n",
    "print(\"Strategia     | W kontekÅ›cie | Poza kontekstem | OgÃ³lna ocena\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for strategy_name, strategy_func in strategies:\n",
    "    correct_in = 0\n",
    "    correct_out = 0\n",
    "    \n",
    "    # Test pytaÅ„ w kontekÅ›cie\n",
    "    for question, should_have_info in [tc for tc in test_cases if tc[1]]:\n",
    "        answer = strategy_func(CONTEXT, question)\n",
    "        if \"POPRAWNE\" in evaluate_answer(answer, should_have_info):\n",
    "            correct_in += 1\n",
    "    \n",
    "    # Test pytaÅ„ poza kontekstem        \n",
    "    for question, should_have_info in [tc for tc in test_cases if not tc[1]]:\n",
    "        answer = strategy_func(CONTEXT, question)\n",
    "        if \"POPRAWNE\" in evaluate_answer(answer, should_have_info):\n",
    "            correct_out += 1\n",
    "            \n",
    "    total_score = (correct_in + correct_out) / 4 * 100\n",
    "    \n",
    "    print(f\"{strategy_name:12} | {correct_in}/2          | {correct_out}/2            | {total_score:.0f}%\")\n",
    "\n",
    "print(f\"\\n=== WNIOSKI ===\")\n",
    "print(\"1. Wariant 'ÅšcisÅ‚e zasady' najlepiej filtruje odpowiedzi\")\n",
    "print(\"2. 'Bez zasad' ma tendencjÄ™ do halucynacji\")  \n",
    "print(\"3. 'Few-shot' daje stabilne rezultaty dziÄ™ki przykÅ‚adom\")\n",
    "print(\"4. Cytowanie ÅºrÃ³deÅ‚ [] zwiÄ™ksza wiarygodnoÅ›Ä‡ odpowiedzi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
