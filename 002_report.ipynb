{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc8b708",
   "metadata": {},
   "source": [
    "# Sprawozdanie Lab 2: Skuteczne promptowanie modeli LLM w Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b36f3a",
   "metadata": {},
   "source": [
    "## Streszczenie\n",
    "W laboratorium przetestowałem 8 różnych zastosowań promptowania LLM:\n",
    "- NER, analiza sentymentu, ekstrakcja relacji\n",
    "- Klasyfikacja tematyczna z porównaniem strategii\n",
    "- Streszczenie i QA z kontekstem  \n",
    "- Praktyczny projekt asystenta turystycznego\n",
    "\n",
    "Najważniejsze wnioski: few-shot poprawia wyniki (chociaż w poniższych zadaniach nieznacznie, bo o pare procent zawzyczaj, natomiast warto by było przetestować znacznie trudniejsze przypadki z trudniejszym kontekstem), modele mają trudności z liczeniem i precyzyjnym cytowaniem, polski model Bielik częściej halucynuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc2f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ollama\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f356f6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Zadanie 7.1: NER (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f1dea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WYNIK NER - CYBERPUNK 2077 ===\n",
      "{\n",
      "  \"PERSON\": [\n",
      "    \"V\",\n",
      "    \"Psycho Squad\",\n",
      "    \"Trauma Team\" \n",
      "  ],\n",
      "  \"PRODUCT\": [\n",
      "    \"bronie\",\n",
      "    \"cyberwszczepy\",\n",
      "    \"robotyka\",\n",
      "    \"kosmetyczne poprawek\",\n",
      "    \"bronie palne\",\n",
      "    \"pociski\",\n",
      "    \"broń krótką\",\n",
      "    \"strzelbami\",\n",
      "    \"karabinami snajperskimi\",\n",
      "    \"bronie do walki w zwarciu\",\n",
      "    \"power (rykoszetująca)\",\n",
      "    \"tech (przebijająca ściany i przeciwników)\",\n",
      "    \"smart (z naprowadzanymi pociskami)\" \n",
      "  ],\n",
      "  \"ART\": [\n",
      "    \"Cyberpunk 2077\",\n",
      "    \"Night City\"\n",
      "  ],\n",
      "  \"EVENT\": [\n",
      "    \"wojna gangów\",\n",
      "    \"walka o dominację\",\n",
      "    \"napaść\"\n",
      "  ],\n",
      "  \"OBJECT\": [\n",
      "    \"osłony\",\n",
      "    \"robotyka\",\n",
      "    \"bronie palne\",\n",
      "    \"cyberwszczepy\",\n",
      "    \"pociski\",\n",
      "    \"broń krótką\",\n",
      "    \"strzelbami\",\n",
      "    \"karabinami snajperskimi\",\n",
      "    \"bronie do walki w zwarciu\",\n",
      "    \"power (rykoszetująca)\",\n",
      "    \"tech (przebijająca ściany i przeciwników)\",\n",
      "    \"smart (z naprowadzanymi pociskami)\" \n",
      "  ],\n",
      "  \"BRAND\": [\n",
      "    \"Night City\",\n",
      "    \"korporacje\",\n",
      "    \"wojsko\",\n",
      "    \"Psycho Squad\",\n",
      "    \"Trauma Team\"\n",
      "  ],\n",
      "  \"NORP\": [\n",
      "    \"Ameryka\",\n",
      "    \"Wolny Stany Kalifornia Północna\" \n",
      "  ],\n",
      "  \"DATE-PERIOD\": [\n",
      "    \"okresy czasu\"\n",
      "  ]\n",
      "}\n",
      "=== WYNIK NER - CYBERPUNK 2077 (Bielik 1.5B) ===\n",
      "{\n",
      "  \"PERSON\": [\"V\", \"Ripperdoc\", \"Trauma Team\", \"Psycho Squad\"],\n",
      "  \"PRODUCT\": [\"Cyberpunk 2077\", \"cyberwszczepy\", \"bronie do walki w zwarciu\", \"bronie palna\", \"bronie dystansowe\", \"bronie ogłuszające\", \"bronie ulepszające skradanie się\", \"bronie elektryczne\", \"bronie chemiczne\", \"bronie termiczne\"],\n",
      "  \"ART\": [\"Cyberpunk 2077: Night City\", \"Cyberpunk 2077: Night City: Entropic Era\", \"Cyberpunk 2077: Night City: Neomilitary Era\", \"Cyberpunk 2077: Night City: Neokitchen Era\"],\n",
      "  \"EVENT\": [\"wojna gangów\", \"konkurencja o dominację\", \"bezdomność\", \"cybermodyfikacje\", \"przemoc\"],\n",
      "  \"OBJECT\": [\"osłony\", \"celowanie\", \"bieganie\", \"ślizgi\", \"skoki\", \"podwójne skoki\", \"broń do walki w zwarciu\", \"broń palna\", \"broń dystansowa\", \"broń ogłuszająca\", \"broń ulepszająca skradanie się\"],\n",
      "  \"BRAND\": [\"Cyberpunk 2077\", \"Ripperdoc\", \"Trauma Team\", \"Psycho Squad\"],\n",
      "  \"NORP\": [\"Kalifornia Północna\", \"Wolny Stan Kalifornia Północna\"],\n",
      "  \"DATE-PERIOD\": [\"XXI wiek\", \"XXII wiek\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"Jesteś precyzyjnym ekstraktorem nazw własnych. Analizuj tekst i klasyfikuj jednostki według podanych kategorii NER.\"\n",
    "\n",
    "prompt = \"\"\"Znajdź i sklasyfikuj wszystkie jednostki NER w tekście według poniższych kategorii:\n",
    "- PERSON: nazwani bohaterowie\n",
    "- PRODUCT: produkty, towary wytworzone przez człowieka  \n",
    "- ART: tytuły gier, filmów, książek, dzieł\n",
    "- EVENT: wydarzenia, bitwy, wojny\n",
    "- OBJECT: zamknięte przestrzenie, przedmioty\n",
    "- BRAND: marki, firmy, producenci\n",
    "- NORP: narodowości, grupy kulturowe\n",
    "- DATE-PERIOD: przedziały czasu, pory\n",
    "\n",
    "Zwróć wynik w formacie JSON.\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "Cyberpunk 2077 jest fabularną grą akcji, zawierającą elementy strzelanek pierwszoosobowych. Gracz wciela się w V, którego płeć, głos, wygląd (twarz, fryzurę, sylwetkę, modyfikacje ciała, rozmiar przyrodzenia czy biustu), pochodzenie i ubiór może dostosować według własnych upodobań. W grze nie ma podziału na klasy postaci, natomiast gracz określa swój sposób gry poprzez rozwijanie cech – budowy ciała, inteligencji, refleksu, zdolności technicznych i opanowania. Postać może rozwijać umiejętności walki wręcz, posługiwania się ostrzami, bronią krótką, strzelbami, karabinami, karabinami snajperskimi, dwiema broniami, jak również hakowania, skrytobójstwa, „zimnej krwi\", inżynierii i sprawności fizycznej. W celu nabycia bądź ulepszenia cyberwszczepów, V musi odwiedzić ripperdoca, z kolei na czarnym rynku kupić może ulepszenia wojskowe. Rzadkość znajdowanego wyposażenia określana jest przez system poziomów, reprezentowanych odpowiednimi kolorami. Przemieszczając się po świecie gry, postać może chować się za osłonami, celować, biegać, wykonywać ślizgi, skoki i podwójne skoki. Ataki wręcz można wyprowadzać za pomocą broni do walki w zwarciu, z kolei broń palna może być modyfikowana i dzieli się na typy Power (rykoszetująca), Tech (przebijająca ściany i przeciwników) oraz Smart (z naprowadzanymi pociskami). Pociski z broni dystansowych można spowolnić w trybie bullet time. W grze pojawiają się cztery rodzaje zadawanych i otrzymywanych obrażeń: fizyczne, termiczne, elektromagnetyczne i chemiczne. Cyberpunk 2077 oferuje również bronie i cyberwszczepy ogłuszające czy ulepszające skradanie się, wobec czego grę można ukończyć bez zabijania kogokolwiek.\n",
    "Night City jest amerykańskim megamiastem w Wolnym Stanie Kalifornia Północna, kontrolowanym przez korporacje, w którym nie obowiązują prawa krajowe i stanowe. Ogarnięte jest wojną gangów i rządzących nim osób, które walczą o dominację. W kwestiach codziennych, takich jak wywóz śmieci czy transport publiczny, mieszkańcy polegają na robotyce. Pod względem wizualnym ukształtowały je cztery epoki, które przeszło – surowy „entropizm”, kolorowy kicz, surowy neomilitaryzm i wystawny neokicz. Internet kontrolowany jest przez korporacje i wojsko. Chociaż w Night City powszechna jest bezdomność, nie wyklucza ona z możliwości korzystania z cybermodyfikacji, prowadząc do uzależnienia od kosmetycznych poprawek i przemocy. Z takimi zagrożeniami mierzy się uzbrojona organizacja znana jako Psycho Squad. Szybkiej pomocy medycznej udzielić może Trauma Team, zaś ze względu na bezustanne zagrożenie napaścią, wszyscy mieszkańcy mają prawo noszenia broni w miejscu publicznym\n",
    "\"\"\"\n",
    "\n",
    "output_format = \"\"\"\n",
    "{\n",
    "  \"PERSON\": [\"imiona bohaterów\"],\n",
    "  \"PRODUCT\": [\"produkty, towary\"],\n",
    "  \"ART\": [\"tytuły gier, filmów\"],\n",
    "  \"EVENT\": [\"wydarzenia, bitwy\"],\n",
    "  \"OBJECT\": [\"przedmioty, bronie\"],\n",
    "  \"BRAND\": [\"marki, firmy\"],\n",
    "  \"NORP\": [\"narodowości, grupy\"],\n",
    "  \"DATE-PERIOD\": [\"okresy czasu\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nTekst:\\n{text}\\n\\nFormat:\\n{output_format}\"}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "print(\"=== WYNIK NER - CYBERPUNK 2077 ===\")\n",
    "print(response['message']['content'])\n",
    "\n",
    "response_pl = ollama.chat(\n",
    "    model='SpeakLeash/bielik-1.5b-v3.0-instruct:Q8_0',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nTekst:\\n{text}\\n\\nFormat:\\n{output_format}\"}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "print(\"=== WYNIK NER - CYBERPUNK 2077 (Bielik 1.5B) ===\")\n",
    "print(response_pl['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264af4d",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "\n",
    "Model gemma2:2b wykazał dość trafnie przyporządkował i wykestrahował poszczególne nazwy własne, chociaż z niektórymi rzeczami miał trudności. \n",
    "\"Psycho Squad\", \"Trauma Team\" to są raczej frakcje lub grupy, a nie pojedyncze osoby czy organizacje, model podał je jako osoby. Date-period podaje jako \"okres czasu\", co jest poprawne, ale nie jest to standardowa kategoria NER, w tej kateogrii brakuje daty 2077. W Brand podaje \"wojsko\" czy też \"korporacje\" co jest zbyt ogólne. Źle zrozumiał nazwe własną \"Object\" jako rzecz/obiekt a nie przestrzeń w której odbywa się akcja gry/przebywają bohaterowie, co pokazuje, że model ma trudności z kontekstem. Ogólnie jednak model radzi sobie całkiem dobrze z rozpoznawaniem nazw własnych w tekście. \n",
    "\n",
    "Bielik znacznie gorzej, zaczynał halucynować i podawać różne nieistniejące w tekście nazwy takie jak Cyberpunk 2077: Night City: Entropic Era itd.\n",
    "Podał w \"PERSON\" nazwe \"Ripperdoc\" co jest technicznie poprawne, chociaż nie jest to imię bohatera, a raczej profesji. W date-period halucynował. Polski model poradził sobie gorzej, mniej poprawnych przynależności do poszczeólnych kategorii jak i więcej halucynacji. \n",
    "\n",
    "Źródło: https://literacka.com.pl/2021/08/analiza-ner-czyli-o-czytaniu-tekstu-za-pomoca-sztucznej-inteligencji/    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7b7bd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Zadanie 7.2: Analiza sentymentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2feef79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALIZA SENTYMENTU - PRZYKŁADY WŁASNE ===\n",
      "\n",
      "--- MODEL: gemma2:2b ---\n",
      "POZYTYWNY:\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"confidence\": 9,\n",
      "  \"evidence\": [\n",
      "    \"perełka\",\n",
      "    \"uprzejma i profesjonalna\",\n",
      "    \"smakły jak u babci\",\n",
      "    \"idealnie chrupiący\",\n",
      "    \"ciepła i przytulna\",\n",
      "    \"z całego serca polecam!\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "SARKASTYCZNY:\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"confidence\": 9,\n",
      "  \"evidence\": [\n",
      "    \"arcydzieło\",\n",
      "    \"fantastyczna przygoda\",\n",
      "    \"profesjonalna\",\n",
      "    \"świetny\",\n",
      "    \"polecam\",\n",
      "    \"marnować czas i pieniądze\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "NEUTRALNY:\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"confidence\": 7,\n",
      "  \"evidence\": [\n",
      "    \"Restauracja mieści się przy ulicy Głównej 15.\",\n",
      "    \"Oferuje dania kuchni polskiej i międzynarodowej.\",\n",
      "    \"Godziny otwarcia: poniedziałek-piątek 12:00-22:00, sobota-niedziela 14:00-23:00.\",\n",
      "    \"Menu dostępne online i w lokalu.\",\n",
      "    \"Możliwość rezerwacji stolików telefonicznych.\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- MODEL: llama3.1:8b ---\n",
      "POZYTYWNY:\n",
      "{\n",
      "  \"sentiment\": \"pozytywny\",\n",
      "  \"confidence\": 10,\n",
      "  \"evidence\": [\n",
      "    \"prawdziwa perełka\",\n",
      "    \"niezwykle uprzejma\",\n",
      "    \"profesjonalna\",\n",
      "    \"smakowały jak u babci\",\n",
      "    \"chrupiący\",\n",
      "    \"ciepła i przytulna\",\n",
      "    \"ceny rozsądne\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "SARKASTYCZNY:\n",
      "{\n",
      "  \"sentiment\": \"negatywny\",\n",
      "  \"confidence\": 8,\n",
      "  \"evidence\": [\n",
      "    \"kelner zapomniał o naszym stoliku\",\n",
      "    \"ceny\",\n",
      "    \"marnować czas i pieniądze\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "NEUTRALNY:\n",
      "{\n",
      "  \"sentiment\": \"neutralny\",\n",
      "  \"confidence\": 8,\n",
      "  \"evidence\": [\n",
      "    \"oferuje dania kuchni polskiej i międzynarodowej\",\n",
      "    \"menu dostępne online i w lokalu\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== TEST ROZPOZNAWANIA SARKAZMU ===\n",
      "ANALIZA SARKAZMU:\n",
      "{\n",
      "  \"literal_sentiment\": \"negatywny\",\n",
      "  \"detected_sarcasm\": true,\n",
      "  \"actual_sentiment\": \"negatywny\",\n",
      "  \"sarcasm_indicators\": [\n",
      "    \"45 minut na zimne jedzenie to była 'fantastyczna' przygoda.\",\n",
      "    \"profesjonalna\",\n",
      "    \"zapomniał o naszym stoliku.\",\n",
      "    \"'świetny' stosunek jakości do ceny - płacisz za restaurację, a dostajesz jakość fast-foodu.\",\n",
      "    \"polecam wszystkim, którzy lubią marnować czas i pieniądze.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"Jesteś precyzyjnym analizatorem wydźwięku tekstu. Zwracaj wyłącznie poprawny JSON według podanej specyfikacji.\"\n",
    "\n",
    "def analyze_sentiment(text, model_name='gemma2:2b'):\n",
    "    prompt = f\"\"\"Określ wydźwięk (pozytywny/negatywny/neutralny) poniższego tekstu.\n",
    "    Zwróć JSON z kluczami: \"sentiment\", \"confidence\" (1-10), \"evidence\" (najważniejsze słowa/frazy).\n",
    "    \n",
    "    Tekst: {text}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        format=\"json\",\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "# Przykład 1: Pozytywna recenzja restauracji\n",
    "positive_review = \"\"\"\n",
    "Restauracja \"Smaki Polski\" to prawdziwa perełka! Obsługa była niezwykle uprzejma i profesjonalna. \n",
    "Pierogi robione na miejscu smakowały jak u babci, a kotlet schabowy był idealnie chrupiący. \n",
    "Atmosfera ciepła i przytulna, ceny rozsądne. Z całego serca polecam!\n",
    "\"\"\"\n",
    "\n",
    "# Przykład 2: Sarkastyczna recenzja (negatywna ukryta w ironii)\n",
    "sarcastic_review = \"\"\"\n",
    "Wow, ta restauracja to prawdziwe \"arcydzieło\"! Czekanie 45 minut na zimne jedzenie to była \n",
    "\"fantastyczna\" przygoda. Obsługa tak \"profesjonalna\", że kelner zapomniał o naszym stoliku. \n",
    "A te ceny! Naprawdę \"świetny\" stosunek jakości do ceny - płacisz za restaurację, \n",
    "a dostajesz jakość fast-foodu. Zdecydowanie \"polecam\" wszystkim, którzy lubią \n",
    "marnować czas i pieniądze.\n",
    "\"\"\"\n",
    "\n",
    "# Przykład 3: Neutralny opis faktyczny\n",
    "neutral_text = \"\"\"\n",
    "Restauracja mieści się przy ulicy Głównej 15. Oferuje dania kuchni polskiej i międzynarodowej. \n",
    "Godziny otwarcia: poniedziałek-piątek 12:00-22:00, sobota-niedziela 14:00-23:00. \n",
    "Menu dostępne online i w lokalu. Możliwość rezerwacji stolików telefonicznych.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== ANALIZA SENTYMENTU - PRZYKŁADY WŁASNE ===\\n\")\n",
    "\n",
    "# Test na różnych modelach\n",
    "models = ['gemma2:2b', 'llama3.1:8b']\n",
    "\n",
    "for model in models:\n",
    "    print(f\"--- MODEL: {model} ---\")\n",
    "    \n",
    "    try:\n",
    "        # Pozytywny\n",
    "        result1 = analyze_sentiment(positive_review, model)\n",
    "        print(\"POZYTYWNY:\")\n",
    "        print(json.dumps(json.loads(result1), indent=2, ensure_ascii=False))\n",
    "        \n",
    "        # Sarkastyczny\n",
    "        result2 = analyze_sentiment(sarcastic_review, model) \n",
    "        print(\"\\nSARKASTYCZNY:\")\n",
    "        print(json.dumps(json.loads(result2), indent=2, ensure_ascii=False))\n",
    "        \n",
    "        # Neutralny\n",
    "        result3 = analyze_sentiment(neutral_text, model)\n",
    "        print(\"\\nNEUTRALNY:\")\n",
    "        print(json.dumps(json.loads(result3), indent=2, ensure_ascii=False))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Błąd dla modelu {model}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Dodatkowy test - czy model rozpoznaje sarkasm\n",
    "print(\"=== TEST ROZPOZNAWANIA SARKAZMU ===\")\n",
    "\n",
    "sarcasm_prompt = \"\"\"\n",
    "Przeanalizuj poniższy tekst pod kątem:\n",
    "1. Dosłownego znaczenia słów\n",
    "2. Prawdopodobnego sarkazmu/ironii\n",
    "3. Rzeczywistego wydźwięku\n",
    "\n",
    "Zwróć JSON: {\n",
    "  \"literal_sentiment\": \"pozytywny/negatywny/neutralny\",\n",
    "  \"detected_sarcasm\": true/false,\n",
    "  \"actual_sentiment\": \"pozytywny/negatywny/neutralny\",\n",
    "  \"sarcasm_indicators\": [\"lista wskaźników sarkazmu\"]\n",
    "}\n",
    "\n",
    "Tekst: \"\"\" + sarcastic_review\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Jesteś ekspertem od analizy stylistycznej tekstu, specjalizującym się w wykrywaniu sarkazmu i ironii.\"},\n",
    "        {\"role\": \"user\", \"content\": sarcasm_prompt}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "print(\"ANALIZA SARKAZMU:\")\n",
    "print(json.dumps(json.loads(response['message']['content']), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a6492",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "\n",
    "Model nie radzi sobie dobrze z analizą sentymentu w języku polskim, co może wynikać z mniejszej ilości danych treningowych w tym języku. Pomyłił sarkastyczny komentarzy jako bardzo pozytywny, co pokazuje, że ma trudności z rozpoznawaniem niuansów językowych. W pozostałych 2 przypadkach poradził sobie dobrze, poprawnie klasyfikując sentyment jako pozytywny i neutralny. Model llama3.1 już we wszystkich 3 przypadkach poradził sobie dobrze, poprawnie klasyfikując sentyment jako pozytywny, neutralny i negatywny.\n",
    "Natomiast udało się dodać odpowiedni prompt do modelu gemma2:2b, twierdząc, że jest to model który ma sobie dobrze radzić w przypadku sarkastycznych wypowiedzi i w ten sposób poprawić jego skuteczność w tym zakresie. W ten sposób model gemma2:2b poradził sobie dobrze we wszystkich 3 przypadkach poprawnie je klasyfikując."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c4837a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Zadanie 7.3: Ekstrakcja relacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75714745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EKSTRAKCJA RELACJI - PRZYKŁADY WŁASNE ===\n",
      "\n",
      "--- TEKST DO ANALIZY ---\n",
      "Dr Aleksandra Wiśniewska jest profesorem na Uniwersytecie Jagiellońskim w Krakowie. \n",
      "    Mieszka w Warszawie, ale dojeżdża do pracy. Wcześniej pracowała w Institute of Technology w Bostonie, \n",
      "    gdzie mieszkała przez 5 lat.\n",
      "\n",
      "```json\n",
      "[{\"person\": \"Dr Aleksandra Wiśniewska\", \"relation\": \"MIESZKA_W\", \"target\": \"Kraków\"}, {\"person\": \"Dr Aleksandra Wiśniewska\", \"relation\": \"MIESZKA_W\", \"target\": \"Warszawa\"}]\n",
      "``` \n",
      "\n",
      "\n",
      "\n",
      "--- TEKST DO ANALIZY ---\n",
      "Michał Zieliński to programista w firmie CD Projekt. Mieszka w Gdańsku, ale pracuje \n",
      "    zdalnie. Jego żona Anna Zielińska pracuje w szpitalu miejskim w Gdańsku jako lekarka.\n",
      "\n",
      "[{\"person\": \"Michał Zieliński\", \"relation\": \"PRACUJE_W\", \"target\": \"CD Projekt\"}, {\"person\": \"Michał Zieliński\", \"relation\": \"MIESZKA_W\", \"target\": \"Gdańsk\"}, {\"person\": \"Anna Zielińska\", \"relation\": \"PRACUJE_W\", \"target\": \"szpital miejski w Gdańsku\"}, {\"person\": \"Anna Zielińska\", \"relation\": \"MIESZKA_W\", \"target\": \"Gdańsk\"}] \n",
      "\n",
      "--- TEKST DO ANALIZY ---\n",
      "Startup TechnoVision został założony przez Pawła Nowaka, który mieszka w Poznaniu. \n",
      "    Firma ma biura w Warszawie i Wrocławiu. Paweł wcześniej pracował w Microsoft Poland.\n",
      "\n",
      "```json\n",
      "[{\"person\": \"Pawel Nowak\", \"relation\": \"MIESZKA_W\", \"target\": \"Poznań\"}, {\"person\": \"Pawel Nowak\", \"relation\": \"PRACUJE_W\", \"target\": \"Microsoft Poland\"}, {\"person\": \"Pawel Nowak\", \"relation\": \"PRACUJE_W\", \"target\": \"Startup TechnoVision\"}]\n",
      "``` \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"Jesteś precyzyjnym analizatorem tekstu. Znajdź TYLKO relacje PRACUJE_W i MIESZKA_W. Zwróć sformatowaną tablicę JSON.\"\n",
    "\n",
    "# Few-shot przykłady do trenowania modelu\n",
    "shots = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Tekst: \\\"Maria Nowak pracuje w banku PKO BP jako analityk finansowy.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": '[{\"person\": \"Maria Nowak\", \"relation\": \"PRACUJE_W\", \"target\": \"PKO BP\"}]'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Tomasz Kowalski mieszka w Krakowie i pracuje w firmie Google.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": '[{\"person\": \"Tomasz Kowalski\", \"relation\": \"MIESZKA_W\", \"target\": \"Kraków\"}, {\"person\": \"Tomasz Kowalski\", \"relation\": \"PRACUJE_W\", \"target\": \"Google\"}]'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Jan Nowak mieszka w Warszawie. Obecnie pracuje w Microsoft, ale wcześniej był zatrudniony w IBM.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": '[{\"person\": \"Jan Nowak\", \"relation\": \"MIESZKA_W\", \"target\": \"Warszawa\"}, {\"person\": \"Jan Nowak\", \"relation\": \"PRACUJE_W\", \"target\": \"Microsoft\"}]'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Przykładowe teksty do analizy\n",
    "test_texts = [\n",
    "    \"\"\"\n",
    "    Dr Aleksandra Wiśniewska jest profesorem na Uniwersytecie Jagiellońskim w Krakowie. \n",
    "    Mieszka w Warszawie, ale dojeżdża do pracy. Wcześniej pracowała w Institute of Technology w Bostonie, \n",
    "    gdzie mieszkała przez 5 lat.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Michał Zieliński to programista w firmie CD Projekt. Mieszka w Gdańsku, ale pracuje \n",
    "    zdalnie. Jego żona Anna Zielińska pracuje w szpitalu miejskim w Gdańsku jako lekarka.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Startup TechnoVision został założony przez Pawła Nowaka, który mieszka w Poznaniu. \n",
    "    Firma ma biura w Warszawie i Wrocławiu. Paweł wcześniej pracował w Microsoft Poland.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(\"=== EKSTRAKCJA RELACJI - PRZYKŁADY WŁASNE ===\\n\")\n",
    "\n",
    "# Test few-shot z przykładami\n",
    "for text in test_texts:\n",
    "    print(f\"--- TEKST DO ANALIZY ---\\n{text.strip()}\\n\")\n",
    "\n",
    "    shots_with_test = shots + [\n",
    "        {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "    ]\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='gemma2:2b',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            *shots_with_test\n",
    "        ]\n",
    "    )\n",
    "    print(response['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6453f76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EKTRAKCJA RELACJI - TEST NA MODELU BIELIK 1.5B ===\n",
      "\n",
      "--- TEKST DO ANALIZY ---\n",
      "Dr Aleksandra Wiśniewska jest profesorem na Uniwersytecie Jagiellońskim w Krakowie. \n",
      "    Mieszka w Warszawie, ale dojeżdża do pracy. Wcześniej pracowała w Institute of Technology w Bostonie, \n",
      "    gdzie mieszkała przez 5 lat.\n",
      "\n",
      "[{\"person\": \"Dr Aleksanara Wiśniewska\", \"related_persons\": [\"Institute of Technology in Boston\"], \"related_place\": \"Kraków, Warszawa\"}]\n",
      "--- TEKST DO ANALIZY ---\n",
      "Michał Zieliński to programista w firmie CD Projekt. Mieszka w Gdańsku, ale pracuje \n",
      "    zdalnie. Jego żona Anna Zielińska pracuje w szpitalu miejskim w Gdańsku jako lekarka.\n",
      "\n",
      "[{\"person\": \"Michał Zieliński\", \"relation\": \"MIESZKA_W\", \"target\": \"CD Projekt\"}, {\"personal\": \"Anna Zielińska\", \"related\": \"PROCEDENT\", \"target\": \"Gdańsk\", \"type\": \"lekarz\"}]\n",
      "--- TEKST DO ANALIZY ---\n",
      "Startup TechnoVision został założony przez Pawła Nowaka, który mieszka w Poznaniu. \n",
      "    Firma ma biura w Warszawie i Wrocławiu. Paweł wcześniej pracował w Microsoft Poland.\n",
      "\n",
      "[{\"person\": \"Paweł Nowak\", \"relation\": \"MIESZKA_W\", \"target\": \"Poznań\"}, {\"personal\": \"TechnoVision\", \"related\": \"Startup\", \"target\": \"Warszawa\"}, {\"personal\": \"TechnoVision\", \"related\": \"Startup\", \"target\": \"Wrocław\"}]\n"
     ]
    }
   ],
   "source": [
    "print (\"=== EKTRAKCJA RELACJI - TEST NA MODELU BIELIK 1.5B ===\\n\")\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"--- TEKST DO ANALIZY ---\\n{text.strip()}\\n\")\n",
    "\n",
    "    shots_with_test = shots + [\n",
    "        {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "    ]\n",
    "    response = ollama.chat(\n",
    "        model='SpeakLeash/bielik-1.5b-v3.0-instruct:Q8_0',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            *shots_with_test\n",
    "        ],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec850f0b",
   "metadata": {},
   "source": [
    "**Wnioski**\n",
    "\n",
    "Model początkowo miał trudności z poprawnym zidentyfikowaniem relacji, podawał i tworzył własne relacje, które istniały w tekście, nie zawsze poprawnie je klasyfikując. Musiałem wymusić w promptcie, aby model skupił się tylko na relacjach MIESZKA_W oraz PRACUJE_W. Po dodaniu tego do promptu model radził sobie już lepiej, identyfikując tylko interesujące nas relacje. Całkiem nieźle klasyfikował relacje, chociaż w 1 przypadku nie podał w ogóle relacji PRACUJE_W oraz podał 2 relacje MIESZKA_W zamiast jednej. Widocznie model ma trudności z zrozumieniem czasu przeszłego i teraźniejszego w kontekście relacji. \n",
    "\n",
    "Bielik natomiast średnio sobie radził, niektóre relacje rzeczywiście były poprawne, ale wymyślał własne klucze w jsonie, własne nazwy i relacje, często mało zrozumiale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc146e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Zadanie 7.4: Klasyfikacja tematyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a74c1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zbiór testowych tekstów z różnych kategorii\n",
    "test_texts = [\n",
    "    \"Nowy mikroskop pozwala obserwować pojedyncze atomy w czasie rzeczywistym.\",\n",
    "    \"Robert Lewandowski strzelił hat-tricka w meczu przeciwko Bayernowi Monachium.\",\n",
    "    \"Parlament przyjął ustawę o reformie systemu podatkowego większością głosów.\",\n",
    "    \"Sztuczna inteligencja ChatGPT-4 osiągnęła przełomowe wyniki w testach językowych.\",\n",
    "    \"Naukowcy z MIT odkryli nowy materiał przewodzący prąd w temperaturze pokojowej.\",\n",
    "    \"Reprezentacja Polski awansowała do półfinału mistrzostw świata w siatkówce.\",\n",
    "    \"Premier zapowiedział zwiększenie wydatków na ochronę zdrowia w przyszłym roku.\",\n",
    "    \"Apple przedstawiło nowy procesor M3 z architekturą 3-nanometrową.\"\n",
    "]\n",
    "\n",
    "# Oczekiwane kategorie (dla weryfikacji)\n",
    "expected_categories = [\n",
    "    \"nauka\", \"sport\", \"polityka\", \"technologia\", \n",
    "    \"nauka\", \"sport\", \"polityka\", \"technologia\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b409bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WARIANT 1: ZERO-SHOT ---\n",
      "1. Nowy mikroskop pozwala obserwować pojedyncze atomy...\n",
      "   Przewidziano: technologia | Oczekiwano: nauka\n",
      "2. Robert Lewandowski strzelił hat-tricka w meczu prz...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "3. Parlament przyjął ustawę o reformie systemu podatk...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "4. Sztuczna inteligencja ChatGPT-4 osiągnęła przełomo...\n",
      "   Przewidziano: technologia | Oczekiwano: technologia\n",
      "5. Naukowcy z MIT odkryli nowy materiał przewodzący p...\n",
      "   Przewidziano: technologia | Oczekiwano: nauka\n",
      "6. Reprezentacja Polski awansowała do półfinału mistr...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "7. Premier zapowiedział zwiększenie wydatków na ochro...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "8. Apple przedstawiło nowy procesor M3 z architekturą...\n",
      "   Przewidziano: technologia | Oczekiwano: technologia\n"
     ]
    }
   ],
   "source": [
    "# WARIANT 1: ZERO-SHOT\n",
    "print(\"--- WARIANT 1: ZERO-SHOT ---\")\n",
    "\n",
    "SYSTEM_ZERO = (\n",
    "    \"Jesteś klasyfikatorem tematów. Przypisz tekst do JEDNEJ kategorii \"\n",
    "    \"z zestawu: nauka, sport, polityka, technologia. \"\n",
    "    \"Zwróć wyłącznie JSON: {\\\"kategoria\\\":\\\"...\\\"}.\"\n",
    ")\n",
    "\n",
    "zero_shot_results = []\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='gemma2:2b',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_ZERO},\n",
    "                {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "            ],\n",
    "            format=\"json\",\n",
    "            options={\"temperature\": 0}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response['message']['content'])\n",
    "        predicted = result.get('kategoria', 'BŁĄD')\n",
    "        zero_shot_results.append(predicted)\n",
    "        \n",
    "        print(f\"{i+1}. {text[:50]}...\")\n",
    "        print(f\"   Przewidziano: {predicted} | Oczekiwano: {expected_categories[i]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Błąd: {e}\")\n",
    "        zero_shot_results.append('BŁĄD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33dfaedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WARIANT 2: FEW-SHOT ---\n",
      "1. Nowy mikroskop pozwala obserwować pojedyncze atomy...\n",
      "   Przewidziano: nauka | Oczekiwano: nauka\n",
      "2. Robert Lewandowski strzelił hat-tricka w meczu prz...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "3. Parlament przyjął ustawę o reformie systemu podatk...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "4. Sztuczna inteligencja ChatGPT-4 osiągnęła przełomo...\n",
      "   Przewidziano: nauka, technologia | Oczekiwano: technologia\n",
      "5. Naukowcy z MIT odkryli nowy materiał przewodzący p...\n",
      "   Przewidziano: nauka | Oczekiwano: nauka\n",
      "6. Reprezentacja Polski awansowała do półfinału mistr...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "7. Premier zapowiedział zwiększenie wydatków na ochro...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "8. Apple przedstawiło nowy procesor M3 z architekturą...\n",
      "   Przewidziano: technologia | Oczekiwano: technologia\n"
     ]
    }
   ],
   "source": [
    "# WARIANT 2: FEW-SHOT\n",
    "print(\"\\n--- WARIANT 2: FEW-SHOT ---\")\n",
    "\n",
    "SYSTEM_FEW = \"Klasyfikuj teksty do jednej z kategorii: nauka, sport, polityka, technologia.\"\n",
    "\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Badacze z Harvardu opracowali nową szczepionkę przeciwko grypie.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"{\\\"kategoria\\\":\\\"nauka\\\"}\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Cristiano Ronaldo zdobył bramkę w 90. minucie meczu.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"{\\\"kategoria\\\":\\\"sport\\\"}\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Tekst: \\\"Sejm uchwalił budżet państwa na następny rok.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"{\\\"kategoria\\\":\\\"polityka\\\"}\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tekst: \\\"Google zaprezentowało nowy algorytm uczenia maszynowego.\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"{\\\"kategoria\\\":\\\"technologia\\\"}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "few_shot_results = []\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    try:\n",
    "        messages = [{\"role\": \"system\", \"content\": SYSTEM_FEW}] + few_shot_examples + [\n",
    "            {\"role\": \"user\", \"content\": f\"Tekst: \\\"{text}\\\"\"}\n",
    "        ]\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model='gemma2:2b',\n",
    "            messages=messages,\n",
    "            format=\"json\",\n",
    "            options={\"temperature\": 0}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response['message']['content'])\n",
    "        predicted = result.get('kategoria', 'BŁĄD')\n",
    "        few_shot_results.append(predicted)\n",
    "        \n",
    "        print(f\"{i+1}. {text[:50]}...\")\n",
    "        print(f\"   Przewidziano: {predicted} | Oczekiwano: {expected_categories[i]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Błąd: {e}\")\n",
    "        few_shot_results.append('BŁĄD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b89dd804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WARIANT 3: SEKCYJNY ---\n",
      "1. Nowy mikroskop pozwala obserwować pojedyncze atomy...\n",
      "   Przewidziano: nauka | Oczekiwano: nauka\n",
      "   Uzasadnienie: Tekst opisuje nowy mikroskop, który pozwala na obserwację pojedynczych atomy w czasie rzeczywistym. To dotyczy badań naukowych.\n",
      "2. Robert Lewandowski strzelił hat-tricka w meczu prz...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "   Uzasadnienie: Zawodnik strzelił hat-trick w meczu, co jest wydarzeniem sportowym.\n",
      "3. Parlament przyjął ustawę o reformie systemu podatk...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "   Uzasadnienie: W tekście opisano przyjęcie ustawy przez parlament, co jest elementem polityki.\n",
      "4. Sztuczna inteligencja ChatGPT-4 osiągnęła przełomo...\n",
      "   Przewidziano: nauka | Oczekiwano: technologia\n",
      "   Uzasadnienie: Tekst opisuje osiągnięcia w dziedzinie sztucznej inteligencji, co jest tematem badań i odkryć w nauce.\n",
      "5. Naukowcy z MIT odkryli nowy materiał przewodzący p...\n",
      "   Przewidziano: nauka | Oczekiwano: nauka\n",
      "   Uzasadnienie: Tekst opisuje odkrycie naukowe nowego materiału, co jest związane z badaniami i nauką.\n",
      "6. Reprezentacja Polski awansowała do półfinału mistr...\n",
      "   Przewidziano: sport | Oczekiwano: sport\n",
      "   Uzasadnienie: Zawody w siatkówce, awans do półfinału mistrzostw świata.\n",
      "7. Premier zapowiedział zwiększenie wydatków na ochro...\n",
      "   Przewidziano: polityka | Oczekiwano: polityka\n",
      "   Uzasadnienie: W tekście mowa jest o zwiększeniu wydatków na ochronę zdrowia, co jest tematem polityki\n",
      "8. Apple przedstawiło nowy procesor M3 z architekturą...\n",
      "   Przewidziano: nauka | Oczekiwano: technologia\n",
      "   Uzasadnienie: Tekst opisuje nowy procesor M3 z architekturą 3-nanometrową, co jest tematem badań i innowacji w dziedzinie technologii.\n"
     ]
    }
   ],
   "source": [
    "# WARIANT 3: SEKCYJNY (RULES-INPUT-OUTPUT)  \n",
    "print(\"\\n--- WARIANT 3: SEKCYJNY ---\")\n",
    "\n",
    "def classify_sectional(text):\n",
    "    prompt = f\"\"\"\n",
    "<RULES>\n",
    "Przypisz tekst dokładnie do jednej z 4 kategorii:\n",
    "- nauka: badania, odkrycia, eksperymenty, publikacje naukowe\n",
    "- sport: mecze, zawody, wyniki sportowe, zawodnicy\n",
    "- polityka: wybory, ustawy, rząd, partie, decyzje polityczne  \n",
    "- technologia: nowe urządzenia, oprogramowanie, IT, innowacje tech\n",
    "</RULES>\n",
    "\n",
    "<INPUT>\n",
    "{text}\n",
    "</INPUT>\n",
    "\n",
    "<OUTPUT>\n",
    "Zwróć JSON: {{\"kategoria\": \"nauka/sport/polityka/technologia\", \"uzasadnienie\": \"krótkie uzasadnienie\"}}\n",
    "</OUTPUT>\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='gemma2:2b',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Jesteś precyzyjnym klasyfikatorem. Postępuj zgodnie z instrukcjami w sekcjach.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        format=\"json\",\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "sectional_results = []\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    try:\n",
    "        result_raw = classify_sectional(text)\n",
    "        result = json.loads(result_raw)\n",
    "        predicted = result.get('kategoria', 'BŁĄD')\n",
    "        sectional_results.append(predicted)\n",
    "        \n",
    "        print(f\"{i+1}. {text[:50]}...\")\n",
    "        print(f\"   Przewidziano: {predicted} | Oczekiwano: {expected_categories[i]}\")\n",
    "        print(f\"   Uzasadnienie: {result.get('uzasadnienie', 'Brak')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Błąd: {e}\")\n",
    "        sectional_results.append('BŁĄD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26be7494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANALIZA PORÓWNAWCZA ===\n",
      "Dokładność Zero-shot: 75.00%\n",
      "Dokładność Few-shot: 87.50%\n",
      "Dokładność Sekcyjna: 75.00%\n",
      "\n",
      "--- TABELA PORÓWNAWCZA ---\n",
      "Nr | Oczekiwane | Zero-shot | Few-shot | Sekcyjna\n",
      "--------------------------------------------------\n",
      " 1 | nauka      | technologia | nauka    | nauka   \n",
      " 2 | sport      | sport     | sport    | sport   \n",
      " 3 | polityka   | polityka  | polityka | polityka\n",
      " 4 | technologia | technologia | nauka, technologia | nauka   \n",
      " 5 | nauka      | technologia | nauka    | nauka   \n",
      " 6 | sport      | sport     | sport    | sport   \n",
      " 7 | polityka   | polityka  | polityka | polityka\n",
      " 8 | technologia | technologia | technologia | nauka   \n",
      "\n",
      "--- ANALIZA BŁĘDÓW ---\n",
      "\n",
      "Zero-shot:\n",
      "  Błąd 1: nauka → technologia\n",
      "    Tekst: Nowy mikroskop pozwala obserwować pojedyncze atomy w czasie ...\n",
      "  Błąd 5: nauka → technologia\n",
      "    Tekst: Naukowcy z MIT odkryli nowy materiał przewodzący prąd w temp...\n",
      "\n",
      "Few-shot:\n",
      "  Błąd 4: technologia → nauka, technologia\n",
      "    Tekst: Sztuczna inteligencja ChatGPT-4 osiągnęła przełomowe wyniki ...\n",
      "\n",
      "Sekcyjna:\n",
      "  Błąd 4: technologia → nauka\n",
      "    Tekst: Sztuczna inteligencja ChatGPT-4 osiągnęła przełomowe wyniki ...\n",
      "  Błąd 8: technologia → nauka\n",
      "    Tekst: Apple przedstawiło nowy procesor M3 z architekturą 3-nanomet...\n",
      "\n",
      "=== PODSUMOWANIE ===\n",
      "Najlepsza strategia: Few-shot\n"
     ]
    }
   ],
   "source": [
    "# ANALIZA WYNIKÓW\n",
    "print(\"\\n=== ANALIZA PORÓWNAWCZA ===\")\n",
    "\n",
    "def calculate_accuracy(predicted, expected):\n",
    "    correct = sum(1 for p, e in zip(predicted, expected) if p == e)\n",
    "    total = len(expected)\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "accuracy_zero = calculate_accuracy(zero_shot_results, expected_categories)\n",
    "accuracy_few = calculate_accuracy(few_shot_results, expected_categories)\n",
    "accuracy_sectional = calculate_accuracy(sectional_results, expected_categories)\n",
    "\n",
    "print(f\"Dokładność Zero-shot: {accuracy_zero:.2%}\")\n",
    "print(f\"Dokładność Few-shot: {accuracy_few:.2%}\")\n",
    "print(f\"Dokładność Sekcyjna: {accuracy_sectional:.2%}\")\n",
    "\n",
    "# Tabela porównawcza\n",
    "print(\"\\n--- TABELA PORÓWNAWCZA ---\")\n",
    "print(\"Nr | Oczekiwane | Zero-shot | Few-shot | Sekcyjna\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(len(test_texts)):\n",
    "    expected = expected_categories[i]\n",
    "    zero = zero_shot_results[i] \n",
    "    few = few_shot_results[i]\n",
    "    sect = sectional_results[i]\n",
    "    \n",
    "    print(f\"{i+1:2d} | {expected:10s} | {zero:9s} | {few:8s} | {sect:8s}\")\n",
    "\n",
    "# Analiza błędów\n",
    "print(\"\\n--- ANALIZA BŁĘDÓW ---\")\n",
    "categories = [\"nauka\", \"sport\", \"polityka\", \"technologia\"]\n",
    "\n",
    "for strategy_name, results in [(\"Zero-shot\", zero_shot_results), \n",
    "                               (\"Few-shot\", few_shot_results),\n",
    "                               (\"Sekcyjna\", sectional_results)]:\n",
    "    print(f\"\\n{strategy_name}:\")\n",
    "    errors = [(i, expected_categories[i], results[i]) \n",
    "              for i in range(len(results)) \n",
    "              if results[i] != expected_categories[i]]\n",
    "    \n",
    "    if errors:\n",
    "        for idx, expected, predicted in errors:\n",
    "            print(f\"  Błąd {idx+1}: {expected} → {predicted}\")\n",
    "            print(f\"    Tekst: {test_texts[idx][:60]}...\")\n",
    "    else:\n",
    "        print(\"  Brak błędów!\")\n",
    "\n",
    "print(f\"\\n=== PODSUMOWANIE ===\")\n",
    "print(f\"Najlepsza strategia: \", end=\"\")\n",
    "best_accuracy = max(accuracy_zero, accuracy_few, accuracy_sectional)\n",
    "if best_accuracy == accuracy_sectional:\n",
    "    print(\"Sekcyjna\")\n",
    "elif best_accuracy == accuracy_few:\n",
    "    print(\"Few-shot\")  \n",
    "else:\n",
    "    print(\"Zero-shot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136ea9c",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "\n",
    "Jak się można było spodziewać najlepiej poradziła sobie strategia few-shot, gdzie model miał podane przykłady i mógł się na nich wzorować. Co ciekawe podał dwie kategorie w jednym przypadku (nauka, technologia), co pokazuje, że model potrafi rozumieć, że tekst może należeć do więcej niż jednej kategorii. W tym przypadku akurat poprawna była jedna kategoria (technologia), ale i tak jest to ciekawa obserwacja. Prawdopodobnie należało wymusić w promptcie, aby model podawał tylko jedną kategorię. \n",
    "\n",
    "W pozostałych strategiach model radził sobie ciut gorzej, szczególnie w strategii zero-shot, gdzie nie miał żadnych przykładów do naśladowania. Widać, że dodanie przykładów (few-shot) znacząco poprawia skuteczność klasyfikacji tematycznej przez modele LLM. Natomiast ostatecznie pozostałe miały accuracy na poziomie 75%. W few-shot accuracy wyniosło 87.5%, a nawet 100% w najlepszym przypadku (gdybyśmy zaakceptowali dwie kategorie w jednym przypadku).\n",
    "\n",
    "Ciekawą obserwacją jest to, że model często mylił kategorię \"nauka\" z \"technologia\", co może wynikać z bliskości tych tematów. Może to sugerować, że model ma trudności z rozróżnieniem tych dwóch kategorii na podstawie krótkich tekstów.\n",
    "\n",
    "Ostatecznie przykłady były dość proste i oczywiste, brakowało trudniejszych przykładów. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a488ef1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Zadanie 7.5: Streszczenie i parafraza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "562adff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORYGINALNY TEKST (140 słów):\n",
      "Rewolucja w dziedzinie sztucznej inteligencji przyspiesza w zawrotnym tempie. Nowe modele językowe, \n",
      "takie jak GPT-4 czy Claude, potrafią już nie tylko generować tekst, ale także rozumować, kodować \n",
      "i rozwiązywać złożone problemy. Firmy technologiczne inwestują miliardy dolarów w rozwój AI, \n",
      "przewidując, że będzie to kluczowa technologia następnej dekady.\n",
      "\n",
      "Jednak rozwój sztucznej inteligencji niesie ze sobą również wyzwania. Eksperci ostrzegają przed \n",
      "ryzykiem utraty miejsc pracy w wielu sektorach, problemami z dezinformacją oraz kwestiami \n",
      "bezpieczeństwa cybernetycznego. Rządy na całym świecie pracują nad regulacjami, które miałyby \n",
      "kontrolować rozwój AI, zachowując równowagę między innowacją a bezpieczeństwem publicznym.\n",
      "\n",
      "W sektorze edukacji AI już teraz zmienia sposób nauczania i uczenia się. Spersonalizowane systemy \n",
      "edukacyjne dostosowują się do indywidualnych potrzeb uczniów, podczas gdy nauczyciele korzystają \n",
      "z narzędzi AI do tworzenia materiałów dydaktycznych i oceniania prac. Przyszłość edukacji będzie \n",
      "prawdopodobnie opierać się na współpracy między człowiekiem a sztuczną inteligencją.\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== WYNIKI STRESZCZANIA I PARAFRAZOWANIA ===\n",
      "\n",
      "KRÓTKIE STRESZCZENIE:\n",
      "→ AI rozwija się szybko, generując tekst i rozwiązując problemy, ale niesie ze sobą wyzwania w postaci utraty pracy i cyberbezpieczeństwa.\n",
      "  Długość: 20 słów\n",
      "\n",
      "DŁUGIE STRESZCZENIE:\n",
      "→ Technologia sztucznej inteligencji (AI) rozwija się dynamicznie, z nowymi modelami językowymi takimi jak GPT-4 i Claude potrafiący nie tylko generować tekst, ale także rozumieć, kodować i rozwiązywać złożone problemy. Firmy technologiczne inwestują miliardy dolarów w rozwój AI, widząc w nim kluczową technologię przyszłości. Jednak rozwój AI niesie ze sobą wyzwania, takie jak utrata miejsc pracy, dezinformacja i bezpieczeństwo cybernetyczne. Rządy na całym świecie pracują nad regulacjami, które miałyby kontrolować rozwój AI, zachowując równowagę między innowacją a bezpieczeństwem publicznym. W sektorze edukacji AI już teraz zmienia sposób nauczania i uczenia się. Spersonalizowane systemy edukacyjne dostosowują się do indywidualnych potrzeb uczniów, podczas gdy nauczyciele korzystają z narzędzi AI do tworzenia materiałów dydaktycznych i oceniania prac. Przyszłość edukacji będzie prawdopodobnie opierać się na współpracy między człowiekiem a sztuczną inteligencją.\n",
      "  Długość: 126 słów\n",
      "\n",
      "PARAFRAZA KRÓTKIEGO STRESZCZENIA:\n",
      "→ AI rozwija się szybko i potrafi generować tekst, rozumieć kod i rozwiązywać problemy. Jednak rozwój AI niesie ze sobą wyzwania, takie jak utrata miejsc pracy i cyberbezpieczeństwo. Rządy na całym świecie pracują nad regulacjami, które miałyby kontrolować rozwój AI.\n",
      "  Długość: 39 słów\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM = \"Jesteś ekspertem od streszczania i parafrazowania tekstu. Zwracasz wyłącznie poprawny JSON.\"\n",
    "\n",
    "text = \"\"\"\n",
    "Rewolucja w dziedzinie sztucznej inteligencji przyspiesza w zawrotnym tempie. Nowe modele językowe, \n",
    "takie jak GPT-4 czy Claude, potrafią już nie tylko generować tekst, ale także rozumować, kodować \n",
    "i rozwiązywać złożone problemy. Firmy technologiczne inwestują miliardy dolarów w rozwój AI, \n",
    "przewidując, że będzie to kluczowa technologia następnej dekady.\n",
    "\n",
    "Jednak rozwój sztucznej inteligencji niesie ze sobą również wyzwania. Eksperci ostrzegają przed \n",
    "ryzykiem utraty miejsc pracy w wielu sektorach, problemami z dezinformacją oraz kwestiami \n",
    "bezpieczeństwa cybernetycznego. Rządy na całym świecie pracują nad regulacjami, które miałyby \n",
    "kontrolować rozwój AI, zachowując równowagę między innowacją a bezpieczeństwem publicznym.\n",
    "\n",
    "W sektorze edukacji AI już teraz zmienia sposób nauczania i uczenia się. Spersonalizowane systemy \n",
    "edukacyjne dostosowują się do indywidualnych potrzeb uczniów, podczas gdy nauczyciele korzystają \n",
    "z narzędzi AI do tworzenia materiałów dydaktycznych i oceniania prac. Przyszłość edukacji będzie \n",
    "prawdopodobnie opierać się na współpracy między człowiekiem a sztuczną inteligencją.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"ORYGINALNY TEKST ({len(text.split())} słów):\")\n",
    "print(text.strip())\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# PROMPT W SCHEMACIE SEKCYJNYM\n",
    "prompt = f\"\"\"\n",
    "<ROLE>\n",
    "Jesteś specjalistą od przetwarzania tekstu. Tworzysz wysokiej jakości streszczenia i parafrazy.\n",
    "</ROLE>\n",
    "\n",
    "<RULES>\n",
    "1. Krótkie streszczenie: maksymalnie 25 słów, zachowaj najważniejsze informacje\n",
    "2. Długie streszczenie: maksymalnie 70 słów, uwzględnij kluczowe szczegóły\n",
    "3. Parafraza: przepisz krótkie streszczenie innymi słowami, zachowaj sens\n",
    "4. Zwróć wynik w formacie JSON\n",
    "</RULES>\n",
    "\n",
    "<INPUT>\n",
    "{text}\n",
    "</INPUT>\n",
    "\n",
    "<OUTPUT>\n",
    "{{\n",
    "  \"short_summary\": \"krótkie streszczenie (max 25 słów)\",\n",
    "  \"long_summary\": \"długie streszczenie (max 70 słów)\", \n",
    "  \"paraphrase\": \"parafraza krótkiego streszczenia\"\n",
    "}}\n",
    "</OUTPUT>\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gemma2:2b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "result = json.loads(response['message']['content'])\n",
    "\n",
    "print(\"=== WYNIKI STRESZCZANIA I PARAFRAZOWANIA ===\\n\")\n",
    "\n",
    "print(\"KRÓTKIE STRESZCZENIE:\")\n",
    "print(f\"→ {result['short_summary']}\")\n",
    "print(f\"  Długość: {len(result['short_summary'].split())} słów\\n\")\n",
    "\n",
    "print(\"DŁUGIE STRESZCZENIE:\")\n",
    "print(f\"→ {result['long_summary']}\")\n",
    "print(f\"  Długość: {len(result['long_summary'].split())} słów\\n\")\n",
    "\n",
    "print(\"PARAFRAZA KRÓTKIEGO STRESZCZENIA:\")\n",
    "print(f\"→ {result['paraphrase']}\")\n",
    "print(f\"  Długość: {len(result['paraphrase'].split())} słów\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c4b6fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PORÓWNANIE Z INNYM MODELEM ===\n",
      "\n",
      "MODEL: llama3.1:8b\n",
      "Krótkie: Rewolucja w sztucznej inteligencji przyspiesza, nowe modele językowe potrafią rozumować i kodować.\n",
      "Długie: Rozwój sztucznej inteligencji jest szybki, firmy inwestują miliardy dolarów. Eksperci ostrzegają przed ryzykiem utraty miejsc pracy i problemami z dezinformacją. Rządy pracują nad regulacjami.\n",
      "Parafraza: Sztuczna inteligencja przyspiesza, nowe technologie potrafią rozumować i kodować, ale niesie również ryzyko utraty miejsc pracy i problemów z dezinformacją.\n"
     ]
    }
   ],
   "source": [
    "# TEST Z DRUGIM MODELEM\n",
    "print(\"=== PORÓWNANIE Z INNYM MODELEM ===\\n\")\n",
    "\n",
    "response2 = ollama.chat(\n",
    "    model='llama3.1:8b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "result2 = json.loads(response2['message']['content'])\n",
    "\n",
    "print(\"MODEL: llama3.1:8b\")\n",
    "print(f\"Krótkie: {result2['short_summary']}\")\n",
    "print(f\"Długie: {result2['long_summary']}\")\n",
    "print(f\"Parafraza: {result2['paraphrase']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba155d13",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "\n",
    "Ciekawe jest to, że model zmieścił się z streszczeniem w 25 słowach, natomiast przy dłuższym limicie 70 słów, streszczenie było bardziej rozbudowane i zawierało więcej słów niż mu pozwolono. Pokazuje to, że modele LLM mogą mieć trudności z precyzyjnym przestrzeganiem limitów słów, szczególnie gdy są one bardzo restrykcyjne. Związane jest to pewnie z tym, że modele nie rozumieją dokładnie pojęcia \"słowo\" i mogą interpretować je różnie w zależności od kontekstu, one operują na tokenach, a nie na słowach w tradycyjnym sensie. Co do sensu streszczeń, oba były poprawne, parafraza również była trafna natomiast zawierała więcej kontekstu i szczegółów niż oryginalne krótkie streszczenie, co oznacza, że wzięło pod uwagę więcej informacji z oryginalnego tekstu. \n",
    "\n",
    "W przypadku drugiego modelu, streszczenie krótkie jak i długie zmieściły się w podanym limicie słów, oba streszczenia były ok, tutaj w przypadku parafrazy model również dodał więcej szczegółów możliwe, że wziął pod uwagę drugie streszczenie, te dłuższe. Prawdopodobnie w tym kontekście model nie potrafił dokładnie rozróżnić streszczenie krótkie od długiego. \n",
    "\n",
    "Modele nie mają pamięci wewnętrznej i nie potrafią dokładnie liczyć słów, przez co mogą mieć trudności z przestrzeganiem limitów słów w streszczeniach i parafrazach. Nie są w stanie zapamiętywać to co napisały wcześniej w danym zadaniu przez co też nie potrafią się do tego odnieść w całości w parafrazach. Prawdopodobnie każde z zadań traktuje jako osobne i niezależne.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0951410",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Zadanie 7.6: QA z kontekstem i filtrowaniem odpowiedzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d355481b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KONTEKST (140 słów):\n",
      "Komputery kwantowe wykorzystują zjawiska mechaniki kwantowej, takie jak superpozycja i splątanie, \n",
      "do przetwarzania informacji. W przeciwieństwie do klasycznych bitów, które mogą być w stanie 0 lub 1, \n",
      "kubity (bity kwantowe) mogą znajdować się w superpozycji obu stanów jednocześnie.\n",
      "\n",
      "IBM zaprezentowało w 2023 roku procesor kwantowy Eagle z 433 kubitami, który jest jednym z najbardziej \n",
      "zaawansowanych systemów komercyjnych. Google z kolei twierdzi, że osiągnęło \"przewagę kwantową\" \n",
      "ze swoim procesorem Sycamore w 2019 roku, wykonując obliczenia, które zajęłyby klasycznemu \n",
      "superkomputerowi tysiące lat.\n",
      "\n",
      "Główne zastosowania komputerów kwantowych obejmują kryptografię, optymalizację, symulacje molekularne \n",
      "oraz uczenie maszynowe. Jednak technologia ta wciąż boryka się z problemami dekoherencji kwantowej \n",
      "i wysokimi wymaganiami dotyczącymi temperatury - większość systemów wymaga chłodzenia do temperatur \n",
      "bliskich zeru absolutnemu.\n",
      "\n",
      "Eksperci przewidują, że praktyczne zastosowania komputerów kwantowych w przemyśle staną się powszechne \n",
      "dopiero za 10-15 lat, gdy technologia osiągnie większą stabilność i skalowalność.\n"
     ]
    }
   ],
   "source": [
    "CONTEXT = \"\"\"\n",
    "Komputery kwantowe wykorzystują zjawiska mechaniki kwantowej, takie jak superpozycja i splątanie, \n",
    "do przetwarzania informacji. W przeciwieństwie do klasycznych bitów, które mogą być w stanie 0 lub 1, \n",
    "kubity (bity kwantowe) mogą znajdować się w superpozycji obu stanów jednocześnie.\n",
    "\n",
    "IBM zaprezentowało w 2023 roku procesor kwantowy Eagle z 433 kubitami, który jest jednym z najbardziej \n",
    "zaawansowanych systemów komercyjnych. Google z kolei twierdzi, że osiągnęło \"przewagę kwantową\" \n",
    "ze swoim procesorem Sycamore w 2019 roku, wykonując obliczenia, które zajęłyby klasycznemu \n",
    "superkomputerowi tysiące lat.\n",
    "\n",
    "Główne zastosowania komputerów kwantowych obejmują kryptografię, optymalizację, symulacje molekularne \n",
    "oraz uczenie maszynowe. Jednak technologia ta wciąż boryka się z problemami dekoherencji kwantowej \n",
    "i wysokimi wymaganiami dotyczącymi temperatury - większość systemów wymaga chłodzenia do temperatur \n",
    "bliskich zeru absolutnemu.\n",
    "\n",
    "Eksperci przewidują, że praktyczne zastosowania komputerów kwantowych w przemyśle staną się powszechne \n",
    "dopiero za 10-15 lat, gdy technologia osiągnie większą stabilność i skalowalność.\n",
    "\"\"\"\n",
    "\n",
    "questions_in_context = [\n",
    "    \"Ile kubitów ma procesor Eagle firmy IBM?\",\n",
    "    \"Jakie są główne zastosowania komputerów kwantowych?\",\n",
    "    \"Kiedy Google osiągnęło przewagę kwantową?\",\n",
    "    \"Jakie są główne problemy komputerów kwantowych?\"\n",
    "]\n",
    "\n",
    "questions_out_of_context = [\n",
    "    \"Jaka jest cena procesora Eagle?\",\n",
    "    \"Kto jest CEO firmy IBM?\",\n",
    "    \"Gdzie produkowane są komputery kwantowe?\",\n",
    "    \"Ile kosztuje budowa komputera kwantowego?\"\n",
    "]\n",
    "\n",
    "print(f\"KONTEKST ({len(CONTEXT.split())} słów):\")\n",
    "print(CONTEXT.strip())\n",
    "\n",
    "# WARIANT 1: BEZ ZASAD\n",
    "def qa_without_rules(context, question, model='gemma2:2b'):\n",
    "    \"\"\"QA bez specjalnych zasad - podstawowy prompt\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Na podstawie poniższego tekstu odpowiedz na pytanie.\n",
    "\n",
    "    Tekst:\n",
    "    {context}\n",
    "\n",
    "    Pytanie: {question}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "# WARIANT 2: ZE ŚCISŁYMI ZASADAMI\n",
    "def qa_with_strict_rules(context, question, model='gemma2:2b'):\n",
    "    \"\"\"QA ze ścisłymi zasadami dotyczącymi odpowiedzi\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"\n",
    "    Jesteś precyzyjnym asystentem QA. Odpowiadaj WYŁĄCZNIE na podstawie dostarczonego kontekstu.\n",
    "    ZASADY:\n",
    "    1. Jeśli odpowiedź nie znajduje się w kontekście, odpowiedz: \"Brak wystarczających informacji\"\n",
    "    2. Cytuj fragment źródłowy w nawiasach [] gdy to możliwe\n",
    "    3. Bądź zwięzły i konkretny\n",
    "    4. NIE dodawaj informacji spoza kontekstu\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    <KONTEKST>\n",
    "    {context}\n",
    "    </KONTEKST>\n",
    "\n",
    "    <PYTANIE>\n",
    "    {question}\n",
    "    </PYTANIE>\n",
    "\n",
    "    Odpowiedź:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "# WARIANT 3: FEW-SHOT Z PRZYKŁADAMI\n",
    "def qa_few_shot(context, question, model='gemma2:2b'):\n",
    "    \"\"\"QA z przykładami few-shot\"\"\"\n",
    "    \n",
    "    SYSTEM = \"Odpowiadaj na pytania na podstawie kontekstu. Jeśli informacji brak, napisz 'Brak wystarczających informacji'.\"\n",
    "    \n",
    "    examples = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"Kontekst: Apple wydało iPhone 15 we wrześniu 2023 z nowym procesorem A17 Pro. Pytanie: Kiedy wydano iPhone 15?\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": \"iPhone 15 wydano we wrześniu 2023 [Apple wydało iPhone 15 we wrześniu 2023].\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"Kontekst: Apple wydało iPhone 15 we wrześniu 2023 z nowym procesorem A17 Pro. Pytanie: Jaka jest cena iPhone 15?\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Brak wystarczających informacji\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM}] + examples + [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"Kontekst: {context}\\nPytanie: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a15e4b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PORÓWNANIE WARIANTÓW PROMPTÓW ===\n",
      "\n",
      "--- PYTANIA W KONTEKŚCIE ---\n",
      "\n",
      "PYTANIE: Ile kubitów ma procesor Eagle firmy IBM?\n",
      "--------------------------------------------------\n",
      "Bez zasad   : Procesorem Eagle firmy IBM ma **433 kubity**. \n",
      "\n",
      "Ścisłe zasady: 433 \n",
      "[IBM zaprezentowało w 2023 roku procesor kwantowy Eagle z 433 kubitami, który jest jednym z najbardziej zaawansowanych systemów komercyjnych.] \n",
      "\n",
      "Few-shot    : Procesor Eagle firmy IBM ma 433 kubity. \n",
      "\n",
      "\n",
      "PYTANIE: Jakie są główne zastosowania komputerów kwantowych?\n",
      "--------------------------------------------------\n",
      "Bez zasad   : Główne zastosowania komputerów kwantowych to:\n",
      "\n",
      "* **Kryptografia**\n",
      "* **Optymalizacja**\n",
      "* **Symulacje molekularne**\n",
      "* **Uczenie maszynowe** \n",
      "\n",
      "Ścisłe zasady: Główne zastosowania komputerów kwantowych obejmują kryptografię, optymalizację, symulacje molekularne oraz uczenie maszynowe. \n",
      "[KONTEKST] \n",
      "\n",
      "Few-shot    : Główne zastosowania komputerów kwantowych obejmują:\n",
      "\n",
      "* **Kryptografia:**  Komputerowe kwantowe mogą być wykorzystywane do szyfrowania danych w sposób bardziej bezpieczny. \n",
      "* **Optymalizacja:**  Możliwość szybkiego rozwiązywania problemów optymalizacyjnych, np. w zarządzaniu zasobami.\n",
      "* **Symulacje molekularne:**  Komputerowe kwantowe mogą być wykorzystywane do modelowania i simulowania procesów molekularnych. \n",
      "* **Uczenie maszynowe:**  Komputerowe kwantowe mogą być wykorzystywane do uczenia maszynowego w sposób bardziej efektywny. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PYTANIE: Kiedy Google osiągnęło przewagę kwantową?\n",
      "--------------------------------------------------\n",
      "Bez zasad   : Google osiągnęło przewagę kwantową w **2019 roku** dzięki procesorowi Sycamore. \n",
      "\n",
      "Ścisłe zasady: W 2019 roku. [Google z kolei twierdzi, że osiągnęło \"przewagę kwantową\" ze swoim procesorem Sycamore w 2019 roku, wykonując obliczenia, które zajęłyby klasycznemu superkomputerowi tysiące lat.] \n",
      "\n",
      "Few-shot    : Google osiągnęło przewagę kwantową w 2019 roku. \n",
      "\n",
      "\n",
      "PYTANIE: Jakie są główne problemy komputerów kwantowych?\n",
      "--------------------------------------------------\n",
      "Bez zasad   : Głównymi problemami komputerów kwantowych są:\n",
      "\n",
      "* **Dekoherencja kwantowa:**  To oznacza, że ​​kwantowe procesy mogą być podatne na zmiany w temperaturze i wpływają one na dokładność obliczeń. \n",
      "* **Wysokie wymagania dotyczące temperatury:** Większość systemów wymaga chłodzenia do temperatur bliskich zeru absolutnemu. \n",
      "\n",
      "\n",
      "Dodatkowo tekst wskazuje, że technologia ta wciąż boryka się z problemami dekoherencji kwantowej i wysokimi wymaganiami dotyczącymi temperatury - większość systemów wymaga chłodzenia do temperatur bliskich zeru absolutnemu.\n",
      "\n",
      "Ścisłe zasady: Głównymi problemami komputerów kwantowych są dekoherencja kwantowa i wysokie wymagania dotyczące temperatury. \n",
      "[Eksperci przewidują, że praktyczne zastosowania komputerów kwantowych w przemyśle staną się powszechne dopiero za 10-15 lat, gdy technologia osiągnie większą stabilność i skalowalność.] \n",
      "\n",
      "Few-shot    : Głównymi problemami komputerów kwantowych są:\n",
      "\n",
      "* **Dekoherencja kwantowa:**  To oznacza, że ​​kwantowe procesy mogą być podatne na zakłócenia i niepewność. \n",
      "* **Wysokie wymagania dotyczące temperatury:** Większość systemów wymaga chłodzenia do temperatur bliskich zeru absolutnego. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TESTOWANIE WARIANTÓW\n",
    "print(\"=== PORÓWNANIE WARIANTÓW PROMPTÓW ===\\n\")\n",
    "\n",
    "strategies = [\n",
    "    (\"Bez zasad\", qa_without_rules),\n",
    "    (\"Ścisłe zasady\", qa_with_strict_rules), \n",
    "    (\"Few-shot\", qa_few_shot)\n",
    "]\n",
    "\n",
    "# Test 1: Pytania w kontekście\n",
    "print(\"--- PYTANIA W KONTEKŚCIE ---\")\n",
    "for question in questions_in_context:\n",
    "    print(f\"\\nPYTANIE: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for strategy_name, strategy_func in strategies:\n",
    "        try:\n",
    "            answer = strategy_func(CONTEXT, question)\n",
    "            print(f\"{strategy_name:12}: {answer}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{strategy_name:12}: BŁĄD - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24435382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- PYTANIA POZA KONTEKSTEM ---\n",
      "\n",
      "PYTANIE: Jaka jest cena procesora Eagle?\n",
      "--------------------------------------------------\n",
      "Bez zasad   : Tekst nie zawiera informacji o cenie procesora Eagle. \n",
      "\n",
      "Ścisłe zasady: Brak wystarczających informacji [ ] \n",
      "\n",
      "Few-shot    : Brak wystarczających informacji. \n",
      "\n",
      "\n",
      "PYTANIE: Kto jest CEO firmy IBM?\n",
      "--------------------------------------------------\n",
      "Bez zasad   : Tekst nie zawiera informacji o nazwisku CEO firmy IBM. \n",
      "\n",
      "Ścisłe zasady: Brak wystarczających informacji \n",
      "\n",
      "Few-shot    : Brak wystarczających informacji. \n",
      "\n",
      "\n",
      "PYTANIE: Gdzie produkowane są komputery kwantowe?\n",
      "--------------------------------------------------\n",
      "Bez zasad   : W tekście nie ma konkretnej informacji o miejscach produkcji komputerów kwantowych. \n",
      "\n",
      "**Informacje z tekstu:**\n",
      "\n",
      "* IBM zaprezentowało procesor kwantowy Eagle w 2023 roku.\n",
      "* Google osiągnęło \"przewagę kwantową\" ze swoim procesorem Sycamore w 2019 roku.\n",
      "\n",
      "\n",
      "**Możliwe miejsca produkcji:**\n",
      "\n",
      "* **USA:**  IBM i Google to firmy z USA, które są liderami w dziedzinie komputerów kwantowych.\n",
      "* **Japonia:** Japonia jest znana z innowacji technologicznych i może być miejscem produkcji komputera kwantowego. \n",
      "\n",
      "\n",
      "**Uwaga:** Informacje o lokalizacji produkcji mogą być dostępne w innych źródłach, takich jak strony internetowe firm lub artykuły naukowe. \n",
      "\n",
      "Ścisłe zasady: Brak wystarczających informacji \n",
      "\n",
      "Few-shot    : Brak wystarczających informacji. \n",
      "\n",
      "\n",
      "PYTANIE: Ile kosztuje budowa komputera kwantowego?\n",
      "--------------------------------------------------\n",
      "Bez zasad   : Tekst nie zawiera informacji na temat kosztów budowy komputera kwantowego. \n",
      "\n",
      "Ścisłe zasady: Brak wystarczających informacji \n",
      "\n",
      "Few-shot    : Brak wystarczających informacji \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n--- PYTANIA POZA KONTEKSTEM ---\")\n",
    "for question in questions_out_of_context:\n",
    "    print(f\"\\nPYTANIE: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for strategy_name, strategy_func in strategies:\n",
    "        try:\n",
    "            answer = strategy_func(CONTEXT, question)\n",
    "            print(f\"{strategy_name:12}: {answer}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{strategy_name:12}: BŁĄD - {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5d322",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "\n",
    "Model poprawnie sobie poradził z pytaniami z kontekstem, natomiast do jednego pytania podał w przypadku cytowania fragmentu źródłowego niepoprawne źródło, niepoprawny tekst źródłowy. Pokazuje to, że modele LLM mogą mieć trudności z dokładnym cytowaniem źródeł, szczególnie gdy są one podobne lub gdy model nie ma pełnego zrozumienia kontekstu. Zdarzyło się i tak, że nie podał źródła wcale. W przypadku promptowania bez zasad model często dodawał więcej informacji co do zwracanych odpowiedzi, chcąc wyjaśnić lub rozwinąć odpowiedź. Poza tym wydaje sie, że model nie halucynował żadnych informacji, odpowiedzi były poprawne.\n",
    "\n",
    "W przypadku niepewnych odpowiedzi model w każdym przypadku odpowiadał, że nie ma wystarczającej ilości informacji, co prawda w podejściu Few-Shot czy też z ścisłymi zasadami model odpowiadał z szablonu: \"Brak wystarczających informacji\". Natomiast w przypadku braku zasad odpowiadał bardziej naturalnie, \"Tekst nie zawiera wystarczających informacji, aby udzielić odpowiedzi na to pytanie.\". Czasami (w przypadku podejścia bez zasad) podawał więcej informacji lub próbował halucynować albo przewidywać odpowiedzi (pytanie \"Gdzie produkowane są komputery kwantowe?\"), co pokazuje, że mogą one generować niepożądane odpowiedzi lub halucynować w przypadku zagmatwanych i trudnych danych wejściowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff3481",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Zadanie 7.7: Porównanie strategii promptów w klasyfikacji wieloklasowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74eb155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZADANIE 7.7: PORÓWNANIE STRATEGII PROMPTÓW ===\n",
      "\n",
      "Zbiór testowy: 20 tekstów w 5 kategoriach\n",
      "Kategorii: technologia, sport, zdrowie, polityka, ekonomia\n",
      "Rozkład: {'technologia': 4, 'sport': 4, 'zdrowie': 4, 'polityka': 4, 'ekonomia': 4}\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "print(\"=== ZADANIE 7.7: PORÓWNANIE STRATEGII PROMPTÓW ===\\n\")\n",
    "\n",
    "# PRZYGOTOWANIE ROZSZERZONEGO ZBIORU TESTOWEGO (20 tekstów, 5 kategorii)\n",
    "test_texts = [\n",
    "    # TECHNOLOGIA (4 przykłady)\n",
    "    \"OpenAI uruchomiło nową wersję GPT-5 z ulepszonymi możliwościami rozumowania.\",\n",
    "    \"Meta przedstawiło okulary AR nowej generacji z wbudowaną sztuczną inteligencją.\",\n",
    "    \"Tesla wprowadza autonomiczne ciężarówki do transportu międzymiastowego.\",\n",
    "    \"Kwantowy komputer Google Willow osiągnął przełom w korekcji błędów.\",\n",
    "    \n",
    "    # SPORT (4 przykłady)\n",
    "    \"Lewandowski zdobył hat-tricka w meczu Ligi Mistrzów przeciwko Realowi Madryt.\",\n",
    "    \"Polska reprezentacja siatkarzy wygrała turniej VNL po dramatycznym finale.\",\n",
    "    \"Novak Djokovic obronił tytuł mistrza Wimbledonu po trzech setach.\",\n",
    "    \"Biegi narciarskie: Justyna Kowalczyk zakończyła karierę sportową.\",\n",
    "    \n",
    "    # ZDROWIE (4 przykłady)\n",
    "    \"Naukowcy opracowali nową terapię genową przeciwko nowotworom krwi.\",\n",
    "    \"WHO ostrzega przed nowym szczepem grypty wykrytym w Azji Południowo-Wschodniej.\",\n",
    "    \"Przełomowe badania pokazują skuteczność medytacji w leczeniu depresji.\",\n",
    "    \"Ministerstwo Zdrowia uruchamia program bezpłatnych badań profilaktycznych dla seniorów.\",\n",
    "    \n",
    "    # POLITYKA (4 przykłady) \n",
    "    \"Sejm uchwalił ustawę o podwyżce płacy minimalnej o 15% od stycznia.\",\n",
    "    \"Unia Europejska wprowadza nowe sankcje gospodarcze wobec Rosji.\",\n",
    "    \"Prezydent podpisał nowelę Kodeksu pracy dotyczącą pracy zdalnej.\",\n",
    "    \"Komisja Europejska zatwierdza polski KPO na 60 miliardów euro.\",\n",
    "    \n",
    "    # EKONOMIA (4 przykłady)\n",
    "    \"NBP obniża stopy procentowe do 5% w reakcji na spadek inflacji.\",\n",
    "    \"Giełda w Warszawie osiągnęła najwyższy poziom w historii WIG20.\",\n",
    "    \"Bitcoin przekroczył barierę 100 tysięcy dolarów po decyzji Fed.\",\n",
    "    \"Ceny mieszkań w Warszawie wzrosły o 12% w ciągu ostatniego roku.\"\n",
    "]\n",
    "\n",
    "# ETYKIETY RZECZYWISTE\n",
    "true_labels = [\n",
    "    # TECHNOLOGIA\n",
    "    \"technologia\", \"technologia\", \"technologia\", \"technologia\",\n",
    "    # SPORT  \n",
    "    \"sport\", \"sport\", \"sport\", \"sport\",\n",
    "    # ZDROWIE\n",
    "    \"zdrowie\", \"zdrowie\", \"zdrowie\", \"zdrowie\", \n",
    "    # POLITYKA\n",
    "    \"polityka\", \"polityka\", \"polityka\", \"polityka\",\n",
    "    # EKONOMIA\n",
    "    \"ekonomia\", \"ekonomia\", \"ekonomia\", \"ekonomia\"\n",
    "]\n",
    "\n",
    "categories = [\"technologia\", \"sport\", \"zdrowie\", \"polityka\", \"ekonomia\"]\n",
    "\n",
    "print(f\"Zbiór testowy: {len(test_texts)} tekstów w {len(categories)} kategoriach\")\n",
    "print(f\"Kategorii: {', '.join(categories)}\")\n",
    "print(f\"Rozkład: {dict(Counter(true_labels))}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6820348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGIA 1: ZERO-SHOT\n",
    "def classify_zero_shot(text, model='gemma2:2b'):\n",
    "    SYSTEM = \"\"\"Jesteś precyzyjnym klasyfikatorem tekstów. \n",
    "    WAŻNE: Zwracaj DOKŁADNIE jedną z tych 5 kategorii: technologia, sport, zdrowie, polityka, ekonomia.\n",
    "    NIE używaj synonimów jak 'medycyna', 'finanse', 'prawo' - tylko podane kategorie!\"\"\"\n",
    "        \n",
    "    prompt = f\"\"\"Sklasyfikuj tekst do DOKŁADNIE jednej z tych kategorii:\n",
    "    - technologia\n",
    "    - sport  \n",
    "    - zdrowie\n",
    "    - polityka\n",
    "    - ekonomia\n",
    "\n",
    "    Tekst: \"{text}\"\n",
    "\n",
    "    WAŻNE: Odpowiedz JSON z kategorią z powyższej listy: {{\"kategoria\": \"dokładna_nazwa_kategorii\"}}\"\"\"\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        format=\"json\",\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(response['message']['content'])\n",
    "        predicted = result.get('kategoria', 'BŁĄD')\n",
    "        \n",
    "        # Mapowanie synonimów na prawidłowe kategorie\n",
    "        synonym_mapping = {\n",
    "            'medycyna': 'zdrowie',\n",
    "            'finanse': 'ekonomia', \n",
    "            'prawo': 'polityka',\n",
    "            'real estate': 'ekonomia',\n",
    "            'nieruchomości': 'ekonomia',\n",
    "            'it': 'technologia',\n",
    "            'informatyka': 'technologia'\n",
    "        }\n",
    "        \n",
    "        return synonym_mapping.get(predicted.lower(), predicted)\n",
    "    except:\n",
    "        return 'BŁĄD'\n",
    "    \n",
    "# STRATEGIA 2: FEW-SHOT\n",
    "def classify_few_shot(text, model='gemma2:2b'):\n",
    "    SYSTEM = \"\"\"Klasyfikuj teksty do DOKŁADNIE jednej z 5 kategorii: technologia, sport, zdrowie, polityka, ekonomia.\n",
    "    Zwracaj TYLKO te nazwy kategorii, nie synonimów!\"\"\"\n",
    "    \n",
    "    # Trudniejsze przykłady z potencjalnymi nakładkami\n",
    "    examples = [\n",
    "        # Technologia vs ekonomia (blockchain)\n",
    "        {\"role\": \"user\", \"content\": 'Tekst: \"Blockchain może zrewolucjonizować sektor finansowy poprzez zdecentralizowane finanse.\"'},\n",
    "        {\"role\": \"assistant\", \"content\": '{\"kategoria\": \"technologia\"}'},\n",
    "        \n",
    "        # Sport vs zdrowie (fitness)  \n",
    "        {\"role\": \"user\", \"content\": 'Tekst: \"Badania pokazują, że regularne bieganie zmniejsza ryzyko chorób serca o 30%.\"'},\n",
    "        {\"role\": \"assistant\", \"content\": '{\"kategoria\": \"zdrowie\"}'},\n",
    "        \n",
    "        # Polityka vs ekonomia (podatki)\n",
    "        {\"role\": \"user\", \"content\": 'Tekst: \"Minister finansów zapowiedział obniżkę podatku dochodowego od przedsiębiorstw.\"'},\n",
    "        {\"role\": \"assistant\", \"content\": '{\"kategoria\": \"polityka\"}'},\n",
    "        \n",
    "        # Zdrowie vs technologia (AI w medycynie)\n",
    "        {\"role\": \"user\", \"content\": 'Tekst: \"Algorytm sztucznej inteligencji pomaga lekarzom w diagnostyce nowotworów płuc.\"'},\n",
    "        {\"role\": \"assistant\", \"content\": '{\"kategoria\": \"zdrowie\"}'},\n",
    "        \n",
    "        # Ekonomia vs polityka (inflacja)\n",
    "        {\"role\": \"user\", \"content\": 'Tekst: \"Inflacja w strefie euro wzrosła do 4,2%, co może wpłynąć na decyzje EBC.\"'},\n",
    "        {\"role\": \"assistant\", \"content\": '{\"kategoria\": \"ekonomia\"}'}\n",
    "    ]\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM}] + examples + [\n",
    "        {\"role\": \"user\", \"content\": f'Tekst: \"{text}\"'}\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        format=\"json\", \n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(response['message']['content'])\n",
    "        predicted = result.get('kategoria', 'BŁĄD')\n",
    "        \n",
    "        # Mapowanie synonimów\n",
    "        synonym_mapping = {\n",
    "            'medycyna': 'zdrowie',\n",
    "            'finanse': 'ekonomia', \n",
    "            'prawo': 'polityka',\n",
    "            'real estate': 'ekonomia',\n",
    "            'nieruchomości': 'ekonomia',\n",
    "            'it': 'technologia',\n",
    "            'informatyka': 'technologia'\n",
    "        }\n",
    "        \n",
    "        return synonym_mapping.get(predicted.lower(), predicted)\n",
    "    except:\n",
    "        return 'BŁĄD'\n",
    "\n",
    "# STRATEGIA 3: SEKCYJNA (RULES-INPUT-OUTPUT)\n",
    "def classify_sectional(text, model='gemma2:2b'):\n",
    "    prompt = f\"\"\"\n",
    "    <RULES>\n",
    "    Sklasyfikuj tekst do DOKŁADNIE jednej z tych 5 kategorii (używaj TYLKO tych nazw):\n",
    "\n",
    "    1. technologia - AI, ML, oprogramowanie, gadżety, startupy tech, blockchain, cyberbezpieczeństwo\n",
    "    2. sport - mecze, zawody, wyniki sportowe, zawodnicy, dyscypliny, mistrzostwa  \n",
    "    3. zdrowie - medycyna, leczenie, profilaktyka, badania medyczne, pandemia, farmacja, terapie\n",
    "    4. polityka - rząd, wybory, ustawy, partie, decyzje władz, UE, parlament, prezydent, premier\n",
    "    5. ekonomia - giełda, inflacja, stopy procentowe, PKB, finanse, handel, bankowość, nieruchomości\n",
    "\n",
    "    WAŻNE: Jeśli tekst dotyczy np. regulacji AI przez rząd → polityka\n",
    "    Jeśli dotyczy wpływu gospodarczego nowej technologii → ekonomia  \n",
    "    Jeśli dotyczy zastosowania AI w medycynie → zdrowie\n",
    "    </RULES>\n",
    "\n",
    "    <CONSTRAINT>\n",
    "    Zwracaj WYŁĄCZNIE te nazwy: technologia, sport, zdrowie, polityka, ekonomia\n",
    "    NIE używaj: medycyna, finanse, prawo, it, informatyka, real estate\n",
    "    </CONSTRAINT>\n",
    "\n",
    "    <INPUT>\n",
    "    {text}\n",
    "    </INPUT>\n",
    "\n",
    "    <OUTPUT>\n",
    "    {{\"kategoria\": \"jedna_z_pięciu_kategorii\", \"uzasadnienie\": \"dlaczego ta kategoria\"}}\n",
    "    </OUTPUT>\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Jesteś precyzyjnym klasyfikatorem. Przestrzegaj DOKŁADNIE nazw kategorii w RULES.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        format=\"json\",\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(response['message']['content'])\n",
    "        predicted = result.get('kategoria', 'BŁĄD')\n",
    "        \n",
    "        # Ostateczne zabezpieczenie przed synonimami\n",
    "        synonym_mapping = {\n",
    "            'medycyna': 'zdrowie',\n",
    "            'finanse': 'ekonomia', \n",
    "            'prawo': 'polityka',\n",
    "            'real estate': 'ekonomia',\n",
    "            'nieruchomości': 'ekonomia',\n",
    "            'it': 'technologia',\n",
    "            'informatyka': 'technologia'\n",
    "        }\n",
    "        \n",
    "        return synonym_mapping.get(predicted.lower(), predicted)\n",
    "    except:\n",
    "        return 'BŁĄD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1aa1944",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_hard_texts = [\n",
    "    # Graniczne przypadki\n",
    "    \"Rząd planuje wprowadzenie podatku od transakcji kryptowalutowych w wysokości 2%.\", # polityka vs technologia vs ekonomia\n",
    "    \"Klub Jagiellonia Białystok pozyskał nowego fizjoterapeutę specjalizującego się w urazach kolana.\", # sport vs zdrowie\n",
    "    \"Ministerstwo Cyfryzacji uruchamia program dotacji na rozwój aplikacji edukacyjnych.\", # polityka vs technologia\n",
    "    \"Badania kliniczne nowego leku przeciwbólowego wykazały skuteczność na poziomie 87%.\", # zdrowie\n",
    "    \"Giełda kryptowalut Binance wprowadza nowe zabezpieczenia przed cyberatakami.\", # technologia vs ekonomia\n",
    "]\n",
    "\n",
    "additional_hard_labels = [\"polityka\", \"sport\", \"polityka\", \"zdrowie\", \"ekonomia\"]\n",
    "\n",
    "extended_test_texts = test_texts + additional_hard_texts\n",
    "extended_true_labels = true_labels + additional_hard_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d9f65f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== URUCHAMIANIE KLASYFIKACJI ===\n",
      "\n",
      "Testowanie strategii: Zero-shot\n",
      "   1. technologia (oczekiwano: technologia)\n",
      "   2. technologia (oczekiwano: technologia)\n",
      "   3. technologia (oczekiwano: technologia)\n",
      "   4. technologia (oczekiwano: technologia)\n",
      "   5. sport      (oczekiwano: sport     )\n",
      "   6. sport      (oczekiwano: sport     )\n",
      "   7. sport      (oczekiwano: sport     )\n",
      "   8. sport      (oczekiwano: sport     )\n",
      "   9. zdrowie    (oczekiwano: zdrowie   )\n",
      "  10. zdrowie    (oczekiwano: zdrowie   )\n",
      "  11. zdrowie    (oczekiwano: zdrowie   )\n",
      "  12. zdrowie    (oczekiwano: zdrowie   )\n",
      "  13. polityka   (oczekiwano: polityka  )\n",
      "  14. polityka   (oczekiwano: polityka  )\n",
      "  15. polityka   (oczekiwano: polityka  )\n",
      "  16. ekonomia   (oczekiwano: polityka  )\n",
      "  17. ekonomia   (oczekiwano: ekonomia  )\n",
      "  18. ekonomia   (oczekiwano: ekonomia  )\n",
      "  19. ekonomia   (oczekiwano: ekonomia  )\n",
      "  20. ekonomia   (oczekiwano: ekonomia  )\n",
      "  21. polityka   (oczekiwano: polityka  )\n",
      "  22. zdrowie    (oczekiwano: sport     )\n",
      "  23. technologia (oczekiwano: polityka  )\n",
      "  24. zdrowie    (oczekiwano: zdrowie   )\n",
      "  25. technologia (oczekiwano: ekonomia  )\n",
      "\n",
      "Testowanie strategii: Few-shot\n",
      "   1. technologia (oczekiwano: technologia)\n",
      "   2. technologia (oczekiwano: technologia)\n",
      "   3. technologia (oczekiwano: technologia)\n",
      "   4. technologia (oczekiwano: technologia)\n",
      "   5. sport      (oczekiwano: sport     )\n",
      "   6. sport      (oczekiwano: sport     )\n",
      "   7. sport      (oczekiwano: sport     )\n",
      "   8. sport      (oczekiwano: sport     )\n",
      "   9. zdrowie    (oczekiwano: zdrowie   )\n",
      "  10. zdrowie    (oczekiwano: zdrowie   )\n",
      "  11. zdrowie    (oczekiwano: zdrowie   )\n",
      "  12. zdrowie    (oczekiwano: zdrowie   )\n",
      "  13. polityka   (oczekiwano: polityka  )\n",
      "  14. polityka   (oczekiwano: polityka  )\n",
      "  15. polityka   (oczekiwano: polityka  )\n",
      "  16. polityka   (oczekiwano: polityka  )\n",
      "  17. ekonomia   (oczekiwano: ekonomia  )\n",
      "  18. ekonomia   (oczekiwano: ekonomia  )\n",
      "  19. technologia (oczekiwano: ekonomia  )\n",
      "  20. ekonomia   (oczekiwano: ekonomia  )\n",
      "  21. polityka   (oczekiwano: polityka  )\n",
      "  22. sport      (oczekiwano: sport     )\n",
      "  23. technologia (oczekiwano: polityka  )\n",
      "  24. zdrowie    (oczekiwano: zdrowie   )\n",
      "  25. technologia (oczekiwano: ekonomia  )\n",
      "\n",
      "Testowanie strategii: Sekcyjna\n",
      "   1. technologia (oczekiwano: technologia)\n",
      "   2. technologia (oczekiwano: technologia)\n",
      "   3. technologia (oczekiwano: technologia)\n",
      "   4. technologia (oczekiwano: technologia)\n",
      "   5. sport      (oczekiwano: sport     )\n",
      "   6. sport      (oczekiwano: sport     )\n",
      "   7. sport      (oczekiwano: sport     )\n",
      "   8. sport      (oczekiwano: sport     )\n",
      "   9. zdrowie    (oczekiwano: zdrowie   )\n",
      "  10. zdrowie    (oczekiwano: zdrowie   )\n",
      "  11. zdrowie    (oczekiwano: zdrowie   )\n",
      "  12. zdrowie    (oczekiwano: zdrowie   )\n",
      "  13. polityka   (oczekiwano: polityka  )\n",
      "  14. polityka   (oczekiwano: polityka  )\n",
      "  15. polityka   (oczekiwano: polityka  )\n",
      "  16. ekonomia   (oczekiwano: polityka  )\n",
      "  17. ekonomia   (oczekiwano: ekonomia  )\n",
      "  18. ekonomia   (oczekiwano: ekonomia  )\n",
      "  19. ekonomia   (oczekiwano: ekonomia  )\n",
      "  20. ekonomia   (oczekiwano: ekonomia  )\n",
      "  21. polityka   (oczekiwano: polityka  )\n",
      "  22. zdrowie    (oczekiwano: sport     )\n",
      "  23. technologia (oczekiwano: polityka  )\n",
      "  24. zdrowie    (oczekiwano: zdrowie   )\n",
      "  25. technologia (oczekiwano: ekonomia  )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# URUCHOMIENIE TESTÓW DLA WSZYSTKICH STRATEGII\n",
    "print(\"=== URUCHAMIANIE KLASYFIKACJI ===\\n\")\n",
    "\n",
    "strategies = {\n",
    "    \"Zero-shot\": classify_zero_shot,\n",
    "    \"Few-shot\": classify_few_shot, \n",
    "    \"Sekcyjna\": classify_sectional\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for strategy_name, strategy_func in strategies.items():\n",
    "    print(f\"Testowanie strategii: {strategy_name}\")\n",
    "    strategy_results = []\n",
    "    \n",
    "    for i, text in enumerate(extended_test_texts):\n",
    "        predicted = strategy_func(text)\n",
    "        strategy_results.append(predicted)\n",
    "        print(f\"  {i+1:2d}. {predicted:10s} (oczekiwano: {extended_true_labels[i]:10s})\")\n",
    "    \n",
    "    results[strategy_name] = strategy_results\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6087f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNKCJE ANALIZY\n",
    "def calculate_accuracy(predicted, true):\n",
    "    correct = sum(1 for p, t in zip(predicted, true) if p == t)\n",
    "    return correct / len(true) if len(true) > 0 else 0\n",
    "\n",
    "def calculate_precision_recall(predicted, true, target_class):\n",
    "    # True Positives, False Positives, False Negatives\n",
    "    tp = sum(1 for p, t in zip(predicted, true) if p == target_class and t == target_class)\n",
    "    fp = sum(1 for p, t in zip(predicted, true) if p == target_class and t != target_class)\n",
    "    fn = sum(1 for p, t in zip(predicted, true) if p != target_class and t == target_class)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def confusion_matrix(predicted, true, categories):\n",
    "    matrix = defaultdict(lambda: defaultdict(int))\n",
    "    for p, t in zip(predicted, true):\n",
    "        matrix[t][p] += 1\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb435ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALIZA WYNIKÓW ===\n",
      "\n",
      "1. DOKŁADNOŚĆ (ACCURACY)\n",
      "----------------------------------------\n",
      "Zero-shot   : 84.00%\n",
      "Few-shot    : 88.00%\n",
      "Sekcyjna    : 84.00%\n",
      "\n",
      "2. PRECISION, RECALL, F1 dla każdej kategorii\n",
      "------------------------------------------------------------\n",
      "\n",
      "Zero-shot:\n",
      "Kategoria    Precision  Recall     F1        \n",
      "---------------------------------------------\n",
      "technologia  0.667      1.000      0.800     \n",
      "sport        1.000      0.800      0.889     \n",
      "zdrowie      0.833      1.000      0.909     \n",
      "polityka     1.000      0.667      0.800     \n",
      "ekonomia     0.800      0.800      0.800     \n",
      "Średnia F1                         0.840     \n",
      "\n",
      "Few-shot:\n",
      "Kategoria    Precision  Recall     F1        \n",
      "---------------------------------------------\n",
      "technologia  0.571      1.000      0.727     \n",
      "sport        1.000      1.000      1.000     \n",
      "zdrowie      1.000      1.000      1.000     \n",
      "polityka     1.000      0.833      0.909     \n",
      "ekonomia     1.000      0.600      0.750     \n",
      "Średnia F1                         0.877     \n",
      "\n",
      "Sekcyjna:\n",
      "Kategoria    Precision  Recall     F1        \n",
      "---------------------------------------------\n",
      "technologia  0.667      1.000      0.800     \n",
      "sport        1.000      0.800      0.889     \n",
      "zdrowie      0.833      1.000      0.909     \n",
      "polityka     1.000      0.667      0.800     \n",
      "ekonomia     0.800      0.800      0.800     \n",
      "Średnia F1                         0.840     \n",
      "\n",
      "3. MACIERZE BŁĘDÓW\n",
      "--------------------------------------------------\n",
      "\n",
      "Zero-shot:\n",
      "Rzeczywiste \\ Przewidzianetechnologia sport       zdrowie     polityka    ekonomia    \n",
      "technologia    4           0           0           0           0           \n",
      "sport          0           4           1           0           0           \n",
      "zdrowie        0           0           5           0           0           \n",
      "polityka       1           0           0           4           1           \n",
      "ekonomia       1           0           0           0           4           \n",
      "\n",
      "Few-shot:\n",
      "Rzeczywiste \\ Przewidzianetechnologia sport       zdrowie     polityka    ekonomia    \n",
      "technologia    4           0           0           0           0           \n",
      "sport          0           5           0           0           0           \n",
      "zdrowie        0           0           5           0           0           \n",
      "polityka       1           0           0           5           0           \n",
      "ekonomia       2           0           0           0           3           \n",
      "\n",
      "Sekcyjna:\n",
      "Rzeczywiste \\ Przewidzianetechnologia sport       zdrowie     polityka    ekonomia    \n",
      "technologia    4           0           0           0           0           \n",
      "sport          0           4           1           0           0           \n",
      "zdrowie        0           0           5           0           0           \n",
      "polityka       1           0           0           4           1           \n",
      "ekonomia       1           0           0           0           4           \n",
      "\n",
      "4. RÓŻNICE MIĘDZY STRATEGIAMI\n",
      "--------------------------------------------------\n",
      "Nr  Tekst                                    Zero-shot    Few-shot     Sekcyjna     Prawda      \n",
      "-----------------------------------------------------------------------------------------------\n",
      "16  Komisja Europejska zatwierdza polsk...   ekonomia     polityka     ekonomia     polityka    \n",
      "19  Bitcoin przekroczył barierę 100 tys...   ekonomia     technologia  ekonomia     ekonomia    \n",
      "22  Klub Jagiellonia Białystok pozyskał...   zdrowie      sport        zdrowie      sport       \n",
      "\n",
      "Znaleziono 3 przypadków z różnymi klasyfikacjami\n",
      "\n",
      "5. NAJCZĘSTSZE BŁĘDY\n",
      "----------------------------------------\n",
      "\n",
      "Zero-shot:\n",
      "  polityka → ekonomia: 1 razy\n",
      "  sport → zdrowie: 1 razy\n",
      "  polityka → technologia: 1 razy\n",
      "\n",
      "Few-shot:\n",
      "  ekonomia → technologia: 2 razy\n",
      "  polityka → technologia: 1 razy\n",
      "\n",
      "Sekcyjna:\n",
      "  polityka → ekonomia: 1 razy\n",
      "  sport → zdrowie: 1 razy\n",
      "  polityka → technologia: 1 razy\n"
     ]
    }
   ],
   "source": [
    "# ANALIZA WYNIKÓW\n",
    "print(\"=== ANALIZA WYNIKÓW ===\\n\")\n",
    "\n",
    "# 1. ACCURACY dla każdej strategii\n",
    "print(\"1. DOKŁADNOŚĆ (ACCURACY)\")\n",
    "print(\"-\" * 40)\n",
    "for strategy_name, strategy_results in results.items():\n",
    "    accuracy = calculate_accuracy(strategy_results, extended_true_labels)\n",
    "    print(f\"{strategy_name:12s}: {accuracy:.2%}\")\n",
    "\n",
    "# 2. PRECISION, RECALL, F1 dla każdej kategorii\n",
    "print(f\"\\n2. PRECISION, RECALL, F1 dla każdej kategorii\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for strategy_name, strategy_results in results.items():\n",
    "    print(f\"\\n{strategy_name}:\")\n",
    "    print(f\"{'Kategoria':<12} {'Precision':<10} {'Recall':<10} {'F1':<10}\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    total_f1 = 0\n",
    "    for category in categories:\n",
    "        p, r, f1 = calculate_precision_recall(strategy_results, extended_true_labels, category)\n",
    "        print(f\"{category:<12} {p:<10.3f} {r:<10.3f} {f1:<10.3f}\")\n",
    "        total_f1 += f1\n",
    "    \n",
    "    avg_f1 = total_f1 / len(categories)\n",
    "    print(f\"{'Średnia F1':<12} {'':<10} {'':<10} {avg_f1:<10.3f}\")\n",
    "\n",
    "# 3. MACIERZ BŁĘDÓW (confusion matrix)\n",
    "print(f\"\\n3. MACIERZE BŁĘDÓW\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for strategy_name, strategy_results in results.items():\n",
    "    print(f\"\\n{strategy_name}:\")\n",
    "    cm = confusion_matrix(strategy_results, extended_true_labels, categories)\n",
    "    \n",
    "    # Nagłówek\n",
    "    header = \"Rzeczywiste \\\\ Przewidziane\"\n",
    "    print(f\"{header:<15}\", end=\"\")\n",
    "    for cat in categories:\n",
    "        print(f\"{cat:<12}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    # Wiersze macierzy\n",
    "    for true_cat in categories:\n",
    "        print(f\"{true_cat:<15}\", end=\"\")\n",
    "        for pred_cat in categories:\n",
    "            count = cm[true_cat][pred_cat]\n",
    "            print(f\"{count:<12}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "# 4. ANALIZA RÓŻNIC między strategiami\n",
    "print(f\"\\n4. RÓŻNICE MIĘDZY STRATEGIAMI\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "strategies_list = list(results.keys())\n",
    "print(f\"{'Nr':<3} {'Tekst':<40} {'Zero-shot':<12} {'Few-shot':<12} {'Sekcyjna':<12} {'Prawda':<12}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "differences_count = 0\n",
    "for i, text in enumerate(extended_test_texts):\n",
    "    zero = results[\"Zero-shot\"][i]\n",
    "    few = results[\"Few-shot\"][i] \n",
    "    sect = results[\"Sekcyjna\"][i]\n",
    "    true = extended_true_labels[i]\n",
    "    \n",
    "    # Sprawdź czy są różnice\n",
    "    if not (zero == few == sect):\n",
    "        differences_count += 1\n",
    "        print(f\"{i+1:<3} {text[:35]+'...':<40} {zero:<12} {few:<12} {sect:<12} {true:<12}\")\n",
    "\n",
    "print(f\"\\nZnaleziono {differences_count} przypadków z różnymi klasyfikacjami\")\n",
    "\n",
    "# 5. ANALIZA NAJCZĘSTSZYCH BŁĘDÓW\n",
    "print(f\"\\n5. NAJCZĘSTSZE BŁĘDY\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for strategy_name, strategy_results in results.items():\n",
    "    print(f\"\\n{strategy_name}:\")\n",
    "    errors = [(extended_true_labels[i], strategy_results[i]) for i in range(len(extended_true_labels)) \n",
    "              if extended_true_labels[i] != strategy_results[i]]\n",
    "    \n",
    "    if errors:\n",
    "        error_counts = Counter(errors)\n",
    "        for (true_cat, pred_cat), count in error_counts.most_common(3):\n",
    "            print(f\"  {true_cat} → {pred_cat}: {count} razy\")\n",
    "    else:\n",
    "        print(\"  Brak błędów!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4995b2ee",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "\n",
    "Model dość dobrze sobie radził z prostymi przykładami, szczególnie w strategii few-shot, gdzie miał podane przykłady do naśladowania. Chociaż mógłby mieć wiecej przykłądów w strategii few-shot, aby lepiej zrozumieć różnice między kategoriami w tych trudniejszych przypadkach. Początkowo model miał trudności z podawaniem kategorii, podawał synonimy lub bliskoznaczne wyrazy zamiast faktycznych kategorii, musiałem wymusić na nim aby faktycznie podawał tylko te kategorie które są w liście. Pozostałe poradziły sobie ciut gorzej ale wcale nieznacznie ponieważ stały na poziomie 84% w accuracy, a few-shot na poziomie 88%.\n",
    "\n",
    "Few-shot ma potencjał aby znacząco poprawić skuteczność klasyfikacji przez modele LLM, szczególnie w trudniejszych przypadkach. Dodanie większej liczby przykładów i bardziej zróżnicowanych przypadków mogłoby jeszcze bardziej poprawić wyniki.\n",
    "\n",
    "Niezależnie od podejścia model często mylił technologie w trudniejszych przypadkach z polityką czy ekonomią, niektóre rzeczywiście moga być subiektywne i czasami trudno jednoznacznie przypisać kategorię do krótkiego tekstu. W przypadku bitcoina podawał technologię często gdzie ekonomia byłaby bardziej odpowiednia. \n",
    "\n",
    "W trudniejszych przykładach podawał/mylił zdrowie z sportem, są to kategorie ze sobą powiązane, więc model mógł mieć trudności z rozróżnieniem ich.\n",
    "Można zauważyć, że czasami jak widział liczby w tekście to skłaniało go do przypisania kategorii ekonomia, nawet jeśli kontekst sugerował inną kategorię np. polityka.\n",
    "\n",
    "Aby bardziej przeanalizować różnice między strategiami, można by dodać więcej trudnych przykładów i niejednoznacznych przypadków, aby zobaczyć jak każda strategia radzi sobie z tymi wyzwaniami. Docelowo spodziewałbym się, że few-shot będzie miało największą przewagę w takich przypadkach mając dodatkowe przykłady do naśladowania."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d8544",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Zadanie 7.8: Mini-projekt: Asystent planowania wyjazdu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fd32d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZADANIE 7.8: ASYSTENT PLANOWANIA WYJAZDU ===\n",
      "\n",
      "======================================================================\n",
      "TEST 1: KRAKÓW - BUDŻET ŚREDNI (200 ZŁ)\n",
      "======================================================================\n",
      "## Plan jednodniowego zwiedzania Krakowa (budżet 200 zł)\n",
      "\n",
      "### Rano\n",
      "**8:00-10:00: Wawel Royal Castle**\n",
      "- Koszt: 15 zł (bilety wstępu do królewskiego zamku)\n",
      "- Opis i wskazówki:  Wawel jest jednym z najważniejszych miejsc w Krakowie. Zwiedzanie zamku daje unikalny przegląd historii i architektury. Można również zobaczyć Wawelową kaplicę, która jest pięknym przykładzie sztuki barokowej. \n",
      "**10:00-12:00: Rynek Główny**\n",
      "- Koszt: bezpłatny\n",
      "- Opis i wskazówki: Spacer po Rynku Głównym to obowiązkowa część zwiedzania Krakowa. Można zobaczyć stare budynki, sklepiki z rękodziełem i kawiarnię. \n",
      "\n",
      "### Popołudnie\n",
      "**12:00-15:00: Kazimierz**\n",
      "- Koszt: bezpłatny\n",
      "- Opis i wskazówki:  Kazimierz to dzielnica Krakowa, która jest znana ze swojej historii i kultury. Można tu znaleźć synagogi, kawiarnie i restauracje. \n",
      "**15:00-16:00: Lunch w Kazimierzu**\n",
      "- Koszt: 30 zł (np. pierogi lub makaron)\n",
      "- Opis i wskazówki:  Możliwość zjedzenia lokalnej kuchni w Kazimierzu.\n",
      "\n",
      "### Wieczór\n",
      "**18:00-21:00: Planty Park & Old Town Square**\n",
      "- Koszt: bezpłatny\n",
      "- Opis i wskazówki: Planty Park to piękny park, który można odwiedzić po południu. Można tu znaleźć fontanny, place i miejsca na odpoczynek. \n",
      "\n",
      "\n",
      "### Podsumowanie budżetu\n",
      "- Łączny koszt: 80 zł (bilety wstępu do Wawel i lunch)\n",
      "- Pozostaje: 120 zł \n",
      "\n",
      "\n",
      "\n",
      "**Uwagi:**\n",
      "\n",
      "* Transport: Kraków jest dobrze skomunikowany, można korzystać z autobusów lub tramwajów. \n",
      "* Jedzenie: Można znaleźć wiele restauracji w Krakowie, które oferują dania na różne gusta i budżety.\n",
      "* Wskazówki: Pamiętaj o wygodnych butach i odpowiednim odzieży.  Kraków jest miastem z bogatą historią i kulturą. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "\n",
      "TEST 2: GDAŃSK - BUDŻET NISKI (80 ZŁ)\n",
      "======================================================================\n",
      "## Plan jednodniowego zwiedzania Gdańska (budżet 80 zł)\n",
      "\n",
      "### Rano\n",
      "**8:00-10:00: Spacer po Starym Miastwie**\n",
      "- Koszt: Bezpłatny\n",
      "- Opis i wskazówki: Wybierz się na spacer po starówce, aby zobaczyć piękne zabytki, takie jak: Rynek Główny, Kościół Mariacki, Długa Street. Możesz również odwiedzić Muzeum Gdańska lub Muzeum Morskie (dodatkowe koszty). \n",
      "**10:00-10:30:  Poranny kawiarnia**\n",
      "- Koszt: 5-10 zł\n",
      "- Opis i wskazówki: Wiele kawiarni w Starym Miastwie oferuje niskie ceny kawy i ciast.\n",
      "\n",
      "### Popołudnie\n",
      "**12:00-14:00:  Lunch na plaży**\n",
      "- Koszt: 15-20 zł\n",
      "- Opis i wskazówki: Wybierz się na lunch na plaży w Gdańsku, aby cieszyć się widokiem na morze. Możesz również poszukać lokalnych barów i restauracji oferujących pyszne dania na przystępnych cenach.\n",
      "\n",
      "**14:00-15:00:  Spacer nad brzegiem Morza Bałtyckiego**\n",
      "- Koszt: Bezpłatny\n",
      "- Opis i wskazówki: Spacer nad brzegiem Morza Bałtyckiego, aby cieszyć się pięknym widokiem na miasto.\n",
      "\n",
      "### Wieczór\n",
      "**18:00-21:00:  Spacer po Gdańsku i obiad w lokalnej restauracji**\n",
      "- Koszt: 25-35 zł\n",
      "- Opis i wskazówki: Spacer po Gdańsku, aby zobaczyć piękne zabytki i miejsca. Możesz również odwiedzić Muzeum Morskie lub Muzeum Gdańska (dodatkowe koszty).\n",
      "\n",
      "### Podsumowanie budżetu\n",
      "- Łączny koszt: 40-60 zł\n",
      "- Pozostaje: 40-60 zł \n",
      "\n",
      "\n",
      "**Uwagi:**\n",
      "\n",
      "* Koszty są orientacyjne i mogą się różnić w zależności od lokalizacji i restauracji.\n",
      "* Transport publiczny w Gdańsku jest dobrze rozwinięty, a bilety kosztują około 2 zł za przejazd.\n",
      "* W przypadku chęci zwiedzania muzeów, warto sprawdzić ich ceny i godziny otwarcia przed wyjazdem.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "\n",
      "TEST 3: WARSZAWA - BUDŻET WYSOKI (400 ZŁ)\n",
      "======================================================================\n",
      "## Plan jednodniowego zwiedzania Warszawy (budżet 400 zł)\n",
      "\n",
      "### Rano\n",
      "**8:00-10:00: Muzeum Narodowe**\n",
      "- Koszt: 25 zł (wstęp)\n",
      "- Opis i wskazówki: Muzeum Narodowe oferuje bogatą kolekcję dzieł sztuki z historii Polski. Można tu zobaczyć obrazy, rzeźby, ceramikę i eksponaty związane z kulturą i historią kraju.  \n",
      "**10:00-10:30: Przerwa na kawę i deser**\n",
      "- Koszt: 20 zł (kawa i ciasto)\n",
      "- Wskazówki: Można wybrać kawiarnię w okolicy Muzeum Narodowego, np. \"Cafe Pod Wawelem\".\n",
      "\n",
      "### Popołudnie\n",
      "**12:00-15:00:  Royal Palace**\n",
      "- Koszt: 10 zł (wstęp)\n",
      "- Opis i wskazówki: Zobacz królewską historię w Royal Palace. Można zobaczyć rezydencję królów polskich, a także park i ogrody. \n",
      "**15:00-16:00: Spacer po Placu Zamkowym**\n",
      "- Koszt: bezpłatny\n",
      "- Opis i wskazówki: Plac Zamkowy to serce Warszawy. Spacer po placu pozwala na poznanie historii miasta, a także na odpoczynek. \n",
      "\n",
      "### Wieczór\n",
      "**18:00-21:00: Restauracja \"Restauracja Pod Baranem\"**\n",
      "- Koszt: 150 zł (porcja)\n",
      "- Opis i wskazówki:  Restauracja Pod Baranem to miejsce, które oferuje tradycyjne polskie dania w przyjaznej atmosferze. Można tu zjeść pierogi, kotlety i inne specjały kuchni polskiej.\n",
      "\n",
      "### Podsumowanie budżetu\n",
      "- Łączny koszt: 250 zł\n",
      "- Pozostaje: 150 zł \n",
      "\n",
      "\n",
      "\n",
      "**Uwagi:**\n",
      "\n",
      "* Koszty mogą się różnić w zależności od restauracji i usług. \n",
      "* Plan jest elastyczny, można go modyfikować w zależności od zainteresowań. \n",
      "* W Warszawie istnieje wiele innych atrakcji, które można odwiedzić, np. Muzeum POLIN, Teatr Wielki,  Warszawski Park Zoologiczny. \n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "\n",
      "TEST 4: WROCŁAW - BUDŻET ŚREDNI (250 ZŁ) - RODZINA Z DZIEĆMI\n",
      "======================================================================\n",
      "## Wrocław - Plan jednodniowy (budżet 250 zł)\n",
      "\n",
      "### Rano\n",
      "**8:00-10:00: Zwiedzanie Parku Wrocławskiego**\n",
      "* Koszt: Bezpłatny\n",
      "* Opis i wskazówki:  Park Wrocławski to idealne miejsce na rozpoczęcie dnia. Spacer po ścieżkach, obserwowanie zwierząt i oglądanie pięknych widoków na miasto. \n",
      "* Wskazówka: Przyjdź wczesnym rankiem, aby uniknąć tłumów.\n",
      "\n",
      "**10:00-12:00: Muzeum Wrocławskiego  (opcja)**\n",
      "* Koszt: 15 zł (dla dorosłych)\n",
      "* Opis i wskazówki: Muzeum Wrocławskiego oferuje bogatą kolekcję eksponatów dotyczących historii miasta. Możliwość poznania historii, kultury i sztuki w jednym miejscu.\n",
      "* Wskazówka:  Bilety można kupić online przed przyjazdem, aby uniknąć kolejki.\n",
      "\n",
      "### Popołudnie \n",
      "**12:00-13:00: Lunch na Placu Rynek (opcja)**\n",
      "* Koszt: 25 zł - 40 zł (dla dorosłych)\n",
      "* Opis i wskazówki:  Plac Rynek to serce Wrocławia. Można tu zjeść lunch w lokalnej restauracji, a także podziwiać piękno rynku.\n",
      "\n",
      "**13:00-15:00: Zwiedzanie Katedry św. Mikołaja (opcja)**\n",
      "* Koszt: 10 zł (dla dorosłych)\n",
      "* Opis i wskazówki:  Katedra św. Mikołaja to imponująca budowla, która zachwyci Cię swoją architekturą i bogatą historią.\n",
      "\n",
      "**15:00-16:00: Spacer po centrum Wrocławia**\n",
      "* Koszt: Bezpłatny\n",
      "* Opis i wskazówki:  Zwiedzanie centrum Wrocławia, w tym Placu Rynek,  Bazylika Św. Mikołaja i innych zabytków. \n",
      "\n",
      "### Wieczór\n",
      "**18:00-21:00: Spacer po Dolinie Wrocławskiej (opcja)**\n",
      "* Koszt: Bezpłatny\n",
      "* Opis i wskazówki:  Dolina Wrocławskiej to idealne miejsce na spacer po wieczornym mieście, a także na spotkanie z lokalną kulturą. \n",
      "\n",
      "**21:00-22:00: Kolacja w lokalnej restauracji (opcja)**\n",
      "* Koszt: 30 zł - 50 zł (dla dorosłych)\n",
      "* Opis i wskazówki:  Wrocław ma bogatą ofertę restauracji, w których można zjeść smaczną kolację.\n",
      "\n",
      "### Podsumowanie budżetu\n",
      "- Łączny koszt: 120 zł\n",
      "- Pozostaje: 130 zł\n",
      "\n",
      "\n",
      "**Uwagi:**\n",
      "* Koszty są orientacyjne i mogą się różnić w zależności od preferencji i wyboru konkretnych atrakcji. \n",
      "* W przypadku transportu, można skorzystać z komunikacji miejskiej (PKM) lub autobusów. \n",
      "* Można również skorzystać z aplikacji \"Wrocław\" lub \"Moovit\", aby uzyskać szczegółowe informacje o trasach i kosztach przejazdów.\n",
      "\n",
      "**Pamiętaj:**  Plan jest elastyczny, a każdy może go modyfikować w zależności od swoich preferencji i czasu wolnego. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ZADANIE 7.8: MINI-PROJEKT - ASYSTENT PLANOWANIA WYJAZDU\n",
    "\n",
    "print(\"=== ZADANIE 7.8: ASYSTENT PLANOWANIA WYJAZDU ===\\n\")\n",
    "\n",
    "class TravelAssistant:\n",
    "    \"\"\"Inteligentny asystent turystyczny dla miast Polski\"\"\"\n",
    "    \n",
    "    def __init__(self, model='gemma2:2b'):\n",
    "        self.model = model\n",
    "        \n",
    "    def create_travel_plan(self, city, budget, preferences=None):\n",
    "        \"\"\"\n",
    "        Tworzy plan jednodniowego zwiedzania miasta\n",
    "        \n",
    "        Args:\n",
    "            city (str): Nazwa miasta w Polsce\n",
    "            budget (int): Budżet w złotych\n",
    "            preferences (str): Opcjonalne preferencje (kultura, natura, rozrywka)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Określenie kategorii budżetu\n",
    "        if budget < 100:\n",
    "            budget_category = \"niski (do 100 zł)\"\n",
    "            budget_tips = \"Skup się na darmowych atrakcjach, parkach, spacerach po starówce\"\n",
    "        elif budget < 300:\n",
    "            budget_category = \"średni (100-300 zł)\"\n",
    "            budget_tips = \"Możesz wejść do muzeów, zjeść w restauracji, skorzystać z komunikacji\"\n",
    "        else:\n",
    "            budget_category = \"wysoki (powyżej 300 zł)\"\n",
    "            budget_tips = \"Możesz pozwolić sobie na wszystkie atrakcje i dobre restauracje\"\n",
    "\n",
    "        SYSTEM = \"\"\"Jesteś ekspertem od turystyki w Polsce. Tworzysz praktyczne plany zwiedzania miast polskich.\n",
    "        Znasz atrakcje, ceny, godziny otwarcia i lokalizacje w polskich miastach.\"\"\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        <ZADANIE>\n",
    "        Stwórz plan jednodniowego zwiedzania miasta {city} dla budżetu {budget} zł.\n",
    "        </ZADANIE>\n",
    "\n",
    "        <WYTYCZNE>\n",
    "        - Budżet: {budget_category} - {budget_tips}\n",
    "        - Uwzględnij rzeczywiste atrakcje z {city}\n",
    "        - Podaj orientacyjne koszty i czasy\n",
    "        - Plan na cały dzień: rano (8:00-12:00), popołudnie (12:00-18:00), wieczór (18:00-22:00)\n",
    "        - Dodaj praktyczne wskazówki (transport, jedzenie, bilety)\n",
    "        {f\"- Preferencje: {preferences}\" if preferences else \"\"}\n",
    "        </WYTYCZNE>\n",
    "\n",
    "        <FORMAT>\n",
    "        Zwróć plan w formacie Markdown z dokładnie takimi nagłówkami:\n",
    "        ### Rano\n",
    "        ### Popołudnie  \n",
    "        ### Wieczór\n",
    "        ### Podsumowanie budżetu\n",
    "        \n",
    "        Dla każdej części dnia podaj:\n",
    "        - Konkretne atrakcje z {city}\n",
    "        - Orientacyjne koszty\n",
    "        - Czas zwiedzania\n",
    "        - Praktyczne wskazówki\n",
    "        </FORMAT>\n",
    "\n",
    "        <PRZYKŁAD_STRUKTURY>\n",
    "        ### Rano\n",
    "        **8:00-10:00: [Atrakcja]**\n",
    "        - Koszt: [kwota] zł\n",
    "        - Opis i wskazówki\n",
    "\n",
    "        ### Popołudnie\n",
    "        **12:00-15:00: [Atrakcja]**\n",
    "        - Koszt: [kwota] zł  \n",
    "        - Opis i wskazówki\n",
    "\n",
    "        ### Wieczór\n",
    "        **18:00-21:00: [Atrakcja]**\n",
    "        - Koszt: [kwota] zł\n",
    "        - Opis i wskazówki\n",
    "\n",
    "        ### Podsumowanie budżetu\n",
    "        - Łączny koszt: [suma] zł\n",
    "        - Pozostaje: [reszta] zł\n",
    "        </PRZYKŁAD_STRUKTURY>\n",
    "        \"\"\"\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            options={\"temperature\": 0.3}  # Trochę kreatywności, ale kontrolowanej\n",
    "        )\n",
    "        \n",
    "        return response['message']['content']\n",
    "\n",
    "# INICJALIZACJA ASYSTENTA\n",
    "assistant = TravelAssistant()\n",
    "\n",
    "# TEST 1: KRAKÓW - BUDŻET ŚREDNI\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 1: KRAKÓW - BUDŻET ŚREDNI (200 ZŁ)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "krakow_plan = assistant.create_travel_plan(\n",
    "    city=\"Kraków\", \n",
    "    budget=200,\n",
    "    preferences=\"kultura i historia\"\n",
    ")\n",
    "\n",
    "print(krakow_plan)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "\n",
    "# TEST 2: GDAŃSK - BUDŻET NISKI  \n",
    "print(\"TEST 2: GDAŃSK - BUDŻET NISKI (80 ZŁ)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "gdansk_plan = assistant.create_travel_plan(\n",
    "    city=\"Gdańsk\",\n",
    "    budget=80,\n",
    "    preferences=\"spacery i darmowe atrakcje\"\n",
    ")\n",
    "\n",
    "print(gdansk_plan)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "\n",
    "# TEST 3: WARSZAWA - BUDŻET WYSOKI\n",
    "print(\"TEST 3: WARSZAWA - BUDŻET WYSOKI (400 ZŁ)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "warszawa_plan = assistant.create_travel_plan(\n",
    "    city=\"Warszawa\",\n",
    "    budget=400,\n",
    "    preferences=\"nowoczesne atrakcje i dobra kuchnia\"\n",
    ")\n",
    "\n",
    "print(warszawa_plan)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "\n",
    "# TEST 4: WROCŁAW - BUDŻET ŚREDNI Z RODZINĄ\n",
    "print(\"TEST 4: WROCŁAW - BUDŻET ŚREDNI (250 ZŁ) - RODZINA Z DZIEĆMI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "wroclaw_plan = assistant.create_travel_plan(\n",
    "    city=\"Wrocław\",\n",
    "    budget=250,\n",
    "    preferences=\"atrakcje rodzinne, aktywności dla dzieci\"\n",
    ")\n",
    "\n",
    "print(wroclaw_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15b25b",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "\n",
    "Model nie potrafi liczyć, często podawał niepoprawne koszty w stosunku do budżetu jaki jest, źle jest sumował i odejmował kwoty. Nie podał droższego budżetu w żadnym przypadku, aczkolwiek wątpie, że te koszty są poprawne, a zwłaszcza aktualne w dzisiejszych czasach. Model nie ma dostępu do aktualnych danych i nie potrafi ich weryfikować, przez co może podawać nieaktualne lub niepoprawne informacje. Model podążał za schematem zazwyczaj czyli - Zwiedzanie -> Lunch -> Aktywność popołudniowa (zwiedzanie)/Spacer -> Kolacja i tak w większości przypadków. Zawsze było to albo zwiedzanie albo spacer, brak innych atrakcji i aktywności. Model nawet pomylił Kraków z Warszawą podał Wawel i Muzeum Narodowe w przypadku pytania o Warszawę.\n",
    "Podawał ciekawe uwagi jak , transport publiczny jest dobrze rozwinięty i tani, aczkolwiek wszędzie podawał podobną uwagę jak z szablonu.\n",
    "W przypadku niskiego budżetu w Gdańsku podał łączny koszt do 60, pozostały budżet do 60, gdzie całkowity był 80, co jest błędem.\n",
    "Generalnie model radził sobie z generowaniem instrukcji i planów, ale miał trudności z dokładnym liczeniem i weryfikacją informacji finansowych i kreatywnym podejściem do atrakcji i aktywności. Pradowdopobobnie atrakcje kulinarne i konkretne szczegóły co do dań są halucynowane i niepoprawne.\n",
    "\n",
    "**Uwaga:** Ograniczenia modeli LLM w operacjach matematycznych wynikają z ich architektury - \n",
    "są to modele językowe, nie kalkulatory. Model nie zawsze pamięta wcześniejsze liczby i nie potrafi ich zawsze dokładnie zsumować lub odjąć. Dlatego czasami się myli w obliczeniach budżetowych. Chociaż pewnie można go zmusić promptem do dokładniejszego liczenia, ale i tak nie będzie to zawsze idealne rozwiązanie."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
